{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) \n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "################ Importing Data #################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cat_2</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Cat_2  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0   M  val1   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1   M  val1   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2   F  val1   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3   M  val1   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4   I  val1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Rings  \n",
       "0          0.1010         0.150     15  \n",
       "1          0.0485         0.070      7  \n",
       "2          0.1415         0.210      9  \n",
       "3          0.1140         0.155     10  \n",
       "4          0.0395         0.055      7  "
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Importing Data\n",
    "\n",
    "# ## Clean Data\n",
    "# df1 = pd.read_csv(\"abalone_v2.csv\", encoding='ISO-8859-1')\n",
    "# print(len(df1))\n",
    "# df1.head()\n",
    "# # Note: use '15' and all else as '8' for severely skewed classes\n",
    "\n",
    "# ## Importing Unclean Data (with missing values)\n",
    "# df1 = pd.read_csv(\"abalone_v2_missing.csv\", encoding='ISO-8859-1')\n",
    "# print(len(df1))\n",
    "# df1.head()\n",
    "\n",
    "## Importing Unclean Data (with missing values and outliers)\n",
    "df1 = pd.read_csv(\"abalone_v2_missing_outlier.csv\", encoding='ISO-8859-1')\n",
    "print(len(df1))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cat_2</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Cat_2  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0   M  val1   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1   M  val1   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2   F  val1   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3   M  val1   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4   I  val1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Target  \n",
       "0          0.1010         0.150      15  \n",
       "1          0.0485         0.070       7  \n",
       "2          0.1415         0.210       9  \n",
       "3          0.1140         0.155      10  \n",
       "4          0.0395         0.055       7  "
      ]
     },
     "execution_count": 1727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Rename target to 'Target'\n",
    "df1 = df1.rename(columns = {'Rings':'Target'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     689\n",
       "10    634\n",
       "8     568\n",
       "11    487\n",
       "7     391\n",
       "12    267\n",
       "6     259\n",
       "13    203\n",
       "14    126\n",
       "5     115\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "4      57\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "3      15\n",
       "21     14\n",
       "23      9\n",
       "22      6\n",
       "24      2\n",
       "27      2\n",
       "1       1\n",
       "25      1\n",
       "2       1\n",
       "26      1\n",
       "29      1\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check Distribution of Target Var\n",
    "df1['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2286\n",
      "1    1891\n",
      "Name: Target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cat_2</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F</td>\n",
       "      <td>val1</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "      <td>231.100</td>\n",
       "      <td>0.8945</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Cat_2  Length  Diameter   Height  Whole_weight  Shucked_weight  \\\n",
       "0   M  val1   0.455     0.365    0.095        0.5140          0.2245   \n",
       "1   M  val1   0.350     0.265    0.090        0.2255          0.0995   \n",
       "2   F  val1   0.530     0.420    0.135        0.6770          0.2565   \n",
       "3   M  val1   0.440     0.365    0.125        0.5160          0.2155   \n",
       "4   I  val1   0.330     0.255    0.080        0.2050          0.0895   \n",
       "5   I  val1   0.425     0.300    0.095        0.3515          0.1410   \n",
       "6   F  val1   0.530     0.415    0.150        0.7775          0.2370   \n",
       "7   F  val1   0.545     0.425    0.125        0.7680          0.2940   \n",
       "8   M  val1   0.475     0.370    0.125        0.5095          0.2165   \n",
       "9   F  val1   0.550     0.440  231.100        0.8945          0.3145   \n",
       "\n",
       "   Viscera_weight  Shell_weight  Target  \n",
       "0          0.1010         0.150       0  \n",
       "1          0.0485         0.070       0  \n",
       "2          0.1415         0.210       1  \n",
       "3          0.1140         0.155       1  \n",
       "4          0.0395         0.055       0  \n",
       "5          0.0775         0.120       1  \n",
       "6          0.1415         0.330       0  \n",
       "7          0.1495         0.260       0  \n",
       "8          0.1125         0.165       1  \n",
       "9          0.1510         0.320       0  "
      ]
     },
     "execution_count": 1729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Binary Target (not skewed)\n",
    "df1.loc[ ((df1['Target'] != 8) & (df1['Target'] != 9) & (df1['Target'] != 10)\n",
    "          , 'Target')] = 0\n",
    "df1.loc[ ((df1['Target'] == 8) | (df1['Target'] == 9) | (df1['Target'] == 10)\n",
    "          , 'Target')] = 1\n",
    "print(df1['Target'].value_counts())\n",
    "df1.head(10)\n",
    "\n",
    "# # Creating Binary Target (highly skewed)\n",
    "# df1.loc[ (df1['Target'] != 15 , 'Target')] = 8\n",
    "# print(df1['Target'].value_counts())\n",
    "# df1.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "################ Data Summary #################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>4169</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_2</th>\n",
       "      <td>4155</td>\n",
       "      <td>2</td>\n",
       "      <td>val2</td>\n",
       "      <td>2148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>4150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527006</td>\n",
       "      <td>0.412561</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.615</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>4160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40788</td>\n",
       "      <td>0.0993208</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>4160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200757</td>\n",
       "      <td>4.07829</td>\n",
       "      <td>-76.2</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.165</td>\n",
       "      <td>231.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole_weight</th>\n",
       "      <td>4095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826532</td>\n",
       "      <td>0.491023</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4395</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>1.14975</td>\n",
       "      <td>2.8255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked_weight</th>\n",
       "      <td>4142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359114</td>\n",
       "      <td>0.22245</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.503375</td>\n",
       "      <td>1.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera_weight</th>\n",
       "      <td>4129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.180858</td>\n",
       "      <td>0.109594</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell_weight</th>\n",
       "      <td>4144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239016</td>\n",
       "      <td>0.139557</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23475</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452717</td>\n",
       "      <td>0.497819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count unique   top  freq      mean        std     min     25%  \\\n",
       "Sex             4169      3     M  1523       NaN        NaN     NaN     NaN   \n",
       "Cat_2           4155      2  val2  2148       NaN        NaN     NaN     NaN   \n",
       "Length          4150    NaN   NaN   NaN  0.527006   0.412561   -15.4    0.45   \n",
       "Diameter        4160    NaN   NaN   NaN   0.40788  0.0993208   0.055    0.35   \n",
       "Height          4160    NaN   NaN   NaN  0.200757    4.07829   -76.2   0.115   \n",
       "Whole_weight    4095    NaN   NaN   NaN  0.826532   0.491023   0.002  0.4395   \n",
       "Shucked_weight  4142    NaN   NaN   NaN  0.359114    0.22245   0.001   0.186   \n",
       "Viscera_weight  4129    NaN   NaN   NaN  0.180858   0.109594  0.0005   0.094   \n",
       "Shell_weight    4144    NaN   NaN   NaN  0.239016   0.139557  0.0015    0.13   \n",
       "Target          4177    NaN   NaN   NaN  0.452717   0.497819       0       0   \n",
       "\n",
       "                    50%       75%     max  \n",
       "Sex                 NaN       NaN     NaN  \n",
       "Cat_2               NaN       NaN     NaN  \n",
       "Length            0.545     0.615    17.5  \n",
       "Diameter          0.425      0.48    0.65  \n",
       "Height             0.14     0.165   231.1  \n",
       "Whole_weight     0.7955   1.14975  2.8255  \n",
       "Shucked_weight    0.335  0.503375   1.488  \n",
       "Viscera_weight    0.171     0.253    0.76  \n",
       "Shell_weight    0.23475      0.33   1.005  \n",
       "Target                0         1       1  "
      ]
     },
     "execution_count": 1730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check each variable summary\n",
    "df1.describe(include='all').transpose()\n",
    "\n",
    "# Note: Outliers can be seen in 'min'/'max' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sex               0.191525\n",
       "Cat_2             0.526694\n",
       "Length            0.646397\n",
       "Diameter          0.406991\n",
       "Height            0.406991\n",
       "Whole_weight      1.963131\n",
       "Shucked_weight    0.837922\n",
       "Viscera_weight    1.149150\n",
       "Shell_weight      0.790041\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check for missing values\n",
    "\n",
    "# # in df\n",
    "print(df1.isnull().values.any()) # returns T/F\n",
    "\n",
    "# # col wise null count\n",
    "# df1.loc[:, list(df1.loc[:, df1.isnull().any()].columns)].isnull().sum()\n",
    "\n",
    "# col wise null% count\n",
    "df1.loc[:,list(df1.loc[:,df1.isnull().any()].columns)].isnull().sum()/(len(df1))*100 # % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "####### Cleaning Data (Missing Value Treatment) ########\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref code: https://www.geeksforgeeks.org/working-with-missing-data-in-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Missing Value Treatment #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1734,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER_INPUT\n",
    "impute_vs_droprow = 'impute' # 'impute', 'drop_row' / 'None'\n",
    "# if 'impute', select 'replacement_type'\n",
    "replacement_type = 'mean_mode' # '0_unknown', 'mean_mode', 'median_mode', 'reg_class'/'None'\n",
    "    # get the best using CV on Valid ('mean_mode' generally better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0/'unknown' imputation\n",
    "if impute_vs_droprow == 'impute' and replacement_type == '0_unknown':\n",
    "    for var in df1.columns.values:\n",
    "        if var != 'Target':\n",
    "            if np.issubdtype(df1[var], np.number): # num vars\n",
    "                df1[var].fillna(0,inplace=True)\n",
    "            else: # cat vars\n",
    "                df1[var].fillna('unknown',inplace=True)\n",
    "\n",
    "## Check for missing values\n",
    "df1.isnull().values.any() # returns T/F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mean/Mode imputation\n",
    "if impute_vs_droprow == 'impute' and replacement_type == 'mean_mode':\n",
    "    for var in df1.columns.values:\n",
    "        if var != 'Target':\n",
    "            if np.issubdtype(df1[var], np.number): # num vars\n",
    "                df1[var].fillna(df1[var].mean(),inplace=True)\n",
    "            else: # cat vars\n",
    "                df1[var].fillna(df1[var].mode()[0],inplace=True)\n",
    "\n",
    "## Check for missing values\n",
    "df1.isnull().values.any() # returns T/F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Median/Mode imputation\n",
    "if impute_vs_droprow == 'impute' and replacement_type == 'median_mode':\n",
    "    for var in df1.columns.values:\n",
    "        if var != 'Target':\n",
    "            if np.issubdtype(df1[var], np.number): # num vars\n",
    "                df1[var].fillna(df1[var].median(),inplace=True)\n",
    "            else: # cat vars\n",
    "                df1[var].fillna(df1[var].mode()[0],inplace=True)\n",
    "\n",
    "## Check for missing values\n",
    "df1.isnull().values.any() # returns T/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 4177\n",
      "NA rows(removed): 0\n",
      "Final rows: 4177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop rows with NA\n",
    "original_rows = len(df1)\n",
    "if impute_vs_droprow == 'drop_row':\n",
    "    df1 = df1.dropna()\n",
    "without_NA_rows = len(df1)\n",
    "\n",
    "with_NA_rows = original_rows - without_NA_rows\n",
    "print(\"Original rows: {}\".format(original_rows))\n",
    "print(\"NA rows(removed): {}\".format(with_NA_rows))\n",
    "print(\"Final rows: {}\".format(without_NA_rows))\n",
    "\n",
    "## Check for missing values\n",
    "df1.isnull().values.any() # returns T/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression/Classification imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "metadata": {},
   "outputs": [],
   "source": [
    "if impute_vs_droprow == 'impute' and replacement_type == 'reg_class':\n",
    "    pass\n",
    "\n",
    "########### DOESN'T SEEM A PACKAGE IS PRESENT - IMPLEMENT YOURSELF ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Use above techniques as hyper-params for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "####### Cleaning Data (Outlier Treatment-Must Do) ########\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER_INPUT\n",
    "outlier_treatment = 'None' # 'Tukeys'/'Grubbs'/'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tukey's Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>4177</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_2</th>\n",
       "      <td>4177</td>\n",
       "      <td>2</td>\n",
       "      <td>val2</td>\n",
       "      <td>2170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527006</td>\n",
       "      <td>0.411225</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.615</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40788</td>\n",
       "      <td>0.0991185</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200757</td>\n",
       "      <td>4.06998</td>\n",
       "      <td>-76.2</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.165</td>\n",
       "      <td>231.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826532</td>\n",
       "      <td>0.486178</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>2.8255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359114</td>\n",
       "      <td>0.221516</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>1.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.180858</td>\n",
       "      <td>0.108962</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239016</td>\n",
       "      <td>0.139004</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>1.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452717</td>\n",
       "      <td>0.497819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count unique   top  freq      mean        std     min     25%  \\\n",
       "Sex             4177      3     M  1531       NaN        NaN     NaN     NaN   \n",
       "Cat_2           4177      2  val2  2170       NaN        NaN     NaN     NaN   \n",
       "Length          4177    NaN   NaN   NaN  0.527006   0.411225   -15.4    0.45   \n",
       "Diameter        4177    NaN   NaN   NaN   0.40788  0.0991185   0.055    0.35   \n",
       "Height          4177    NaN   NaN   NaN  0.200757    4.06998   -76.2   0.115   \n",
       "Whole_weight    4177    NaN   NaN   NaN  0.826532   0.486178   0.002  0.4445   \n",
       "Shucked_weight  4177    NaN   NaN   NaN  0.359114   0.221516   0.001  0.1865   \n",
       "Viscera_weight  4177    NaN   NaN   NaN  0.180858   0.108962  0.0005   0.095   \n",
       "Shell_weight    4177    NaN   NaN   NaN  0.239016   0.139004  0.0015    0.13   \n",
       "Target          4177    NaN   NaN   NaN  0.452717   0.497819       0       0   \n",
       "\n",
       "                   50%     75%     max  \n",
       "Sex                NaN     NaN     NaN  \n",
       "Cat_2              NaN     NaN     NaN  \n",
       "Length           0.545   0.615    17.5  \n",
       "Diameter         0.425    0.48    0.65  \n",
       "Height            0.14   0.165   231.1  \n",
       "Whole_weight    0.8085  1.1415  2.8255  \n",
       "Shucked_weight  0.3375  0.5005   1.488  \n",
       "Viscera_weight   0.172  0.2515    0.76  \n",
       "Shell_weight     0.235  0.3275   1.005  \n",
       "Target               0       1       1  "
      ]
     },
     "execution_count": 1744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check each variable summary\n",
    "df1.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER_INPUT\n",
    "IQR_range = 3  # hyper-param\n",
    "replace_with = 'mean' # 'mean'/'median'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outlier Replacement - with mean/median\n",
    "\n",
    "if outlier_treatment == 'Tukeys':\n",
    "    for col in df1.columns.values:\n",
    "        if (np.issubdtype(df1[col] ,np.number)) & (col != 'Target'):\n",
    "            Q1 = df1[col].quantile(0.25)\n",
    "            Q3 = df1[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            Max_limit = Q3 + IQR_range*IQR\n",
    "            Min_limit = Q1 - IQR_range*IQR\n",
    "\n",
    "            print(\"---{}---\".format(col))\n",
    "\n",
    "            count = 0\n",
    "            for i, val in enumerate(df1[col]):\n",
    "                if (val < Min_limit) | (val > Max_limit):\n",
    "                    count += 1\n",
    "    #                 print(val)\n",
    "    #                 print(df1[col][i])\n",
    "                    if replace_with == 'mean':\n",
    "                        df1[col][i] = df1[col].mean()\n",
    "                    else:\n",
    "                        df1[col][i] = df1[col].median()\n",
    "    #                 print(df1[col][i])\n",
    "            print(\"number of outliers replaced for col '{}': {}\".format(col, count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>4177</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_2</th>\n",
       "      <td>4177</td>\n",
       "      <td>2</td>\n",
       "      <td>val2</td>\n",
       "      <td>2170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527006</td>\n",
       "      <td>0.411225</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.615</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40788</td>\n",
       "      <td>0.0991185</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200757</td>\n",
       "      <td>4.06998</td>\n",
       "      <td>-76.2</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.165</td>\n",
       "      <td>231.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826532</td>\n",
       "      <td>0.486178</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>2.8255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359114</td>\n",
       "      <td>0.221516</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>1.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.180858</td>\n",
       "      <td>0.108962</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell_weight</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239016</td>\n",
       "      <td>0.139004</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>1.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>4177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452717</td>\n",
       "      <td>0.497819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count unique   top  freq      mean        std     min     25%  \\\n",
       "Sex             4177      3     M  1531       NaN        NaN     NaN     NaN   \n",
       "Cat_2           4177      2  val2  2170       NaN        NaN     NaN     NaN   \n",
       "Length          4177    NaN   NaN   NaN  0.527006   0.411225   -15.4    0.45   \n",
       "Diameter        4177    NaN   NaN   NaN   0.40788  0.0991185   0.055    0.35   \n",
       "Height          4177    NaN   NaN   NaN  0.200757    4.06998   -76.2   0.115   \n",
       "Whole_weight    4177    NaN   NaN   NaN  0.826532   0.486178   0.002  0.4445   \n",
       "Shucked_weight  4177    NaN   NaN   NaN  0.359114   0.221516   0.001  0.1865   \n",
       "Viscera_weight  4177    NaN   NaN   NaN  0.180858   0.108962  0.0005   0.095   \n",
       "Shell_weight    4177    NaN   NaN   NaN  0.239016   0.139004  0.0015    0.13   \n",
       "Target          4177    NaN   NaN   NaN  0.452717   0.497819       0       0   \n",
       "\n",
       "                   50%     75%     max  \n",
       "Sex                NaN     NaN     NaN  \n",
       "Cat_2              NaN     NaN     NaN  \n",
       "Length           0.545   0.615    17.5  \n",
       "Diameter         0.425    0.48    0.65  \n",
       "Height            0.14   0.165   231.1  \n",
       "Whole_weight    0.8085  1.1415  2.8255  \n",
       "Shucked_weight  0.3375  0.5005   1.488  \n",
       "Viscera_weight   0.172  0.2515    0.76  \n",
       "Shell_weight     0.235  0.3275   1.005  \n",
       "Target               0       1       1  "
      ]
     },
     "execution_count": 1747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check each variable summary - after Outlier treatment\n",
    "df1.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Use IQR_range value as hyper-param for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grubb's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "################ Dummy Coding #################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Cat_2_val1</th>\n",
       "      <th>Cat_2_val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  Sex_F  Sex_I  Sex_M  Cat_2_val1  Cat_2_val2  \n",
       "0         0.150       0      0      0      1           1           0  \n",
       "1         0.070       0      0      0      1           1           0  \n",
       "2         0.210       1      1      0      0           1           0  \n",
       "3         0.155       1      0      0      1           1           0  \n",
       "4         0.055       0      0      1      0           1           0  "
      ]
     },
     "execution_count": 1750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select categorical variables & create dummies\n",
    "cat_vars = [x for x in list(df1.columns) if not np.issubdtype(df1[x].dtype, np.number)]\n",
    "df2 = pd.get_dummies(df1, columns=cat_vars)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Cat_2_val1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  Sex_F  Sex_I  Cat_2_val1  \n",
       "0         0.150       0      0      0           1  \n",
       "1         0.070       0      0      0           1  \n",
       "2         0.210       1      1      0           1  \n",
       "3         0.155       1      0      0           1  \n",
       "4         0.055       0      0      1           1  "
      ]
     },
     "execution_count": 1751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop last variable of dummy coding (for each cat var)\n",
    "df2 = df2.drop(['Sex_M','Cat_2_val2'],axis=1) # if not removed, var. red. required\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "########### Remove High Multi-Collinearity ############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def sklearn_vif(exogs, data):\n",
    "    # initialize dictionaries\n",
    "    vif_dict, tolerance_dict = {}, {}\n",
    "    # form input data for each exogenous variable\n",
    "    for exog in exogs:\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        X, y = data[not_exog], data[exog]\n",
    "        # extract r-squared from the fit\n",
    "        r_squared = LinearRegression().fit(X, y).score(X, y)\n",
    "        # calculate VIF\n",
    "        vif = 1/(1 - r_squared)\n",
    "        vif_dict[exog] = vif\n",
    "        # calculate tolerance\n",
    "        tolerance = 1 - r_squared\n",
    "        tolerance_dict[exog] = tolerance\n",
    "    # return VIF DataFrame\n",
    "    df_vif = pd.DataFrame({'VIF': vif_dict, 'Tolerance': tolerance_dict})\n",
    "\n",
    "    return df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Tolerance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>1.084343</td>\n",
       "      <td>0.922217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>7.457793</td>\n",
       "      <td>0.134088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>1.002530</td>\n",
       "      <td>0.997476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole_weight</th>\n",
       "      <td>34.903095</td>\n",
       "      <td>0.028651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked_weight</th>\n",
       "      <td>14.598504</td>\n",
       "      <td>0.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera_weight</th>\n",
       "      <td>11.283037</td>\n",
       "      <td>0.088629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell_weight</th>\n",
       "      <td>11.802654</td>\n",
       "      <td>0.084727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_F</th>\n",
       "      <td>1.294236</td>\n",
       "      <td>0.772656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_I</th>\n",
       "      <td>1.717390</td>\n",
       "      <td>0.582279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_2_val1</th>\n",
       "      <td>1.001298</td>\n",
       "      <td>0.998704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      VIF  Tolerance\n",
       "Length           1.084343   0.922217\n",
       "Diameter         7.457793   0.134088\n",
       "Height           1.002530   0.997476\n",
       "Whole_weight    34.903095   0.028651\n",
       "Shucked_weight  14.598504   0.068500\n",
       "Viscera_weight  11.283037   0.088629\n",
       "Shell_weight    11.802654   0.084727\n",
       "Sex_F            1.294236   0.772656\n",
       "Sex_I            1.717390   0.582279\n",
       "Cat_2_val1       1.001298   0.998704"
      ]
     },
     "execution_count": 1753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visual inspection of multi-collinear vars\n",
    "exogs = list(df2.columns)\n",
    "exogs = [x for x in exogs if x != 'Target'] # remove 'Target'\n",
    "vif_df = sklearn_vif(exogs=exogs, data=df2)\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER_INPUT\n",
    "remove_multi_collinear = 'N' # 'Y'/'N'\n",
    "vif_val = 10 # cutoff VIF; above 10 is recommended (through experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      VIF  Tolerance\n",
      "Length           1.084343   0.922217\n",
      "Diameter         7.457793   0.134088\n",
      "Height           1.002530   0.997476\n",
      "Whole_weight    34.903095   0.028651\n",
      "Shucked_weight  14.598504   0.068500\n",
      "Viscera_weight  11.283037   0.088629\n",
      "Shell_weight    11.802654   0.084727\n",
      "Sex_F            1.294236   0.772656\n",
      "Sex_I            1.717390   0.582279\n",
      "Cat_2_val1       1.001298   0.998704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Cat_2_val1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  Sex_F  Sex_I  Cat_2_val1  \n",
       "0         0.150       0      0      0           1  \n",
       "1         0.070       0      0      0           1  \n",
       "2         0.210       1      1      0           1  \n",
       "3         0.155       1      0      0           1  \n",
       "4         0.055       0      0      1           1  "
      ]
     },
     "execution_count": 1755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automatically removes all multi-collinear vars above 'vif_val' threshold\n",
    "vif_df = sklearn_vif(exogs=exogs, data=df2)\n",
    "print(vif_df)\n",
    "\n",
    "if remove_multi_collinear == 'Y':\n",
    "    while max(vif_df['VIF']) > vif_val:\n",
    "        for i, x in enumerate(vif_df['VIF']):\n",
    "            if (x == max(vif_df['VIF'])):\n",
    "                collinear_var = vif_df.index[i]\n",
    "                print('\\nVar removed: {}\\n'.format(collinear_var))\n",
    "\n",
    "                df2 = df2.drop(collinear_var, axis=1)\n",
    "                exogs = list(df2.columns)\n",
    "\n",
    "                vif_df = sklearn_vif(exogs=exogs, data=df2)\n",
    "                print(vif_df)\n",
    "                break\n",
    "            \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "########### Feature Engineering ############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "######### Feature Selection/Reduction - V1 ##########\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################### Remove multi-collinear vars ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER_INPUT\n",
    "remove_multi_collinear = 'N' # 'Y'/'N'\n",
    "vif_val = 20 # cutoff VIF; above 10 is recommended (through experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1757,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      VIF  Tolerance\n",
      "Length           1.084343   0.922217\n",
      "Diameter         7.457793   0.134088\n",
      "Height           1.002530   0.997476\n",
      "Whole_weight    34.903095   0.028651\n",
      "Shucked_weight  14.598504   0.068500\n",
      "Viscera_weight  11.283037   0.088629\n",
      "Shell_weight    11.802654   0.084727\n",
      "Sex_F            1.294236   0.772656\n",
      "Sex_I            1.717390   0.582279\n",
      "Cat_2_val1       1.001298   0.998704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Cat_2_val1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  Sex_F  Sex_I  Cat_2_val1  \n",
       "0         0.150       0      0      0           1  \n",
       "1         0.070       0      0      0           1  \n",
       "2         0.210       1      1      0           1  \n",
       "3         0.155       1      0      0           1  \n",
       "4         0.055       0      0      1           1  "
      ]
     },
     "execution_count": 1757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove multi-collinear vars - post 'featue engineering'\n",
    "vif_df = sklearn_vif(exogs=exogs, data=df2)\n",
    "print(vif_df)\n",
    "\n",
    "if remove_multi_collinear == 'Y':\n",
    "    while max(vif_df['VIF']) > vif_val:\n",
    "        for i, x in enumerate(vif_df['VIF']):\n",
    "            if (x == max(vif_df['VIF'])):\n",
    "                collinear_var = vif_df.index[i]\n",
    "                print('\\nVar removed: {}\\n'.format(collinear_var))\n",
    "\n",
    "                df2 = df2.drop(collinear_var, axis=1)\n",
    "                exogs = list(df2.columns)\n",
    "\n",
    "                vif_df = sklearn_vif(exogs=exogs, data=df2)\n",
    "                print(vif_df)\n",
    "                break\n",
    "            \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################### RFE (Recursive Feature Elimination) ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1758,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER_INPUT\n",
    "Remove_RFE_Vars = 'N' # 'Y'/'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RFE - check variable ranking using RFE\n",
    "# from sklearn import datasets\n",
    "# from sklearn.feature_selection import RFE, RFECV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# df2_ind_vars = df2.drop(['Target'], axis=1) # select ind vars\n",
    "\n",
    "# # create a base classifier used to evaluate a subset of attributes\n",
    "# model = LogisticRegression()\n",
    "# # create the RFE model and select 3 attributes\n",
    "# rfe = RFE(model, 1) # n here is user_defined\n",
    "# rfe = rfe.fit(df2_ind_vars, df2['Target'])\n",
    "# # summarize the selection of the attributes\n",
    "# print(rfe.support_)\n",
    "# print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "   estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "   min_features_to_select=1, n_jobs=None, scoring='f1_macro', step=1,\n",
       "   verbose=0)"
      ]
     },
     "execution_count": 1760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RFECV - XGBoost - to identify insignificant variables\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "xgb_m = XGBClassifier(objective='binary:logistic')\n",
    "rfecv = RFECV(estimator=xgb_m, step=1, cv=StratifiedKFold(10), scoring='f1_macro') # use cv=10\n",
    "# select 'scoring' from: https://scikit-learn.org/stable/modules/model_evaluation.html \n",
    "rfecv.fit(df2_ind_vars, df2['Target'])\n",
    "\n",
    "# Note: RFE - XGBoost did better than RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 6\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RFECV - RF - to identify insignificant variables\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import RFE, RFECV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# rfc = RandomForestClassifier(random_state=101)\n",
    "# rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(10), scoring='f1_macro') # use cv=10\n",
    "# # select 'scoring' from: https://scikit-learn.org/stable/modules/model_evaluation.html \n",
    "# rfecv.fit(df2_ind_vars, df2['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9kAAAJBCAYAAABS9nZwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XeYVOX58PHv0kVEVAiigIi9GyWxIIpiL6hRY9RALNE0E6NpJr8kaoymGBNjosYkKmJL7L1FEBXBgr2gWEBRVIqKSC/z/nHPvOfsMLs7u8zu7Mx+P9c1157znDNn7ql77vO0mkwmgyRJkiRJWnXtyh2AJEmSJEnVwiRbkiRJkqQSMcmWJEmSJKlETLIlSZIkSSoRk2xJkiRJkkrEJFuSJEmSpBIxyZakphkFZLK3s8saiVqTcSSfi+NT5aNo/s9LXY/dGgwliW1aWSMpraE0/XmdnbrvqBLGpObxe5L36x+p8m+nyu8v8lj/Sd3nzBLGWMiHqcfauZkfS1KWSbakYhxP8k86fVsIvEmcIG5VptgUBlD4Pcq/taTtiUTibFpf0lesaTT8mg4tU2ytyVCS9/qwcgbSihxP8pps30KP2Q44FLiR+OwuBD4DJgPXAocANS0US0v4N8n3cEI9+41O7Te+BeJqKT1JPmO/LGskkmrpUO4AJFW0LsBG2duRwK7Ai2WNqOWcR5zgAbxbzkBase2Bs7LLj9C2a+ta4vPyfWDN7PKUZnqMugwlea+vBm7P2/4cMCS7vKiFYmoJ9T2v44E9ssvTgOebOZbeRHK9e155F2Dz7O04YC3g02aOpaVcDZyUXd6F+F/0Vt4+qwNfSa2PKnEMtwMvZ5c/KfGxG9KT5Hu3GPhtgX2GA52yy6+0RFCSTLIlNc0QoCMwCPgd0J44kTkVOKWMcTVVR6J2Z0kj7vNG9tZa/YBIANqSbsDnzXj8q4ArC5S/VMR9W+LzUkwc5TKX6qpBzGktz6sr8ACwXXZ9BZFM3k3E2A84gNrJZn1WI5K2FSWNsvQeI5LqjbLrXwfOydvncOL/E8AC4kJEKX2YvbVWT5U7AKktsrm4pKYYDzwMXEDtPmj9C+zbF7gIeI1ouvg58AxwOpHc5utMJIjjiVqBJcAM4mRxl9R+6ea6A1LlQ1Pl01LlA/Lu04c4CZ1JnExuSfwm/oA4KfkMWArMysZ7OVETlDMqdayzs2W/S5VdXuC5vZnavm+qvLGvUTFeIl7D/Fu+LwM3ANOJ1/oT4CGi9iPfMcAd2efxKfH6zCFqqU+kdjPUDJGU5uzBys3Wh1L4vYK6+6senyofB3wJ+B/xfk1P7dcV+CnJe7mYSHL/DPQq8NyK8S6FX9O5Rdx3FCt/XmDl53kg8d4vIpKHU7P7bQLcmX0unxJ9OvOfx7jUsY6v57GHA08Qn7VZxGd1dWo7FbgPmEryXZhJJHKHp/YbkD3uWamyb7Dy+zq0QFnacODe7GMsBWYDDxItZPJNSx1rGPBjouZ+cTbeMwrcp5B/pY7zg1T5WanyE1PlF6TKf13P8zo+u75H6r5XUfjznJb7LH9OfKb+C3yhyOdyGkmCDVFjfRJwGzCWqPH9GrA1kWgWin1T4FbiN2AB0D27X6fs8Sdm41pCfNeuB3YsEMvXieT3E2AZ8RvxEvG8032CewB/IvndW0z81j9CvNZdi3zuV+c9dqF4cm4jPs8Q/0+uJ2p3ZxOfu8+AZ4FfNeLx6+uT3Tsb38fE+zqGuDhdl8bE9ATRDSCncyqOdP/r+vpkbwL8k/itWZSN8XniO7BG3r75fdL3IH5z5hPv9XXAOvU8N6ltyWQy3rx589bQ7fhMbeltd6fK/523bedMJvNJpm5jM5lM59T+a2cymWfr2f+HqX3TBqTKh6bKp6XKB+TdZ0re+vaZTOaceh47k8lkvpY63qhU+dnZsk1SZXMymUzHTO3XIh1Xu0zTXqO6bvnPb2gR9/luJpNZXs9jn5+3/3/q2TeTyWQuyhR+fwqp770iE69pzqhUefqz+F4mk1mQWv80u0/PTCbzUj2P/V4mk9kw0/DrQzaunLOL2H9cav/jU+WFPi/5z/PNTOH34/eZ+Dzlu78Jj/1GgeNkMpnMP/KO9UQd++Xkvov5n7t8ufe1vvf64gaOcXmm7vck/3uck/6u1nU7JrX/zanyMany9GfvqVT5bvU8r/RntJDcMdPv/euZTGZxgX3z3+O6bq+l7jOmyPukY/80k8nMzHvsHplMZvVMJjOxnueyNJPJjEwd84R69s1kMpkzU/s+0sC+6xb5PDbIZDIrUvfbJbVt3Uwmsyy1bZ/Uth828PgTMsnvNJn4Huakvy/fTpWn36/umcKfzwWZTGZyaj39mjQmpoa+oztn9/uwQBmZeC3m13P/KZlMpnem8PN/K1P7dc25PVPce+bNW9XfrMmW1BS7EbUgPwL2y5YtAS5L7dOZqInpkV2/BTiIqJnK9dveE/i/1H3+DnwxdbwLsvf5GnAFUdNRKv2J2qj9iCbus4EjstuWEf1b9wKOAn5O1K4sbeCYbwCPZpfXJppn5hybWr6KaIbZlNeoWA+z8gBd6X6yWwF/I2rvVxB9hvcFvkXSr/DnxGuQcydRazM8G9cworZsdnb7qcC62eUhwPmp+z6fLcvdSmF9oobo5GzsudrFS4gau9zjHkO8F7ek7peu/SpWuoYzdytl39aNgJuIz8AtqfKfAfOAo4nPZc5+wGaNfIyNiZYLB1P7+3oS0dw+J9fX9WDiu74P8f7mvoNnE13OPiDez3SrhftI3udCNdFpw6n9nP5C1Ob/gaTFwynE97CQgUTz4IOJ72jOaQ08LkQNb85u2b8dqV3bl/usrgHskF2eDzxZz3Hvzd4v3Qf7fJLX5LwC99mUiH84tZs7F/Mer563z4MN7F/ImsRz/yHxXTqNeK/PJXk9Ps+WH0zyW9KBqAntl13P/YZCfEaGES0fziBqeRdmt/Uk6Ts+nfiNH0bUOv+B6ONc7ECN7xA1qjkjUsvHEN2Zco8zJrXt2WxchwN7E79pXyXpZrML8V1sqp8TNcUQtcQ/Jl67/1G7VVRaY2I6hWixkLOE2r+x9fW/Xp2oec7VjD+efcwTgI+yZZsAl9Zx/4FEq5bhRAuunEOp3bJMarPsky2pKR7LW59ENG1+JlW2D0nz8VnAX4mTps+IZpp/y277JpEcrUntE+mfABen1v9bisDzjv+3vLJcs9+lRPPTZ1Nlvy/yuFeQnDweRySm7YkECSKhzSUkjX2NSukEki5DY0maOb5KNKnMNZM9mSQZeYB43b5HnGR1pXYT8fZEk9e7iGbUG6e2NUff1QyRkOUuSPyPuGCRPtH/I/BedvnvxElhR+IkdDPg9RLHtCpmEEnGMuLzkH4e3yGSV4gLHbnR/Delcc/hFeJzmcke7xvE+9gB2JCkX/fdxNRCw4jP6Gp5x1kT2IKkW8LeqW0zKf69Pj61fBdJU+/7SAZUzO13U4H7X07S/H420YQW4nVpyEfE67EV0ax3M2JQsK5E89l1ic/5+sA2JMnaY9R/wW1m9pbuRvAG9b8ms4kEZSHxOhxNkog19B73yFufU8++9RmZfWyI71JNtiznLJLf5P8RTfPXIy4Wfo24KJp+zq8T383cRbi/pLZ9DiwnXtNPidfnVZLB49LTWn2Bwu/n0yQXfUYRCSnEa/dDIulMJ9zXULuP+UTiwslPic9yd1buRrkzyWvSWOkLTH8BLswuP0R0PSnUFaAxMb1I7XFEGjNy+kEk3U0WEjMC5N6necDN2eVDic9X/sXED4ikfEk2lmNIkutNqK5p+qQmMcmWVApbEv2K88tyepHU8ObrQ/TjGkjt36RbSxZdYbcUKPsHMUL6akRCCXGy/Hx2/yuJBKg+NxPJcXdiupw1ssfMnVDlTrCg8a9RY06eCw18lr5/+rH3pnaSlJarEV6NqO1oqFZtrWIDLIE3WXk0+01JkiGI/o112ZrGJaiFBj5r6PPQGE+ljpf/Xk9MLc9OLa/dyMcYS1JDuIJotZCrzcoda13iwllD/YFL8V6na/TyE4TxJIlKXTV/6ZrJ9GtW7OsyhuSCxRCS5/QwkTTsnS3fNnWfdA14qUwkqeWFxj2X/ASoKf1iFxMXVtJ65R0r/f4sIT6vuenacu/Pv4gktz3RYgLiM/Zi9viXEv29FxGtJU4kLmA8Q3we3yVaCVxF8ht8ILVbSuRsSJLM3UK0YOlGvF4HEhdKv5jaP7/1ynXU3UIip6mf8Rrif1pO+vu7mHi+B7Cy5owpLf19eo3avynp97k9kTQ/nXf/8dRO8OeQJNmN/U2SqpLNxSU1RQ1xAj46u96VOIHZss571K9bw7vUK52cFzuo1QcFyq4hBnO5nDiB/JR4nvtmyy4o4rgLiEGpIBLTr1C7qfgVRcaXr7GvUaGBzybXe4/6H/dwkgR7PpHE70kkIOlRrRvzfyXdHDT/om8x72Oh97AxGvuaFhr47Il679E46VrA/FGd62qW3tg5jz/OW09fJMgd60SSBPsjotn4HsR7nT4Zbw3nEOnn05QLHumEeXeSViiPklz02p3ag5ilE/tSKeZ9qct8al8squuCWX0+ovjm2fUZRwzs9VfiotxsIincg/j9vC617ylEy43/EM3DlxCJ2tFEy5pDG/G480lqXyFqsNO12BOpPa3dQGonsxcQLYuGkPx+Q8t+xltjTHVZlc+r1Ca0hi+qpMo0izhJmppd70TtJtXphO5dkmmy8m/diD51U4jmgznpEYxz0v+80/ORpmvRDyky/kInlDXEifW3gZ2Ik8OdUtuPKfLY6UT6myTPZQ61+0U39jUqpfRj31DH49aQ1GSnR46/n6itH0fUUOW3YshJJ4qF/t+k38OeRLNTiIR7/4aeAIXfw/zP0WbU/Zo2pV92W5B+r68lau8fJT6jddWSNvRe1+W11PLgvG2D69ivlB4h+bzsnnrMR0n6eO9DdIOASC6Kne+6qa9JU4xKLe9N3bWhm5DMmZxW6Ls0i9o16un3oyPJawLJ+1NDvD4/JPq59yK6jeSm1juUpOXECiLpPoaozV6d6I6Sk/u9HUXh7/C0vHhHpZYPJrpCFNoGtT/j7xPNsx8iLpz1Y9VlSP43Qu1+/p1J+vevakyl+N5tTu3vdfp9Xk7rnqpSarVsLi5pVSwmBvH5d3b9EKJ53nNEn73pxMlBf6Lp37+I5td9iP6W+xL/wE8gavFuIvr2QVzFX5840e1G9A19gWSwpikkCfAl2duO1K69aKybiCvy44iTnPnUnmqrS5HHeYqomdmaZEAliJrydBO7xr5GpTSKOBFuR5zMziOacy4mkuYtif7L52f3fTt132HE6zyXGMynruaL6RP0bYla/ZlErezL2WMuI/4XdSZe//uJBGEgTfMp0dUgl2TcS3yW3iT6Fm5AJFObU3cT5Lr0p/b7mfM20Z+6WqTf6yOJWsB2RJ/cumqp0u/1EKLP51xi+qA363msUSQXoQ4hpnR6iHiPjsjbrzl8Soy98CXiswHxnXyHiH0xtccWGEfxc0enX5OjiKRwCVHrPKupAdfhr8RvZ24arxuI3467iTEe1icuXB1F9D9fUuAY+TJEa6XTs+vnEH3R3yZaN6yfLV9MUtP6F+J360HidZxLJJS5xLqG+K4vID4X9xJNp2cQTZNzLQmg+N/bnEeJxHZD4kJCn2z5IlYe0yP9GV+PSGhfIH4L8y/2NNXNxKCFEK/hHCK5PZl4D/I1JaZ0jXJHYhDB54nf1YkF7xHuJT6DvYgWV7cRfcZ7UHsgszso7eCOUpthki1pVY0mBuXKXYX/NXHSvIho9ncv8Y97L2qPVJ2TPgE/lUjutiVOxH5GcpICyckexAA8uaaHWxJJNiTJbVN0I0bzPbqO7Y2p+byC2gP95MrSmvIalcpLRJPvi4kE6pTsrS53EyeBA4lYc10FPiROHAslrBOIk+muxEBZuX7wY4jats+JvpYnZ8sPyd4yJANSNcX3iEGDtiZO+P9RYJ+mtAw4gcIXO04n5jmvFqOJgafWIhLPXDPcV4mLJIX6ao8lks92RJPfXP/eK4jWHHW5kxiQ7lQiAftR9pb2LwoPelYqY6ldK5trJr6YuGA2JG/fYv2PpE/5/iStM0YQLQRKaWH2+P8lEtX2xOte32tfjF8RI1rvTIwvkT9Y5DLidyM3R30Xohb54DqOdydJC5b1SeaBL2R0PdsKyV0UOCuv/HZWnsv+3Wz5YcTn7g/Z8mVEM/dSJNq/I97/jYhENjfw2VKSiwGrGtNs4qJ2ru95bmC6+dTfHeZzYgDE24nf50KzPrxB/JZKagKbi0taVUtJTgYgmgPmBgmaSDQD/DORNC0gTganEiegp1N71Ow5RO30Gdn7zs0e/wMiEU1Pm3M90bTwnew+b2TvV8zUPXW5jKhtfo04EVyejeGJ7HFPr/uuK7mW2rVFudrtfI19jUrpEuLk+TriBG8JUev1OpHUjCQZgG4BcQHgNqL2ZC5xwrwbyZQv+T4haq8nUff0a2cQSdQc4qLDE0Qt6M117F+MWcCXiVr2J0g+RzOy6+dRu5ZUtX1ITNv1EPF5mEN8nvek9uBcaZOJz8srNDzVXb7vExfm7ieShmXEZ+whYvqi+i7+lEJ+H+v0AISP5G1rTJJ9BZFovUfxtd+r4kPiPTqc+P68S3ynPie+09cTv8/5CWd95hP9qU8nfn/nEe/PDKL2ehdqJ8M3EC2bXiI+N8uzx3iO+B1LX8D8OfEbMo1ktPFZxOfgQJo2+OXVrNz0fVQd+44kLvC8T3yuJxK1/6WaBWEukbheS9QGL8weex/i/0GpYjqGaAU1r5Hx/Y9Izv9F/L9ZQvzOv0iM2D+I+ExJaoKaTKYU41xIkiRJkiRrsiVJkiRJKhGTbEmSJEmSSsQkW5IkSZKkEjHJliRJkiSpREyyJUmSJEkqEefJLpGePXtmBgwYUO4wJEmSJEnN4JlnnpmdyWR6NbSfSXaJDBgwgEmTJpU7DEmSJElSM6ipqXmnmP1sLi5JkiRJUomYZEuSJEmSVCIm2ZIkSZIklYhJtiRJkiRJJWKSLUmSJElSiZhkS5IkSZJUIibZkiRJkiSViEm2JEmSJEklYpItSZIkSVKJmGRLkiRJklQiJtmSJEmSJJWISbYkSZIkSSViki1JkiRJUomYZEuSJEmSVCIm2ZIkSZIklYhJtiRJkiRJJWKSLUmSJElSiZhkS5IkSZJUIibZkiSp6j3/PJxwAvzmNzB9ermjkSRVM5NsSZJU1W69FXbdFUaNgrPOggED4OCD4Y47YNmyckcnSao2JtmSJKkqZTJwwQVw5JGwcGFSvmIF3HMPHHYYbLAB/PKXMG1a2cKUJFUZk2xJklR1li6Fb30LfvrTSLYBNtoIhg2rvd+MGXDeeTBwIOy/P9xyS9xXkqSmMsmWJElV5dNP4cAD4V//Ssp22w2eeAIeegjeeAPOPBO+8IVkeyYDDzwQtd79+sX2N99s+dglSZXPJFuSJFWNqVNh8OBIpnOOOy7We/aM9Y03ht/9LgZAu/lm2G8/qKlJ9v/oI/jDH2CTTWDvveG//4XFi1v2eUiSKpdJtiRJqgpPPAE77QSvvpqUnX02XHMNdO688v6dOsERR8D998Pbb0ff7D59au8zZgx87WvQty/8+Mfw+uvN+hQkSVXAJFuSJFW8G2+EPfeEWbNivVMnuPbaGE08XUtdlwED4Nxz4d13Y9Txgw6CdqmzpNmz4cILYfPNYehQuO46WLSoOZ6JJKnSmWRLkqSKlcnA+efD0UcnSe8660QN9HHHNf54HTrA8OFw990x4vjZZ0ctdtojj8DXvw7rrw8//CG88sqqPgtJUjUxyZYkSRVpyRI48UT4v/9LyjbdNJqN77bbqh+/X7+oCZ82Lab8OvRQaN8+2f7xx/DXv8LWW8fjXX01LFiw6o8rSapsJtmSJKnifPxxDFg2alRSNnQoTJwYA5uVUvv2MVr57bdHc/Lf/jbm1057/HE4/nhYbz049VR48cXSxiBJqhwm2ZIkqaK8+SbssguMG5eUHX98TMG19trN+9jrrRc152+/HY93xBHRxDxn7ly45BLYbjvYeWe44gr4/PPmjUmS1LqYZEuSpIoxfnwkr1OmJGXnnQdXXhmDnbWUdu1g331jCrD33oPf/x422qj2Pk8+Cd/8ZiTm3/42PPtsy8UnSSofk2xJklQRrr8ehg2DOXNivXPnmMP6F78obgTx5tK7N/zsZ5H4jxkTg7B17JhsnzcPLr8cdtwRBg2K5c8+K1+8kqTmZZItSZJatUwGzjknRgtfsiTKevWK5uJf/WpZQ6ulXTvYay/4z3/g/ffhT3+KgdjSnnkmarXXWw9OPhmeeiqenySpephkS5KkVmvxYhg5MqbSytlii2iKvfPOZQurQb16wY9+BK+9FlN+HXdc1LznzJ8P//437LQTfPGL0Y/700/LF68kqXRMsiVJUqs0ezbsvTdce21StvfeMGECbLhh+eJqjJoa2H33eA4zZsBFF8GWW9be54UXYkTy9daDE06I52fttiRVLpNsSZLU6kyZEjXV48cnZSefDPfeCz16lC+uVbH22nDaafDyyzHl1ze+AV26JNsXLowpyQYPhm22iTm4P/64bOFKkprIJFuSJLUqjzwSCfZbb8V6TQ388Y8xYFh6QLFKVVMDu+4aCfUHH8Df/w7bblt7n1degR/+MGq3R4yARx+1dluSKoVJtiRJajWuvhr22Qc++STWV1stpsn6yU/KO4J4c+nRA773PXj++ehnftJJ0LVrsn3x4mhqvsce0Rf9wgujGb0kqfUyyZYkSWW3YgX88pdw/PGwdGmUrbtu1Gp/5StlDa1F1NTAl78cg6F98AH84x+www6193n9dfjxj2H99eGYY2Ds2HjdJEmti0m2JEkqq0WL4Nhj4bzzkrJttoma3S99qXxxlUv37vCtb8V0X5MmxfIaayTblyyJacKGDYPNNoM//AE++qh88UqSajPJliRJZTNzZswt/d//JmX77x8DnvXvX764Wosdd4xa7Rkzopb7y1+uvf3NN+HMM6FvXzjqKHjwQWu3JancTLIlSVJZTJ4cA5xNnJiUfec7cNddUZurRLdu0V/7ySej//b3vgdrrplsX7Ys+q7vtx9svHG0Cpgxo3zxSlJbZpItSZJa3JgxsMsuMHVqrNfUwF/+ApdcAh06lDe21m677WJE8hkzYoTyXXetvX3q1Ojf3r8/HH54THu2fHlZQpWkNskkW5Iktah//zuahM+dG+tdu8Ltt8eUVdU4gnhz6do15tp+/PGYe/u002CttZLty5fH63rQQbDhhnDOOTB9evnilaS2wiRbkiS1iBUr4Gc/g5NPjubNEPNAP/YYDB9e3tgq3VZbwUUXRe32tdfC7rvX3j59Opx9NgwYAIccAnfembwHkqTSMsmWJEnNbsEC+OpX4Y9/TMq23z76GOdPVaWm69IFjjsupj6bPBl+9CPo2TPZvmIF3H03HHoobLAB/PrX8M475YtXkqqRSbYkSWpWH34IQ4fCLbckZQcfHDXYffuWLayqt/nm8Kc/wXvvxZRfe+1Ve/uMGXDuudGU/IAD4NZbkznKJUlNZ5ItSZKazcsvw047wdNPJ2WnnRZ9hbt1K19cbUnnznD00THY3BtvRJP9L3wh2Z7JwP33wxFHQL9+8ItfwNtvly9eSap0lZZkrw3cBswH3gGOrWffHYBHgc+Bj4DTsuX9s2XpWwb4Ueq+x2aPPx+4Pfu4kiSpER54IEa+fvfdWG/XLkbFvugiaN++vLG1VRtvDL//ffTRvvlm2Hff2oPNffQR/O53sNFGsM8+cOONsGRJ+eKVpEpUaUn2JcASoDdwHHAZsFWB/XoC9wOXA+sAGwMPZre9C3RL3bYBVgC5RmxbZe83Ivs4C4BLS/9UJEmqXpddFqNaz5sX6926RV/g732vvHEpdOoUNdcPPABvvQX/93/Qp0/tfR56KGrA+/aFn/4UpkwpT6ySVGlqMplMuWMo1urAJ8DWQO5n/hrgfeDMvH3PB/oRiXJDzgKGAnum7juApJZ8I2AykazPq+sggwYNykyaNKmIh5MkqXotXw4/+UnMeZ3Tr18k2NtuW7641LBly+Cee+Cf/4T77otm5PmGDoVTTon5t7t0afEQJamsampqnslkMoMa2q+SarI3BZaRJNgAL1C4Jntn4GNgAjATuItoJp6vBhgJXJ0q2yp73Jy3iNrzTZsauCRJbcHnn8NXvlI7wd5xxxhB3AS79evQIUYdv+cemDYNzjpr5YHpxo2DY4+F9deHM86IEcwlSbVVUpLdDfgsr2wusEaBffsC3yD6YfcHpgI3FNhvN6JJ+M15jzO3mMepqak5paamZlJNTc2kWbNmFfMcJEmqSjNmxNzMd96ZlB12WEwlld8MWa1f//4xr/a0adEKYfjw2v3oP/44LqZsuSUMGQLXXAMLF5YrWklqXSopyf4c6J5X1p3CTbgXEgOkPQ0sAs4BdgXWzNvvG0Rf7M+b8jiZTOafmUxmUCaTGdSrV68in4YkSdXl+efhy1+G555Lyn7845iya/XVyxeXVl379tG3/o47Yj7tc8+N+bXTxo+HkSNhvfXgBz+Al14qT6yS1FpUYp/srYA3smWjgRms3Cf7GmApcGJ2fW1gDtCDpJZ6NeBD4HBgbOq+5wMbEAOrAQwEXsM+2ZIkreSee2JwrPnzY719e7j00ui3q+q0fHkMivbPf0bLhWXLVt5nwADo3TumCsvdevVaeb1XL+jYscWfgiQ1SbF9sispyQb4DzHd1jeB7YF7iRrqV/L224uood4zu+2PwCBgSGqfY4mEesPsMXO2AiYCBwHPEiONdwC+Vl9gJtmSpLbm4ovh9NNhxYpY794dbroppoVS2/DhhzBqFPz73zFKeVOstVb9iXh6fe21Yyo4SSqHak2y1wauBPYhaqbPBK4nkuf7iP7UOd8Bfgl0BcYD3wWmp7Y/ADwF/KrA4xwL/J6ovX4IOIEYSK1OJtmSpLZi2bJIrv/+96Rsgw2iVnurQsORquqtWAEPPwz/+hfceissXdo8j9OuHfTsWXxS3r177XnAJWlVVGuS3Wp8qcdbAAAgAElEQVSZZEuS2oJ58+BrX4N7703Kdtop+uz27l2+uNR6zJ8P778PM2fGbdasZDl/ffbswlOFlUqnTg0n4un1rl2bLxZJla/YJLtDSwQjSZIq3/TpcMgh8EJqosujjoKrr4bVVitfXGpdVl8dNt00bg1ZvjxGKq8rCc9f//TTxsWyZEkk/O+/X3zs+Ul4ff3JO3VqXDyS2gaTbEmS1KBnnokE+4MPkrKf/xx++1v7yKrp2rdPEtZiuhosWRK138Um5bkB+Yo1f37cpk0rbv8ePYprtp7rT56eBk1S9TLJliRJ9brjDjj2WFiwINY7dIiRpU84obxxqe3p1CmmCltvveL2X7Cg/iQ8f33JksbF8+mncZsypeF9a2oa1598zTXtTy5VKpNsSZJUUCYDf/lLzHmd6zfbo0cMbLXnnuWNTSpG164xKF/+3N6FZDLw2WcrJ+F1JeazZiUj6xcjk0nu90r+vDgFdOzYcCK+3XbQr1/xMUhqGSbZkiRpJUuXwve/D5dfnpQNHBgjiG++efnikppLTU3UHq+5Jmy8ccP7r1iR9Ccvprb843rnqVnZ0qUwY0bc6tKuHZx3HvzsZ9Z6S62JSbYkSapl7lz46lfhwQeTsl13hdtvj5o0Scl0Yj17Frf/0qVJf/JikvJ58xo+5ooVMTbC9Okxb719vqXWwSRbkiT9f9OmwcEH127OeswxcOWV0KVL2cKSKl7HjtCnT9yKsXBhknwXSsKffRZeein2vfTSGEH9+uudhkxqDUyyJUkSAE8+CcOHx0l8zq9/DWefbVNUqaWtthr07x+3QhYvjsEHb7gh1u+4A4YNg7vuKr52XVLzcNINSZLEzTfD0KFJgt2xI4weDeecY4IttUadO8O118JPf5qUPfFEdO14++3yxSXJJFuSpDYtk4E//AGOOgoWLYqytdeGhx6CESPKG5uk+rVrF9/fv/0tuRj2xhuwyy7w9NPljU1qy0yyJUlqo5YsgZNPhjPPTMo22SRqw3bfvXxxSWqcU0+FW25Jxk2YOTNaptx7b1nDktosk2xJktqgTz6BAw6AK65IynbfHSZOjERbUmU5/HAYMyZaogAsWBBjLPz73+WNS2qLTLIlSWpj3n47+m2OHZuUjRwZU3ats0754pK0anbdFSZMgAEDYn358mitctZZ0TVEUsswyZYkqQ2ZMAF22gleey0pO/dcGDUqBlKSVNk22yxapOywQ1L2m9/ASSfFXN2Smp9JtiRJbcR//gN77QWzZ8d6584xr+4vf+kI4lI1WXddeOQR2H//pOyqq+CQQ2DevPLFJbUVJtmSJFW5TAZ++1s45piYWxdiHt2xY6NMUvXp1g3uvDPm0s554IEYEO3DD8sWltQmmGRLklTFFi+G44+HX/0qKdt8c3jyyei/Kal6dewYgxuedVZS9uyzMcVXusuIpNIyyZYkqUrNmQP77gujRydle+0V/bIHDixfXJJaTk0NnH12jDLevn2UTZsGgwfD44+XMzKpeplkS5JUhd54I2qrHn00KTvpJLj/flhrrfLFJak8Tjopmo937RrrH38Mw4bBrbeWNy6pGplkS5JUZR59FHbeORLtnN//Hv71r2g+KqltOvDAGBDtC1+I9cWL4cgj4W9/K29cUrUxyZYkqYpccw3svXfUUgF06QI33QQ/+5kjiEuCQYNiiq9NNon1TAZ+8AP4yU9gxYryxiZVC5NsSZKqQCYDv/41jByZzIXbu3fUWh15ZHljk9S6DBwYYzPssktS9qc/wXHHJTMQSGo6k2xJkircokVxcnzuuUnZVlvFCOJf/nL54pLUevXsCQ89BIcdlpT95z8xt/ann5YvLqkamGRLklTBZs2K5uE33JCU7btvjBq8wQbli0tS69e1K9x8M3z3u0nZuHGw224wfXrZwpIqnkm2JEkV6rXXYoCz9DQ83/423HMPrLlm+eKSVDnat4e//z0GR8x55ZVoSv7SS+WLS6pkJtmSJFWgsWPjJPjtt2O9pgYuvBAuvRQ6dChvbJIqS01NDI547bXJDATvvx812mPHljc2qRKZZEuSVGGuugr22y/pN9m1a8x1e8YZjiAuqemOOw7uuw+6d4/1zz6LPtrXX1/euKRKY5ItSVKFWLECfvELOPFEWLYsyvr0iXmx04MXSVJTDRsGjz0G668f60uXRvL9hz/ELAaSGmaSLUlSBVi4EL72Nfjd75KybbeNEcR33LF8cUmqPttuG3Npb7VVUnbmmfD978Py5eWLS6oUJtmSJLVyH30Ee+4JN92UlB14IIwfD/36lS8uSdWrX7/4jRk6NCm75BI48si46CepbibZkiS1Yq+8AjvtFDXWOd//PtxxB6yxRvniklT9evSA+++PVjQ5t98eTcpnzy5fXFJrZ5ItSVIr9b//wa67wjvvxHq7dnDxxXFzBHFJLaFzZ7juOvjxj5OyiRNh8OBkdgNJtZlkS5LUCv3zn3DAATG6L0C3bnDnnVGLLUktqV07uOAC+OtfkxkMpkyJaQQnTSpvbFJrZJItSVIrsmJF1Bh961vJAEPrrx99Iw86qLyxSWrbfvCDGBuic+dYnzkz+mzfd19Zw5JaHZNsSZJaifnz4Ygj4MILk7IddoCnnoLttitfXJKUc8QRMGYMrLVWrM+fD4ccAldcUd64pNbEJFuSpFZgxgzYY48YVChn+PCYA3u99coXlyTlGzwYJkyADTaI9eXL4ZvfhLPPdi5tCUyyJUkquxdfjBHEn3kmKTvjDLj1Vlh99fLFJUl12XxzeOIJ+OIXk7Jzzolke+nS8sUltQYm2ZIklcHixfD443D++VEr9N57Ud6+PVx6aTQZb9++vDFKUn3WXRceeQT22y8pu/LKaIXz+efli0sqNycAkSSpBXzySTSvHD8+bk8/HYl22hprxKBC6RNWSWrN1lgD7rorBmu86qoou//+6P5yzz2RiEttjUm2JEnN4J13koR6/Hh4+eX69+/fP05It966ZeKTpFLp2DEGPuvXD37zmyh79tmY4uv++2Gzzcobn9TSTLIlSVpFy5fDK6/UTqqnT2/4fhtvDLvtFrejjoLu3Zs/VklqDjU10Se7b1/4znfid3HaNNh1V7jzzugWI7UVJtmSJDXSwoXR3DuXUE+YAHPn1n+f9u1jgKBcUj14sM0oJVWfk0+OGRG++lVYsAA+/hj23huuvx4OP7zc0UktwyRbkqQGzJ5duz/1pEkNj567+urRVDKXVO+0E3Tr1jLxSlI5HXQQjBsXf2fNgkWLYn7tiy+GU08td3RS8zPJliQpJZOBqVNrN/2ePLnh+627bpJQ77YbbLcddPC/rKQ26ktfgokT4YAD4I034rf1+9+Hd9+F3/8e2jnHkaqY//4lSW3asmUxT3U6qf7gg4bvt/nmtZPqgQOjT6IkKWy0UUxVOHx4zKkNcMEFMWXhVVdB587ljU9qLibZkqQ2Zf58ePLJJKGeOLHh+Vw7dIBBg5KEetddoVevlolXkipZr14wZgwceyzccUeU3XADfPgh3Hor9OhR3vik5mCSLUmqajNnRk1KLql+9tmova5P9+6RSOeS6i99Cbp2bZl4JanadO0Kt9wSzcUvuyzKHn4YhgyBe++Nqb+kamKSLUmqGpkMvPlm7abfU6Y0fL/11ouTvSFDIqneeusYDVySVBrt28Mll0D//vDzn0fZyy/HAJH33QfbbFPe+KRSMsmWJFWspUvh+edrJ9UzZzZ8v622qt2feoMN7E8tSc2tpgbOPDPm0j7xxPgNf//9+B2+7TbYa69yRyiVhkm2JKlizJsXg+fkEuonnoh5WOvTqVM09073p1577ZaJV5K0sq9/Hfr0iXmz582Dzz6D/feHUaOi77ZU6UyyJUmt1gcf1K6lfv55WLGi/vv06AGDBydJ9aBB0KVLy8QrSSrOsGHw2GNw4IEwY0bUah93XIw8/pOf2LqoLclk4qL56NGw/fbwrW+VO6JVZ5ItSWoVMhl47bXaSfXbbzd8vw02qN30e8stnX9VkirBdtslc2m/+mqU/exnMH06XHSRY2NUu6lT4Zpr4vbmm1G27bYm2ZIkNdmSJTHS9/jxUZvx+OMwZ07996mpiX/AuYR68GBHpZWkSta/f/wfOPxweOSRKPv736Ov9nXXwWqrlTc+ldann8JNN0Vi/dhjK29/8cW4bbtty8dWSibZkqQWMXdu1FjkaqmffBIWLar/Pl26wE47JUn1LrvAmmu2TLySpJax1lrwwAMwciTceGOU3XZbNCm/6y5YZ53yxqdVs3QpPPhgNAe/4w5YvHjlfbp3h69+FUaMiBk+Kp1JtiSpWbz3Xu2m3y++GE3C67POOlE7nZtKa4cdYuAySVJ169wZbrghWiddeGGUTZwYg1Xefz9suGF541PjZDLw3HORWF9/PcyatfI+7dvHgHcjRsDw4dXVasEkW5K0ylasiP506aT6nXcavt/AgbX7U2+2mf2pJamtatcO/vSnSLRPPz0StSlTYOed4d57Yccdyx2hGvLee9HMf/TopJ99vh12iMT6mGOgd++Wja+lmGRLkhpt0SKYNClJqB9/PPpZ1adduxg1NN2fer31WiZeSVLlOO00WH/9mOpr8WKYORP22CP68h5wQLmjU77PP4dbb43EeuzYwq3W1l8/Ro+vlubgDTHJliQ16OOPYcKEJKl++ukYuKw+XbtG7UMuqd55Z1hjjZaJV5JU2Y48Mmo5Dz0UPvkE5s+HQw6Byy+Hk04qd3RavjwS6muugVtugQULVt6na1c44ojoa7/nnm1rtHiTbElSLbNnw+TJcXvuuUiqX3654ft94Qu1m35vvz107Nj88UqSqtOQIdFS6oADogvS8uXwzW/GFF9nneVc2uXw8suRWF97bcxvnq+mJgasGzkyRozv1q3lY2wNTLIlqQ3KZGJ6lFdfTRLq3K3Q4CSFbLpp7aR644094ZEkldYWW8QAaAceCM8/H2XnnBN9fy+7zIu5LeGjj2JQutGj4+J7IVtuGYn1ccdB374tG19rZJItSVVs2TKYOnXlZPq112DevOKP06FDDFSSS6h33bV6ByuRJLUuffrAo49GE/IHH4yyK66ImtQbb2y7taXNaeFCuPPOSKwfeCBaEeTr1QuOPTaS6y9+0QvtaSbZklQFFi2KEVgnT66dUE+Z0nDf6XyrrQabbx61B1tuGQn1l78Mq6/ePLFLktSQNdaAu++Gk0+Gq6+Osvvug6FD4Z57vPBbCitWRBex0aNjkLnPPlt5n86do5/8yJGw7762JKhLpSXZawNXAPsCs4GfA9fXse8OwEXZv/OB84G/prafBvwQ+ALwLnAoMAUYCowF0t33vwdcXaLnIElN9tlnSQKdTqanTo1/jo2x1lqRSKdvW24J/fs7jZYkqfXp2BGuuiqm+Prtb6PsmWdgl10i4d5ss/LGV6mmTEn6WU+bVnifIUMisT7ySOjRo0XDq0iVlmRfAiwBegPbA/cALwCv5O3XE7gfOB24GegEpHsHfBM4CTgImAwMBD5JbZ+Rt78ktZhMJqYrSTfvziXUhQYZaUifPpE85yfUvXvbtEuSVFlqauDccyPR/s534gLz1KnR6uquu+KvGjZnDvz3v5FcP/FE4X023jgS669/HTbcsGXjq3SVlGSvDhwBbA18DowH7gRGAGfm7XsG8ABwXXZ9MZFMA7QDzgKOB3JTpL/VXEFLUl1WrIB331154LFXX43pShqjpib+AeYn05tv7hVnSVL1OeUUWG89OPromD7q449jVOvrr49RrbWyJUvg3nujOfjdd8PSpSvvs9Za8LWvRXK9005ejG+qSkqyNwWWEU26c14A9iiw787AS8AEYGPgSaLJ97tEDXVfIlkflT3maOAcINfY8gvAR0ST8duBXxJNziWp0ZYuhTffXDmZfu21wvNK1qdjxxjVOz+Z3nTT6EstSVJbcfDB8PDD8XfWrBif5Igj4G9/g+99r9zRtQ6ZDDz5ZNRY/+c/cTEiX8eOcNBBMGJE/O3cueXjrDaVlGR3A/K7388F1iiwb1+iL/Y+RLL9R+AGYDBJM/B9gW2AHsCDwHvAv4DXiKborwEbEH2x/wx8K/9BampqTgFOAejfv3+Tn5ik6rBgAbz++sojeb/xRozy3RjdutUefCyXTA8cGCN9S5KkGJhzwoSYS/vNNyOpPPXUaCn2u9+13TFGpk2LPtajR8d5SCE77RSJ9dFHQ8+eLRpe1avJZDLljqFYXwQeB7qmyn5EDFR2SN6+LwDPAidk19chBkrrQfS/fjZ7v0dSx9kNKNS4ZGfgbqKfd50GDRqUmTRpUlFPRFJl++STlQcemzwZ3nkn/rk3Rs+eKw88tsUWMcekTbQkSSrOrFlwyCFRa5tz7LFw5ZVtp2Z27ly4+eZIrB99tPA+/ftHYj1ihAPFNUVNTc0zmUxmUEP7VVJ9yBQi3k2A3PWY7Vh50DOAF4H0qW56+XVi8LS6tufLEP24JbUhmQx88EHhkbw/+qjxx+vXb+WBx7bYIuaYlCRJq6ZXLxg7NvoT33VXlF1/ffwvv/XW6h2fZNmymDt89Gi4445oMp9vjTXgqKOin/WQIW23dr8lVVJNNsB/iKT3m0ST7nuBXVk50d4LuAXYM7vtj8AgYEh2+2hiOrBjgDWBh4ALiOnB9gTeJum/PRqYRlIrXpA12VJlWr48mlTlJ9OvvRZXhBujfXvYaKOVE+nNN49/cJIkqXktWwbf/z784x9J2dZbxxRffatk7qBMBp5/PvpZX3994Yv/7drBfvtFYj18OHTtuvI+arxqrMkG+C5wJTATmAN8h0iihwD3Ef22Iea5/gUxxVdXYiTyY1PHORX4JzFV16dEX+wrs9u+CFwLrJV9jNuA/2uuJySpZSxeHH2S8kfxnjKl8FXf+nTunPSXTt822aTtNEmTJKk16tABLr00mkX/4hdR9vLLyVzaW29d3vhWxfvvR1I9enQ8p0K23z4S62OOgXXXbdn4lKi0muxWy5psqXWYNy9qofNH8n7rrai1bozu3VceeGyLLWDAgKi1liRJrdc118CJJyaDj665Jtx2G+y5Z3njaoz58yPm0aPhoYcKj/3Sp0/MZT1iBGyzTcvH2JZUa022JAEwe/bKA49NngzTpzf+WL17rzzw2BZbxD8tBx+TJKkyjRgRtblHHBEX4efOjSbUV18dNb2t1fLlMG5cJNa33BKJdr6uXWM+8JEjY35wL/63LibZkirK55/DvvvCxImNv++AAYWT6bXWKnmYkiSpFdhnnxhp+8ADYxC0pUtj1PH33oMf/7h1XUx/9dVIrK+9NpqG56upiVr4kSPhK19xvJfWzCRbUkW55pr6E+wOHaJvdH4yvdlmDvohSVJbtP328MQTsP/+0eoN4Kc/jdZvf/lLeWuBZ86EG26I85tnnim8zxZbRGJ93HExW4laP5NsSRXlwQeT5U03hS99qXZCvdFG0LFj+eKTJEmtT//+8PjjcNhhyRzSf/tb1Ghfdx2stlrLxbJoEdx5ZyTW991XeMyYnj2jxn3ECNhxx9ZV466GOfBZiTjwmdT8li2DddaBzz6L9cmTY5RvSZKkYixaBN/4Btx4Y1K2666R9K6zTvM9biYD48dHYn3jjYWnCe3UCQ49NBLr/fe30qA1cuAzSVXnqaeSBLtfv2gCLkmSVKwuXaJ59vrrR1NxgAkTYPDgqFXecMPSPt6bb0Zifc01MHVq4X0GD47m4Ecd5Tgx1cIkW1LF+N//kuV99rHplCRJarx27eDPf44L9j/6UdQyv/56zKV9zz3RPHtVfPxx1FaPHl33ODIDB0Zi/fWvR1c3VReTbEkVI90fe999yxeHJEmqfKefDn37RvPsxYvho49gjz3g5pujuXZjLFkSNeGjR8Pdd8d6vh494OijI7neZRcrC6qZSbakijB3Ljz5ZCzX1MSckJIkSaviqKNiLu3hw+HTT2NO6oMPhn/+E048sf77ZjLw9NPRFPyGG2DOnJX36dAhpg8bORIOOiiaq6v6mWRLqggPP5yMvrnDDjHqpiRJ0qoaMiRGHj/gAHj33TjfOOmkmOLr179eucb5nXdiRPLRo6OZeSFf+lIk1kcfDb16Nf9zUOtiki2pIuT3x5YkSSqVLbeM/tMHHggvvBBlZ58dU3xddhksWAC33BKJ9bhxhY/Rr1/0sR4xIqYWVdtlki2pItgfW5IkNaf11os5tI88Mrm4/+9/R/L99tuwcOHK9+nWLfYfOTL6c7dr17Ixq3UyyZbU6k2dGlNgAHTtGvNZSpIklVr37jFw2cknR601wCuv1N6nXbtoVTdyJBx2WJybSGkm2ZJavXRT8T32gM6dyxeLJEmqbp06wahR0fz7vPOS8m23jcT62GOhT5+yhacKYJItqdWzP7YkSWpJNTXw299G67kXXoi+2tttV+6oVClMsiW1asuXw0MPJev2x5YkSS3lwAPjJjWGXfMltWqTJsW8lRADkmy5ZXnjkSRJkupjki2pVctvKp4/V6UkSZLUmphkS2rV0lN32R9bkiRJrZ1JtqRWa968mJsyZ++9yxeLJEmSVAyTbEmt1rhxsGxZLG+3HfTuXdZwJEmSpAaZZEtqtdL9sR1VXJIkSZXAJFtSq2V/bEmSJFUak2xJrdK778Lrr8dyly6w227ljUeSJEkqhkm2pFYp3VR8991htdXKF4skSZJULJNsSa1S/vzYkiRJUiUwyZbU6qxYAQ89lKw76JkkSZIqhUm2pFbnuedgzpxY7t0bttmmvPFIkiRJxTLJltTq5I8qXlNTvlgkSZKkxjDJltTq2B9bkiRJlcokW1KrMn8+jB+frJtkS5IkqZJ0KHK/LsBpwDDgC6ycnG9byqAktV2PPgpLl8by1ltDnz7ljUeSJElqjGKT7EuBw4GbgAlAptkiktSmpftjO6q4JEmSKk2xSfZhwFHAQw3tKEmrwv7YkiRJqmTF9sleAExvzkAk6f334ZVXYrlTJ9h99/LGI0mSJDVWsUn2H4EzACfSkdRs0rXYu+0GXbuWLxZJkiSpKYptLr4PMATYH3gVWJq3fXgpg5LUNqWTbPtjS5IkqRIVm2TPBm5rzkAktW0rVtgfW5IkSZWv2CT7hGaNQlKb9+KLMGtWLPfsCdtvX954JEmSpKYoNsnOGQhsSUzhNRl4u+QRSWqT0lN37b03tCt2xAhJkiSpFSk2ye4OXAEcAazIltUAtwAnAfNKH5qktsT+2JIkSaoGxdYV/RXYFtgTWC17G5Ytu6h5QpPUVixcCI89lqzbH1uSJEmVqtgkezjwTeARYmTxpcA44BTgsGaJTFKb8dhjsHhxLG+xBfTtW954JEmSpKYqNsleDZhToPxjoEvpwpHUFqX7Y9tUXJIkSZWs2CT7ceBcoGuqbHXgHGBCqYOS1LY4dZckSZKqRbEDn50OPAC8D7yYLdsGWADs1wxxSWojPvwwpu8C6NgR9tijvPFIkiRJq6LYJPtlYBPgOGDzbNk1wHXAwmaIS1Ib8dBDyfKuu0K3buWLRZIkSVpVjZknewHwr+YKRFLbZH9sSZIkVZP6kuyvAHcRI4l/pYHj3FqyiCS1GZmM/bElSZJUXepLsm8G1gVmZpfrkgHalzIoSW3Dyy9Hn2yAtdeGHXYobzySJEnSqqovyW5Xx7IklUS6FnvYMGjv5TpJkiRVuGKT590pnJC3z26TpEazP7YkSZKqTbFJ9sPA2gXKe2S3SVKjLFoEjz6arNsfW5IkSdWg2CS7huh7nW8dYH7pwpHUVjz+OCzMTgC46aawwQbljUeSJEkqhYam8Loz+zcDXAssTm1rD2wNTGiGuCRVuXRTcWuxJUmSVC0aSrLnZP/WAJ8AC1PblgDjce5sSU2QHvTM/tiSJEmqFg0l2Sdk/04D/oRNwyWVwMyZ8Nxzsdy+PQwdWtZwJEmSpJJpKMnOOadZo5DUpowZkyzvsgt0716+WCRJkqRSKjbJhqjVPgboD3TK2zawZBFJqnr2x5YkSVK1KnZ08Z8AFwLPAAOA24GXiWm9rmyWyCRVpUzG/tiSJEmqXsUm2ScDpwA/B5YCfweGE4m3E+9IKtrkyfD++7G85powaFB545EkSZJKqdgkuy/wVHZ5IZDrQXkDcESpg5JUvdK12MOGQYfGdFqRJEmSWrlik+wPgZ7Z5XeAXbLLGxNzaLeUtYHbiFHO3wGOrWffHYBHgc+Bj4DT8rafBkzNHmsysGlq27HZ488nmsavXYLYJVG7P7ZNxSVJklRtik2yxxLNwwGuAP4MPAz8F7i1GeKqyyXE/Ny9geOAy4CtCuzXE7gfuBxYh7gYkDq155vAScBBQDfgYGB2dttW2fuNyD7OAuDSEj8PqU1avBjGjUvWHfRMkiRJ1aYmkymqIrpd9rYsu340MBiYQiSkS5slutpWBz4Bts4+LsA1wPvAmXn7ng/0IxLlfO2IWurjgTEFtp9PDO6WqyXfiKjpXgeYV1dwgwYNykyaNKnhZyG1YePGwZ57xvJGG8Gbb5Y1HEmSJKloNTU1z2QymQZHFCq2JnsFSYINUYP9A2IAtJZIsCGacy8jSbABXqBwTfbOwMfABGAmcBcx9RhE//K+RLI+nWgyfg7Ja7FV9rg5bxG15+nm5ADU1NScUlNTM6mmpmbSrFmzmvaspDYk3R/bWmxJkiRVo2KT7FOBrxco/zrw3dKFU69uwGd5ZXOBNQrs2xf4BtHvuj+RSN+Q2gawL7ANsCcx//dJqceZW8zjZDKZf2YymUGZTGZQr169GvVkpLbI/tiSJEmqdsUm2T8kan3zTQNOL1k09fucZFTznO4UbsK9kBgg7WlgEVFTvSuwZnYbwB+BT4nncDlwYBMeR1KR5syBZ56J5XbtkmbjkiRJUjVpzBRe7xQof4+kZri5TQE6AJukyrYDXimw74vUHvU8vfw60fy7ru2vZI+bMxDoTO1m6pIaacwYyD3i0q0AACAASURBVA0BsdNO0KNHeeORJEmSmkNjpvDavkD5DiSjcje3+cRI5r8hBkEbDBxKDH6W7yrgcCLmjsCvgPFEs+8FRJ/ynxJNwPsCpwB3Z+97HXAIMCT7OL/JPq412dIqsD+2JEmS2oJik+zrgYuBfYiktSPRp/kiIiltKd8FViMGM7sB+A5R8zyEaOadMxb4BXBPdt+NqT2n9qnZ/WcAE4nnd2V22yvAt4nnNZNIxFuq37lUlTIZ+2NLkiSpbSh2Cq+OwGhi6q7l2bJ2wE3ENFktNcJ4q+UUXlLdpkyBzTaL5TXWiP7ZHTuWNyZJkiSpMYqdwqtDkcdbSozA/WuSZuPPA280LTxJbUm6FnuvvUywJUmSVL2KTbJz3sDEWlIjpZNs+2NLkiSpmtWXZF8M/JwYcOziBo7zg5JFJKmqLF0KDz+crNsfW5IkSdWsviR7G6IvNsC21J7mKq2oTt2S2qYnnoDPs8MSbrABbLxxeeORJEmSmlN9SfY3iCmvAIY2fyiSqlF66q5994WamvLFIkmSJDW3+qbwmgr0yi6PBXo0fziSqo39sSVJktSW1JdkzwN6ZpeHkjQdl6SifPIJPP10LNfUwLBh5Y1HkiRJam71NRd/iKjBnpxdvw1YUse+e5UyKEnVYexYWLEilgcNgrXXLm88kiRJUnOrL8keAZwIbAzsAbwOLGiJoCRVh/z+2JIkSVK1qy/JXghckl3eHvgR8GmzRySpaqT7Y5tkS5IkqS2oL8lO27NZo5BUdd56C6ZOjeXVV4eddy5vPJIkSVJLqC/Jvhj4OTA/u1yfH5QsIklVIV2Lveee0KlT+WKRJEmSWkp9SfY2JCOKb1PPfpnShSOpWqT7Yzt1lyRJktqK+pLsPetYlqR6LVsGY8Yk6/bHliRJUltR3zzZDdkY6FKqQCRVj6efhs8+i+W+fWGzzcobjyRJktRSik2yzwe+kV2uAf4HTAE+ABzOSFIt+aOK19SULxZJkiSpJRWbZB9HzJMNcAAxpdfOwGjgd80Ql6QKZn9sSZIktVXFTuHVG3gvu3wgcCPwFPAxMKkZ4pJUoebOhSeeiOWaGth77/LGI0mSJLWkYmuy5wAbZJf3BXJDGnUgmo9LEgDjxsHy5bH8xS9Cz55lDUeSJElqUcXWZN8CXE/0w14beCBbvj3wZjPEJalC5ffHliRJktqSYpPsM4B3gP7AT4H52fI+wGXNEJekCpVOsu2PLUmSpLam2CR7GXBhgfK/lDAWSRVu6lR4M9u2ZbXVYPDg8sYjSZIktbRi+2TvAeyUWj8eGA9cDnQrcUySKlR6VPE99oDOncsXiyRJklQOxSbZFwHrZpc3I5LrF4FdgAuaIS5JFSidZNsfW5IkSW1RsUn2xsBL2eUjgP8B3wVOBg5phrgkVZjly2HMmGTd/tiSJElqi4pNslcA7bPLw4D7s8sfAuuUOihJleeZZ+CTT2K5Tx/YaqvyxiNJkiSVQ7FJ9tPAr4ARwBDgvmz5AOCD0oclqdLkjypeU1O+WCRJkqRyKTbJ/iExJ/bfgfOAt7LlRwETmyEuSRXG/tiSJElS8VN4vQxsW6D8x8Dy0oUjqRLNmwcTJiTre+9dvlgkSZKkcio2ya7LopJEIamiPfIILFsWy9ttB717lzceSZIkqVwak2SfABwD9Ac65W0bWLKIJFWcdH9sm4pLkiSpLSu2T/ZPgAuBZ4jBzm4nmpCvDVzZLJFJqhjp/thO3SVJkqS2rNgk+2TgFODnwFJiALThROK9QfOEJqkSTJ8Or70Wy126wG67lTceSZIkqZyKTbL7Ak9llxcC3bPLNwBHlDooSZUjXYs9ZAistlr5YpEkSZLKrdgk+0OgZ3b5HWCX7PLGQKbUQUmqHPbHliRJkhLFJtljiebh8P/au/MwKcpzYeN3s4oguCGugAoGxQUVFVwQBTUmcTdqNCYaTxKNfnHXaNxNNJpo4lHjkiiu8RjXqPGoBxARxYWooEQOijtuCIiAbEJ/f7w1p2uaZqaHqZnq6r5/1zUX9VbVVD3daQlPv+/zFNwCXA08DdwLPNgCcUnKgGXLYOTIwth6bEmSJNW6cruL/4xCQn4jMBvYBXgAuKkF4pKUAa++CjNnhu0ePWCrrdKNR5IkSUpbuUn2suinzr3Rj6QaFq/HHj4c2pS7NkaSJEmqUg0l2ds14TqvNDcQSdljPbYkSZJUX0NJ9gRCU7NcI9fIA20Ti0hSJsyfD+PGFcbDh6cXiyRJklQpGkqyN261KCRlztixsGRJ2N5yS1h//XTjkSRJkipBQ0n2+60WhaTMiS8Vt6u4JEmSFDTWpmhL4FGga4lj3aJjmycdlKTKF296Zj22JEmSFDSWZJ8OTAK+KnFsDvAqcGbSQUmqbNOnw+TJYbtDBxgyJN14JEmSpErRWJJd9yzsFXkI2C25cCRlwciRhe1dd4VVV00vFkmSJKmSNJZk9wRmNnB8FrBhcuFIygLrsSVJkqTSGkuyZwObNnC8L/BlcuFIqnTLltWfybYeW5IkSSpoLMl+BjilgeOnAGOTC0dSpZs0CT7/PGyvvTYMGJBuPJIkSVIlaSzJ/h2wN6H2eidCR/FuwCDgYWB4dI6kGhHvKj58OLRp7G8RSZIkqYY09JxsgNeAQ4FbgeeLjs0EDiN0GJdUI+L12C4VlyRJkuprLMkGeAzoBXwb6APkgKnAU8DXLReapEqzYAE8+2xhbNMzSZIkqb5ykmyABYQl45Jq2LPPwqJFYXvzzWFDny0gSZIk1WM1paSyxeuxncWWJEmSlmeSLals1mNLkiRJDTPJllSWTz8Nj+8CaN8edt893XgkSZKkSmSSLaksI0cWtnfeGbp0SS8WSZIkqVKVm2S/A6xVYv/q0TFJVc56bEmSJKlx5SbZvYG2JfZ3BDZILBpJFSmftx5bkiRJKkdjj/A6OLb9XWBObNwWGAa8l3BMkirMG2+EmmyANdaA7bZLNx5JkiSpUjWWZN8f/ZkHbik6toSQYJ+ecEySKkx8qfjw4dC21LoWSZIkSY0m2XXLyd8FdgC+aNlwJFWi+FJx67ElSZKkFWssya6zcYtGIaliLVwIY8cWxibZkiRJ0oqV2/hsBKWXhZ8G/DW5cBq1JvAQMB94HziygXO3A8YC84DPgJNjx94DFkTH5gGxeTqOAZbGjs0DhiYQu5RJzz0HCxaE7b59oXfvVMORJEmSKlq5M9n7Av9ZYv9o4IzkwmnU9cBioAcwAPgnMBGYXHTe2sATwKmEuvIOwIZF5+wHjKS08cCuyYQsZVu8Htuu4pIkSVLDyp3JXp0wo1tsPmF2uTV0Bg4Bzo9iGQc8Ahxd4tzTgCeBu4FFwFzgzdYJU6ou1mNLkiRJ5Ss3yZ4KfKfE/u8CbycXToM2A76JYqkzEehf4txBwCzgeeBz4FGgZ9E5dwMzCEvFtyk6ti2hydtUQlJfcsY/l8v9LJfLTcjlchNmzJjRpBcjZcGMGfDqq2G7bVvYY49045EkSZIqXbnLxa8CbgTWISwRh/CM7FOAE1sgrlK6AF8V7ZsDrFbi3A0JNdl7Aa8DVwL3ALtEx48CXgFyhFrtJ4F+wJeEOu4tCTXf/YF7Ccn95cU3yefzNwM3AwwcODC/0q9MqlAjYwUVgwdD167pxSJJkiRlQbkz2bcTEuofAf8T/RxNWJY9omVCW848oPif+F0JS8GLLSA0SHsZWAhcDOwMdIuOPxed8zUhef4S2C069g7hkWXLCAn6JcChSb0IKUvi9dguFZckSZIaV+5MNsBN0U/3aNza66OnEuLtC7wV7duG5ZueAUwC4jPLjc0y5wmz2k09JlWtfL5+PbZNzyRJkqTGlTuTXWcgsCdhBhhCM7KmJOrNMR94kDCz3Jmw9PsA4M4S544ADiJ0IG9PqKseR1he3jP63Q7AKsCZhG7kz0W/uy+hezmEJeTnA/9I/NVIFW7KFJg+PWx36wYDB6YbjyRJkpQF5SbZPYAXgJeAv1FIQq8m1Gu3ll8AnQjNzO4BTiDMZO9G/e7no4FzCY/4+hzoQ+GZ2qsBNwCzgenAtwmJ9czo+DDCTPh84HFCYn9ZS70gqVLFZ7GHDYN2rfV1miRJkpRh5f6z+Y/AZ8BawAex/fcB1yYdVANmAQeW2P8soTFa3A3RT7HJwNYN3OMMWvfZ31JFsh5bkiRJarpyk+xh0c/sov3TWP7RWJIybvFiGDOmMLYeW5IkSSpPucvFOwGLS+zvTujeLamKjB8P8+eH7U02CT+SJEmSGldukj0WOCY2zgNtgbOBUQnHJClldhWXJEmSVk65y8XPAp4BdgA6Epqd9Sc8d3qXlglNUlqsx5YkSZJWTrkz2f8GtgKeB54iPPrqPmBbQl22pCoxcyZMmBC227SBPfdMNx5JkiQpS8qZyW4P/Ba4HriwZcORlLZRoyCfD9s77girr55uPJIkSVKWlDOTvYTwfOpcC8ciqQLEl4pbjy1JkiQ1TbnLxZ8EXDQqVbl8vn7TM+uxJUmSpKYpt/HZKOAyYGvgX8D8ouMPJhmUpHS89RZ88EHYXm012GmndOORJEmSsqbcJPu66M9fljhW9zgvSRkXn8XeYw9o3z69WCRJkqQsKjfJLndZuaQMsx5bkiRJap5ykuf2wIvAt1o4FkkpWrIEnn66MLYeW5IkSWq6cruLb0xYFi6pSr34IsydG7Z79YK+fdONR5IkScqicpeB3w78tCUDkZSueD323ntDzof2SZIkSU1Wbk12Z+AoYC9Kdxcv1RBNUobE67FdKi5JkiStnHKT7M2BV6LtTYqOuYxcyrjZs+Gll8J2LgfDhqUbjyRJkpRV5SbZe7RoFJJS9fTTsGxZ2B44ENZcM914JEmSpKwqN8muswrQhzB7PQ1YmHhEklpdcT22JEmSpJVTbuOz9sDvgdnAROD1aPvK6JikDLMeW5IkSUpGuTPZVwA/AI4HxkX7dgMuJyTqZyQfmqTWMG0avPNO2O7cGQYPTjceSZIkKcvKTbKPBH4CPB7bNw2YAfwVk2wps+Kz2EOHQocOqYUiSZIkZV65y8W7EZLqYtOA1ZMLR1Jrsx5bkiRJSk65SfZESj8L+2TgteTCkdSavvkGRo8ujK3HliRJkpqn3OXiZxGWig8HXoj2DQLWB/ZtgbgktYKXX4Y5c8L2hhtCv37pxiNJkiRlXbkz2WOBzYD7gS7Rz33Atyg0QpOUMfGl4nvtBblcerFIkiRJ1aApz8n+GPh1SwUiqfXFm55Zjy1JkiQ1X2Mz2VsCjwJdSxzrFh3bPOmgJLW8OXPghRcK42HD0otFkiRJqhaNJdmnA5OAr0ocmwO8CpyZdFCSWt6YMbB0adjebjvo3j3VcCRJkqSq0FiSvQvwQAPHHwJ2Sy4cSa2luB5bkiRJUvM1lmT3BGY2cHwWsGFy4UhqLdZjS5IkSclrLMmeDWzawPG+wJfJhSOpNbz3Hrz1Vtju1Al22SXVcCRJkqSq0ViS/QxwSgPHTyE83ktShsRnsXffHTp2TC8WSZIkqZo0lmT/DtibUHu9E6GjeDdgEPAwMDw6R1KGxOuxXSouSZIkJaex52S/BhwK3Ao8X3RsJnAYocO4pIxYuhRGjSqMbXomSZIkJaexJBvgMaAX8G2gD5ADpgJPAV+3XGiSWsK//gWzZ4ft9daD/v3TjUeSJEmqJuUk2QALCEvGJWVcvB57r70gl0svFkmSJKnaNFaTLanKWI8tSZIktRyTbKmGzJ0L48cXxsOHpxeLJEmSVI1MsqUa8swzsGRJ2N5mG+jRI914JEmSpGpjki3VkOJ6bEmSJEnJKrfxWVx/YCjQFhgHvJJkQJJajvXYkiRJUstq6kz2z4Gngd2BPYExwFkJxySpBXz4IUyZErY7doRdd003HkmSJKkaNTaT3R2YERv/Etga+DQa7wY8AFyZfGiSkhRfKj5kCHTqlF4skiRJUrVqbCb7JeCY2PhroF9svAXwVcIxSWoB8aXi1mNLkiRJLaOxmexdgeuAo4GfEmay7wPaR7/7TXRMUgVbtgxGjiyMrceWJEmSWkZjSfZ04CDgEOB/gL8AmwGbEmbB/xdY2JIBSmq+V1+FmTPD9jrrwFZbpRuPJEmSVK3KbXz2ALAt0Bt4DlgFmIgJtpQJxY/uauPD+yRJkqQWUc4jvL4DbE5Iqo8nLCG/FRgF/BqY32LRSUqE9diSJElS62hsPusqYASwA3ATcD7h2djbA3OAVwlJuKQKNX8+PPdcYWySLUmSJLWcxpLsYwhJ9BGERLuuydli4ELgQOCclgpOUvONHQuLF4ftLbeE9ddPNx5JkiSpmjWWZM8HNo62N2L5Gux/E56VLalCFddjS5IkSWo5jSXZ5wB3AB8DzxCWi0vKkHg9to/ukiRJklpWY43P7gaeADYB3gK+bPGIJCXm449h8uSw3aEDDBmSbjySJElStSunu/jM6EdSxsSXiu+6K6y6anqxSJIkSbXAp+VKVcx6bEmSJKl1mWRLVWrZsvpJtvXYkiRJUsszyZaq1Ouvw+efh+2114YBA9KNR5IkSaoFJtlSlYp3FR8+HNr4X7skSZLU4vxnt1SlrMeWJEmSWp9JtlSFFiyAsWMLY5NsSZIkqXWYZEtVaNw4WLQobPfrBxttlG48kiRJUq3IWpK9JvAQMB94HziygXO3A8YC84DPgJNjx94DFkTH5gFPFf3uqcCnwFfArUDH5ocutZ54PbZdxSVJkqTWk7Uk+3pgMdADOAq4Aehf4ry1gSeAm4C1gD4sn0jvB3SJfuJpyD7Ar4BhQC9gE+DixF6B1AriSbZLxSVJkqTWk6UkuzNwCHA+YfZ5HPAIcHSJc08DngTuBhYBc4E3y7zPj4FbgMnAbOBS4JhmxC21qk8/hUmTwnb79jB0aKrhSJIkSTUlS0n2ZsA3wNTYvomUnskeBMwCngc+Bx4FehadczcwgzDDvU1sf//ouvF79CDMiEsVb+TIwvbgwdClS3qxSJIkSbUmS0l2F0KNdNwcYLUS525ImJE+mZBcvwvcEzt+FNCbsBz8acKs9+qx+8wpugel7pPL5X6Wy+Um5HK5CTNmzGjKa5FaTPzRXdZjS5IkSa0rS0n2PKBr0b6uhKXgxRYQGqS9DCwk1FTvDHSLjj8XnfM1cDnwJbDbCu5Tt73cffL5/M35fH5gPp8f2L1796a+Hilx+bzPx5YkSZLSlKUkeyrQDugb27cNoXa62CQgHxvnS5xD0fFctD2Z+svHtyF0J5/ZlGClNEyeDJ98ErbXWAO23z7deCRJkqRak6Ukez7wIHAJoQnaLsABwJ0lzh0BHAQMANoTmqWNIyz97hn9bgdgFeBMQjfy56LfvQM4DtiCsIT8POC2Fng9UuLiXcWHD4e2bdOLRZIkSapFWUqyAX4BdCI0M7sHOIEw87wbYZl3ndHAucA/o3P7UHim9mqER3/NBqYD3wb2pTBT/QRwJaFW+wPC87gvbKkXJCXJpeKSJElSunL5fGMrqVWOgQMH5idMmJB2GKphCxfCmmvCggVh/O670Lt3qiFJkiRJVSOXy/0rn88PbOy8rM1kS1qB558vJNh9+5pgS5IkSWkwyZaqRLwe20d3SZIkSekwyZaqhPXYkiRJUvpMsqUqMGMGvPJK2G7bFvbYI914JEmSpFplki1VgVGjCtuDBkHXrunFIkmSJNUyk2ypCliPLUmSJFUGk2wp4/J567ElSZKkSmGSLWXclCnw0Udhu1s32GGHdOORJEmSaplJtpRx8VnsPfeEdu3Si0WSJEmqdSbZNWL8eHj33bSjUEuwHluSJEmqHCbZNeCuu2DoUNh/f/jqq7SjUZIWL4YxYwpj67ElSZKkdJlkV7kPP4TjjgvJ2BtvwJFHwtKlaUelpIwfD/Pnh+1NNoFNN003HkmSJKnWmWRXuY02gr/8pTD+5z/hV79KLx4lK75U3FlsSZIkKX0m2TXgRz+Cs88ujP/wB7j11vTiUXLiTc+sx5YkSZLSZ5JdIy67DA44oDA+/ngYOza9eNR8M2fChAlhu02b0FlckiRJUrpMsmtEmzahAdrWW4fxkiVw8MHwzjvpxqWVN3o05PNhe8cdYfXV041HkiRJkkl2TenSBR55BNZZJ4xnzoT99rPjeFb56C5JkiSp8phk15heveDhh6FDhzD+97/hBz+w43jW5PP167FteiZJkiRVBpPsGjR4MNxyS2H8+ONw1lnpxaOme+steP/9sL3aarDTTunGI0mSJCkwya5RP/whnHNOYXz11fDXv6YXj5omPou9xx7Qvn16sUiSJEkqMMmuYb/5DRx4YGF8wgkwZkxq4agJrMeWJEmSKpNJdg1r0wbuvBMGDAjjb76BQw6BadPSjUsNW7IEnn66MLYeW5IkSaocJtk1rq7jeI8eYTxrVug4PmdOunFpxV58EebODdu9ekHfvunGI0mSJKnAJFtstFHoON6xYxi/+SYcfniY2VblKe4qnsulF4skSZKk+kyyBcCgQXDrrYXxk0/CGWekF49WzHpsSZIkqXKZZOv/HHkk/PrXhfE118DNN6cXj5b35Zfw0kthO5eDPfdMNx5JkiRJ9Zlkq55LLoGDDy6MTzyxfpMtpWv0aFi2LGwPHAhrrZVuPJIkSZLqM8lWPW3awB13wLbbhnFdx/G33043LgXF9diSJEmSKotJtpbTuXPoOL7uumE8e3boOP7ll+nGJeuxJUmSpEpnkq2SNtwQ/vEPWGWVMJ4yxY7jaZs2Dd55J2x37gyDB6cbjyRJkqTlmWRrhXbcEUaMKIyfegpOOy29eGpdfKn40KHQoUNqoUiSJElaAZNsNeiII+CCCwrja6+FG29ML55aFl8qbj22JEmSVJlMstWoCy+EQw8tjE86KXS5Vuv55pv677n12JIkSVJlMslWo9q0gdtvh+23D+OlS0PSPXVqunHVkpdfhjlzwvYGG0C/funGI0mSJKk0k2yVZdVVQyO09dYL47qO47NnpxtXrYjXY++9N+Ry6cUiSZIkacVMslW2DTao33F86lQ47DBYsiTduGqBj+6SJEmSssEkW02yww5h6XidkSPh1FPTi6cWfPUVvPBCYTxsWHqxSJIkSWqYSbaa7LDD4KKLCuPrr4c//zm1cKre00+HOniA7baD7t3TjUeSJEnSiplka6VccAEcfnhh/MtfhlltJS9ej+2juyRJkqTKZpKtlZLLwYgRMHBgGC9dCt//Pvzv/6YbVzWyHluSJEnKDpNsrbROnUIjtPXXD+Mvvwwdx2fNSjeuavLee/DWW2G7UyfYZZdUw5EkSZLUCJNsNcv668Mjj4QEEEJC+P3v23E8KfGl4rvvDh07pheLJEmSpMaZZKvZtt8e7rijMB49OtRo5/PpxVQtrMeWJEmSssUkW4k49FC45JLC+MYbQ9dxrbylS+s3k7MeW5IkSap8JtlKzHnnwRFHFMYnn1y/aZea5pVXYPbssL3eetC/f7rxSJIkSWqcSbYSk8vBrbfCjjuG8bJl4ZnaU6akG1dWxb+g2Guv8P5KkiRJqmwm2UpUp07w8MOw4YZhPGcOfO97MHNmunFlkfXYkiRJUvaYZCtx660XOo6vumoYT5sWarbtOF6+uXPh+ecL4+HD04tFkiRJUvlMstUitt0W7ryzMB4zBk46yY7j5XrmmcKXEltvDeuum248kiRJkspjkq0Wc/DB8JvfFMY33wzXXptePFkSXypuV3FJkiQpO0yy1aLOPReOPLIwPvVUeOKJ9OLJiuKmZ5IkSZKywSRbLSqXg1tugZ12CuNly+Dww+HNN9ONq5J9+GGhI3vHjrDbbunGI0mSJKl8JtlqcausEjqOb7RRGH/1lR3HGxJfKr7bbqFjuyRJkqRsMMlWq1h33fodx995Bw45BBYvTjeuSmQ9tiRJkpRdJtlqNQMGwN13F8bPPAMnnmjH8bhly2DkyMLYJFuSJEnKFpNstaoDD4TLLy+M//pXuOaa9OKpNK+9Bl98EbbXWQe22irdeCRJkiQ1jUm2Wt3ZZ8PRRxfGp58Ojz+eXjyVpLireBv/C5UkSZIyxX/Cq9XlcuGZ2YMHh/GyZXDEETB5crpxVYJ4PbaP7pIkSZKyxyRbqVhlFXjoIejZM4znzoX99issla5FX38N48YVxibZkiRJUvaYZCs1PXrAo49C585h/O67cPDBtdtxfOzYwmvv3x/WXz/deCRJkiQ1nUm2UrX11vC3v4Ul5ADPPgvHH1+bHcfj9dh2FZckSZKyySRbqdt/f/jd7wrjESPg6qvTiyct1mNLkiRJ2Ze1JHtN4CFgPvA+cGQD524HjAXmAZ8BJ5c4Z3cgD/wmtu8YYGn0e3U/Q5sXthpz5pnwox/VHz/2WHrxtLaPP4Y33gjbHTrAkCHpxiNJkiRp5WQtyb4eWAz0AI4CbgD6lzhvbeAJ4CZgLaAP8FTROe2Ba4AXS/z+eKBL7GdM80NXQ+o6ju+ySxjn8/CDHxQSz2o3cmRhe5ddCnXqkiRJkrIlS0l2Z+AQ4HzC7PI44BHg6BLnngY8CdwNLALmAm8WnXM6IfGe0kLxqok6doQHH4RevcJ43rzQcXzGjHTjag3WY0uSJEnVIUtJ9mbAN8DU2L6JlJ7JHgTMAp4HPgceBXrGjvcCfgJcsoJ7bQt8Ed3rfKBdcwJX+dZZJ3Qc79IljN97L3QcX7Qo1bBa1LJl9WeyrceWJEmSsitLSXYX4KuifXOA1UqcuyHwY0Iddk/gXeCe2PH/pDAjXmwssCWwDmHm/AfAmaUCyuVyP8vlchNyudyEGbUw3dpKttoK7rmn0HF83Ljq7jj++uvw2Wdhe621YNtt041HkiRJ0srLUpI9D+hatK8rYSl4sQWEBmkvAwuBi4GdgW7AfoTE/N4V3OcdQlK+DHidMNt9aKkT8/n8zfl8fmA+nx/YvXv3Jr0YNex734MrryyMb7sN/vCH1MJpUfGl4sOHQ5ss/VcpsNMfmgAAFm5JREFUSZIkqZ4s/XN+KmHZdt/Yvm2AySXOnUToGl4nvj0MGAh8Gv0cDpwC/GMF980DuZULWc1x+ulw7LGF8dlnh6Xk1Sb+6C7rsSVJkqRsy1KSPR94kDCz3BnYBTgAuLPEuSOAg4ABhC7i5xMapc2JtjeLjg0gNE/7C1CXzu1L6F4O0C86f0UJuFpQLgc33AC77hrG+TwceSRMmpRuXElasADGji2MrceWJEmSsi1LSTbAL4BOhGZm9wAnEGayd6N+ffVo4Fzgn9G5fSg8U3suhVnsTwlLy+cTGqVBmOmeFO17nJDYX9ZSL0gNq+s43rt3GNd1HK+rYc66ceMKTd369YONNko3HkmSJEnNk7Wu2bOAA0vsf5bQGC3uhuinMccUjc+IflQhuncPy8R33hnmzoUPPggdx0ePDkl4lsXrsZ3FliRJkrIvazPZqlFbbgn/9V+FpmDPPw8/+1n2O45bjy1JkiRVF5NsZcZ3vgO//31hfMcd9TuQZ81nn8HEiWG7fXsYOjTVcCRJkiQlwCRbmXLqqXDccYXxOefAPzLalm7kyML24MHQpbjgQZIkSVLmmGQrU3I5+POfYciQMM7n4aijCjPCWRKvx3apuCRJklQdTLKVOR06wAMPwCabhPH8+aHj+KefphtXU+Tz9euxbXomSZIkVQeTbGXS2muHjuNdu4bxhx/CQQfBwoXpxlWuyZPhk0/C9hprwPbbpxuPJEmSpGSYZCuzttiifsfxF16An/40Gx3H47PYw4ZB27bpxSJJkiQpOSbZyrR994WrriqM77oLfve79OIpl/XYkiRJUnUyyVbmnXxymMGuc+658OCD6cXTmEWL4JlnCmPrsSVJkqTqYZKtzMvl4Lrr6j9n+uij4dVXUwupQc89BwsWhO2+faF371TDkSRJkpQgk2xVhQ4d4P77YdNNw/jrr2H//Suz47hdxSVJkqTqZZKtqrHWWvU7jn/0ERx4YGHWuFJYjy1JkiRVL5NsVZXNN4e//73QcfzFF+G44yqn4/iMGYVl7G3b1l/iLkmSJCn7TLJVdfbZB/70p8L4nnvgssvSiydu1KhCwj9oEHTrlm48kiRJkpJlkq2qdNJJ8POfF8bnnQcPPJBePHXiS8Wtx5YkSZKqj0m2qlIuB9deC3vuWdh39NHwyivpxZTP1296Zj22JEmSVH1MslW12reH++6DPn3CeMGC0HH8k0/SiWfKlNCMDcIy8R12SCcOSZIkSS3HJFtVbc014bHHCrXP06fDAQek03E8Pou9557Qrl3rxyBJkiSpZZlkq+p961thRrtt2zB++WU49tjW7zhuPbYkSZJU/UyyVRP22guuuaYwvvdeuPTS1rv/4sUwZkxhbD22JEmSVJ1MslUzTjwRfvGLwvjCC8MMd2sYPx7mzw/bm2wCm27aOveVJEmS1LpMslVT/vQnGDasMP7xj2HChJa/b7we26XikiRJUvUyyVZNqes4vtlmYbxgQWiENn16y943Xo/tUnFJkiSpeplkq+assQY8+iisvnoYf/wxHHggfP11y9xv1qzCbHmbNvWf3S1JkiSpuphkqyZttln9juMTJsAxx8CyZcnfa9SoQifzHXcsJPeSJEmSqo9JtmrW8OFw7bWF8X33wSWXJH8f67ElSZKk2mGSrZp2wglw0kmF8cUXh8d7JSWftx5bkiRJqiUm2ap5f/xj/eT3mGPg5ZeTufbbb8P774ft1VaDnXZK5rqSJEmSKpNJtmpeu3Zh9vpb3wrjhQtDx/GPPmr+teOz2HvsEbqbS5IkSapeJtkSoRnZo4+GzuMAn3wSEu3585t3XeuxJUmSpNpiki1F+vaFBx4IM9sAr7zSvI7jS5bA6NGFsfXYkiRJUvUzyZZi9tgDrruuML7/frjoopW71ksvwdy5Ybtnz5DES5IkSapuJtlSkZ//HH75y8L40kvhnnuafp3iruK5XPNjkyRJklTZTLKlEq66CvbZpzA+9lh48cWmXSOeZFuPLUmSJNUGk2yphLqO4/36hfGiRXDggfDhh+X9/pdfhuXiEGawhw1rmTglSZIkVRaTbGkFunULHcfXXDOMP/0U9t+/vI7jo0cXGqZtvz2stVbLxSlJkiSpcphkSw3o06d+x/HXXoMf/ajxjuPxR3fZVVySJEmqHSbZUiOGDoUbbiiMH3wQLrig4d+xHluSJEmqTSbZUhn+4z/glFMK49/+Fu6+u/S506bBO++E7c6dYfDglo9PkiRJUmUwyZbK9Pvfw777FsbHHQcvvLD8efGl4kOHQseOLR6aJEmSpAphki2VqV278LzsLbYI47qO4x98UP+8eJLtUnFJkiSptphkS01Q13G8rlv4Z5+FjuPz5oXxN9/AqFGF8216JkmSJNUWk2ypiTbZJDQ/a98+jCdOhKOPDh3HJ0yAOXPC/g02KDxnW5IkSVJtMMmWVsKQIfU7jj/8MJx3Xv2u4nvvDblc68cmSZIkKT3t0g5AyqrjjoM334Srrgrjyy+HtdcuHLceW5IkSao9zmRLzXDFFfDd7xbGX3xR2B4+vPXjkSRJkpQuk2ypGdq2hb/9Dfr3r79/222he/d0YpIkSZKUHpNsqZm6dg0dx10qLkmSJMkkW0rAxhvDI49Az57Qpw+cckraEUmSJElKg43PpIQMHgzvvgtt/OpKkiRJqlmmA1KCTLAlSZKk2mZKIEmSJElSQkyyJUmSJElKiEm2JEmSJEkJMcmWJEmSJCkhJtmSJEmSJCXEJFuSJEmSpISYZEuSJEmSlBCTbEmSJEmSEmKSLUmSJElSQkyyJUmSJElKiEm2JEmSJEkJyVqSvSbwEDAfeB84soFztwPGAvOAz4CTS5yzO5AHflO0/1TgU+Ar4FagY7OiliRJkiTVhKwl2dcDi4EewFHADUD/EuetDTwB3ASsBfQBnio6pz1wDfBi0f59gF8Bw4BewCbAxcmEL0mSJEmqZllKsjsDhwDnE2anxwGPAEeXOPc04EngbmARMBd4s+ic0wmJ95Si/T8GbgEmA7OBS4FjkngBkiRJkqTqlqUkezPgG2BqbN9ESs9kDwJmAc8DnwOPAj1jx3sBPwEuKfG7/aPrxu/RgzAjXk8ul/tZLpebkMvlJsyYMaP8VyJJkiRJqkpZSrK7EGqk4+YAq5U4d0PCjPTJhOT6XeCe2PH/pDAjXuo+c4ruQan75PP5m/P5/MB8Pj+we/fu5bwGSZIkSVIVa5d2AE0wD+hatK8rYSl4sQWEBmkvR+OLgS+AbsAQQsJ8b5n3qdsudR9JkiRJkv5PlpLsqYR4+wJvRfu2IdROF5tE6BpeJ749DBhI6B4OIfFeCmwFHBBdbxvg77F7fAbMbPYrkCRJkiRVtSwtF58PPEioo+4M7EJIiu8sce4I4CBgAKGL+PmERmlzou3NomMDCM3T/gIcG/3uHcBxwBbA6sB5wG0t8HokSZIkSVUmSzPZAL8gPLf6c8LM8gmEmefdgP8m1FMDjAbOBf4JrEpIsOueqT2X+ku/FxAS+FnR+AngSuBpoBPwAHBhY4H961//+iKXy72/kq9L1WVtQnmCVA38PKva+JlWNfHzrGqShc9zr3JOyuXz+cbPklS2XC43IZ/PD0w7DikJfp5VbfxMq5r4eVY1qabPc5aWi0uSJEmSVNFMsiVJkiRJSohJtpS8m9MOQEqQn2dVGz/TqiZ+nlVNqubzbE22JEmSJEkJcSZbkiRJkqSEmGRLkiRJkpQQk2wpGR2BW4D3Cc9hfw3YN9WIpGT0BRYCd6UdiJSAI4A3gfnANGC3dMORVlpv4HFgNvApcB3QLs2ApCY4CZgALAJuKzo2DJgCfA08TZnPpa40JtlSMtoBHwK7A92A84C/E/5PUMqy64GX0w5CSsBewBXAscBqwBDgnVQjklben4HPgfWAAYR/f/wi1Yik8n0M/Aa4tWj/2sCDwPnAmoRE/N7WDS0ZJtlSMuYDFwHvAcuAx4B3ge3TC0lqtiOAL4FRaQciJeBi4BLgBcLf09OjHymLNiZ8mb+QMJP9BNA/1Yik8j0IPAzMLNp/MDAZuI/w2b4I2Abo15rBJcEkW2oZPYDNCH9RSFnUlZCQnJZ2IFIC2gIDge7A28BHhOW1ndIMSmqGPxG+CF0V2IBQovZEqhFJzdcfmBgb15X2ZO4LJJNsKXntgbuB2wk1JVIWXUroM/BR2oFICehB+Lv5UEId9gBgW0Jpj5RFYwmJx1eEv6cnEGYGpSzrAswp2jeHUOKTKSbZUrLaAHcCiwlNHaQsGgAMB/6YdiBSQhZEf14LfAJ8AVwNfCe1iKSV14Ywa/0g0JlQx7oGoeeAlGXzCCvp4roSmgpnikm2lJwcYeavB3AIsCTdcKSVNpTQtO8DQq3fGYTP9CvphSQ1y2zCbF8+ti+/gnOlSrcm0JNQ8rCIUNc6Ar80UvZNJtRg1+kMbEoGyy9NsqXk3ABsDuxHYdZEyqKbCf+nNiD6uRH4J7BPmkFJzTQC+H/AOoRZv1MJTSqlrPmC0Fz1BMLTTVYHfgxMSjMoqQnaAasQ+mW0jbbbAQ8BWxK+2F8FuIDwuc5c+aVJtpSMXsDPCQnJp4TlLvOAo9IMSlpJXxM+x3U/8whdPmekGZTUTJcSHkc3lfCs7FeB36YakbTyDga+Tfh7+W3C6rlTU41IKt95hAmpXwE/jLbPI3yeDyH83Twb2InQ4C9zcvm8q6UkSZIkSUqCM9mSJEmSJCXEJFuSJEmSpISYZEuSJEmSlBCTbEmSJEmSEmKSLUmSJElSQkyyJUmSJElKiEm2JEmSJEkJMcmWJEmSJCkhJtmSJEmSJCXEJFuSJEmSpISYZEuSJEmSlBCTbEmSJEmSEmKSLUmSJElSQkyyJUmSJElKiEm2JEmSJEkJMcmWJEmSJCkhJtmSJEmSJCXEJFuSJEmSpISYZEuSJEmSlBCTbEmSJEmSEmKSLUmSJElSQkyyJUmSJElKiEm2JElNcxvwWNpBFDkAeAv4hhBfKasC9wNzgDzQuzUCqxJjgOvSDmIFzgDeSzsISVKBSbYkKUtuIySI5xftHxrtX7uV46kUtwAPAL2Ak1dwzk+AIcCuwHrAhwnd+zYq70uHSncbvmeSVLVMsiVJWbMQOBPonnYgCWu/kr+3OrAW8CQwnTBTXUof4E3gdeBTYOlK3q8lrex7IElSxTDJliRlzdOE5bHFs9lxQ1l+Zrt3tG9g0Tn7Av8CFgDPAhsCuwMTgXmEGce1StzjPOCz6JwRQKfYsRxwFjAtuu7rwA9LxPIDYHR0zs9X8FrWAG4HZkfnjQT6x17D7Gh7dHTNoSWuMYYwwz0kOmdMtL8DcAXwEfA18DKwT+z32hJmyd+N7v1W9Lrq/v1wEfBj4LvRdevuX/f6BlJfHjg02q47p9R7sDPwTBTTdOAGoGvsOkOAFwjv/RzgJWDLEq+7zsHApOges6Jr94gd34/wGVgYvdbfEt6bFWnsfQPoBzwSxTcPGA9sxYrfM4ANgP8i/G86G/gn0LfoumcRviSZB9wBdGkgTklSCkyyJUlZswz4FXA8sGkC17sYOAXYiZDQ3gtcAPyMkPz0JyRGcbsD2wDDgEOAvQlJV53fAMcBJwJbAJcDNxESq7jLgT9H5zy8gvhui2I7ANiRkNQ9QUjqn6eQcB9CWAb+fIlrHEz4ImB8dM7B0f4R0Ws5kpCk3g48Gr02CP9OmA4cBmwO/Bo4Fzg2Ov4H4O+ExH+9Bu7fkOL3YCvgKUKCuk0U6wDg1uj8dsA/gHHR8Z2AP7Himfl1CYnr7dFrGALcGTu+D3A3oea6P2FZ/aHAZQ3E3Nj7tn4UXx7YC9gOuJ7wpcWK3rNVCV8gLYyuPRj4JDpv1ei6hxE+WxdG1/xf4LQG4pQkpaBd2gFIkrQSHgeeI8w4HtHMa51PmMEGuBG4FtgeeCXadzuF2dc6SwmJ5jzgDeBswozvOdHx0wiJd9113yUkyCcSZifrXEtoRrYifYH9CUnX2Gjf0cAHwFHAX4HPo/2zCDOcpcwiJOeLY+dsSphF7h1dD0KiOZwwo/wLYAnhC4c67xGSux9Er3ceYXZ4UQP3bkzxe3AZ4YuOq2L7TgBeBdYhNHdbnZDUTouOT2ng+usTlqHfD7wf7XsjdvzXwO8JiTPRNc8G7iKUJeSLrlfO+3YiMB/4PuE9B5gau0ap9+yHhBUQx8bu+XPC/77fIyTmpxA+jzdFx38L7EEoBZAkVQiTbElSVp1NmJn9fTOvMym2/Vn05+tF+9Yp8TvzYuPxhCXEmwIdgVUIs83xBK09y3eBntBIbJsTZu7Hx/bNieLbopHfbcx2hKTu30X7OxKWb9c5HvgPQlO1ToTX8T7JKX4PtickjYfH9uWiPzclvBe3EWrQR0U/91NIeItNJMwGv0GYIR8ZnT8jdr8dCZ+nOm0Ir3VdwmxyXDnv27aEmezFlG97YGNgbtH+VSms2Nic8MVK3HhMsiWpophkS5Ky6iVCR+0rgUuLji2L/szF9q2oqdaS2HZ+BfuaUl5Vd+5+LJ/4LSkaz2/CdYsVz7A2VZvoGjuwfFwLoj8PJyzFPoOwpPkrwiztQY1cuynvf/F70IaQSP6xxLnToz+PjeL6NmGm/7fAgYTEu9hSwqqCQdGfxxGWqNfV3bchlAzcV+J3Z5TYV877tjLaAK9RemXGrGZcV5LUykyyJUlZdi5hRvHbRfvrkqP1YtsDErzvVkBnCgniIMKs5TRCsrSIMPM7uuRvl+/N6HqDKSwX7xrdf8SKfqlMrxKS4HUJtcCl7Aq8SP1nRBfXwS8m1BrHxd//OuW+/68QaqPfbuS8idHPFcB/E5qJlUqyISTF46OfS4DJhC8QJkb361fG/eqU8769Slj+3YHSs9ml3rNXCMvQvwC+XMF13yR81m6N7RtUVtSSpFZj4zNJUpa9DdzM8s+GfpvwHOiLgM0IM5jnJXjfdoREpz+hsdXvgL8Qku65hOZWfyA00epDSDCPJzRTa4q3CE2+bgJ2IyTXdxFmlP/WzNcwldDw6zZCzfkmhG7gZ1BojDaVsDx6X0J9+PmEGeC49wjNv75F6ObenjCj+wJhCXZ/QrfwP5QZ1xWE5ds3EpZd9yHUJNfVIW9MeL93JnyRsQewNcsv364ziPC//Q5AT8LM90ax8y8hNDC7JHod/Qjvx5UruF4579ufCV2//x7dtw8hga77ouE9ln/P7iaUJvyD8B5vTGjSdhWFDuPXEL5M+Gm07xxC4zdJUgUxyZYkZd0lhGZYcUsIy243IcxWXkyY9U7KM4TZ0KeBhwgz1mfFjp9PSPDPiM77H0L373dX4l7HEpbGPxL9uSph5r45S5Pj1x5BSCinEB5XNoRCzfVNhETxb4THVPWmfkMyCF8uvEmorZ4B7BLt/0n058vRdcr9kmNSFENvwvs8kbC8u65e/mvCFyf3ERLe2wkJ6hXFF4rMiWJ6jPClxVWE8oK7ouNPErq+70F4f18idK9fUY03NP6+TY/GHQifkVeB/0fhc1rqPfs6+p13otc2JXpta1B4TNu9hM/Vb6NrbgVc3UCckqQU5PL55pZ0SZIkSZIkcCZbkiRJkqTEmGRLkiRJkpQQk2xJkiRJkhJiki1JkiRJUkJMsiVJkiRJSohJtiRJkiRJCTHJliRJkiQpISbZkiRJkiQlxCRbkiRJkqSE/H9jcgfZmGvhVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f529b734a90>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## RFE - view accuracy plot for 'no of vars' (vars not in order)\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, \n",
    "          fontweight='bold', color='w')\n",
    "plt.xlabel('Number of features selected', fontsize=14, labelpad=20, color='w')\n",
    "plt.ylabel('% Correct Classification', fontsize=14, labelpad=20, color='w')\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='b', linewidth=3)\n",
    "plt.xticks(fontsize=12, color='w')\n",
    "plt.yticks(fontsize=12, color='w')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 1 3 1 5 1 4]\n",
      "['Length' 'Diameter' 'Height' 'Whole_weight' 'Shucked_weight'\n",
      " 'Viscera_weight' 'Shell_weight' 'Sex_F' 'Sex_I' 'Cat_2_val1']\n"
     ]
    }
   ],
   "source": [
    "# RFE - Insignificant Vars\n",
    "print(rfecv.ranking_) # values >= 2 means insignificant var\n",
    "print(df2_ind_vars.columns.values) # view all corresponding vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insig. Vars identified by REF, not removed: ['Height', 'Sex_F', 'Sex_I', 'Cat_2_val1']\n",
      "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
      "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell_weight  Target  Sex_F  Sex_I  Cat_2_val1  \n",
      "0         0.150       0      0      0           1  \n",
      "1         0.070       0      0      0           1  \n",
      "2         0.210       1      1      0           1  \n",
      "3         0.155       1      0      0           1  \n",
      "4         0.055       0      0      1           1  \n"
     ]
    }
   ],
   "source": [
    "## Drop Vars (marked insignificant by RFE)\n",
    "if Remove_RFE_Vars == 'Y':\n",
    "    drop_vars = [df2_ind_vars.columns.values[i] for i,x in enumerate(rfecv.ranking_) if x>1]\n",
    "    df2 = df2.drop(drop_vars,axis=1)\n",
    "    print(\"Insig. Vars identified by REF, removed: {}\".format(drop_vars))\n",
    "    print(df2.head())\n",
    "else:\n",
    "    print(\"Insig. Vars identified by REF, not removed: {}\".format(drop_vars))\n",
    "    print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################### PCA (Principal Component Analysis) ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1767,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applied later (as to be applied post Train-Val-Test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "############# Train-Vald-Test Split ##############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2912\n",
      "651\n",
      "614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70:15:15\n",
    "\n",
    "df = df2.copy()\n",
    "\n",
    "np.random.seed(4)\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "\n",
    "# Train set\n",
    "Train = df[msk]\n",
    "\n",
    "Vald_Test = df[~msk]\n",
    "msk = np.random.rand(len(Vald_Test)) < 0.5\n",
    "\n",
    "# Vald and Test sets\n",
    "Vald = Vald_Test[msk]\n",
    "Test = Vald_Test[~msk]\n",
    "\n",
    "# QC\n",
    "print(len(Train))\n",
    "print(len(Vald))\n",
    "print(len(Test))\n",
    "len(Train)+len(Vald)+len(Test) == len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "########### Separate X & Y of all datasets ############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1769,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0    1600\n",
      "1    1312\n",
      "dtype: int64\n",
      "0    354\n",
      "1    297\n",
      "dtype: int64\n",
      "0    332\n",
      "1    282\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antrived/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/antrived/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/antrived/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "X_Train = Train.drop(['Target'], axis=1)\n",
    "Y_Train = Train[[\"Target\"]]\n",
    "X_Train = X_Train.as_matrix()\n",
    "Y_Train = np.asarray(Y_Train).flatten()\n",
    "\n",
    "X_Vald = Vald.drop(['Target'], axis=1)\n",
    "Y_Vald = Vald[[\"Target\"]]\n",
    "X_Vald = X_Vald.as_matrix()\n",
    "Y_Vald = np.asarray(Y_Vald).flatten()\n",
    "\n",
    "X_Test = Test.drop(['Target'], axis=1)\n",
    "Y_Test = Test[[\"Target\"]]\n",
    "X_Test = X_Test.as_matrix()\n",
    "Y_Test = np.asarray(Y_Test).flatten()\n",
    "\n",
    "# QC\n",
    "print(len(X_Train)+len(X_Vald)+len(X_Test) == len(df2))\n",
    "print(pd.value_counts(Y_Train))\n",
    "print(pd.value_counts(Y_Vald))\n",
    "print(pd.value_counts(Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "############# Mean Standardization ##############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1770,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_Train = sc.fit_transform(X_Train)\n",
    "X_Vald = sc.transform(X_Vald)\n",
    "X_Test = sc.transform(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "######### Feature Selection/Reduction - V2 ##########\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########### PCA (Principal Component Analysis) ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1771,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER_INPUT\n",
    "Apply_PCA = 'N' # 'Y'/'N'\n",
    "variance_thresh = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ind. Vars.: 10\n",
      "PCA not applied\n"
     ]
    }
   ],
   "source": [
    "# Applying PCA function on training \n",
    "# and testing set of X component \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "print(\"Number of Ind. Vars.: {}\".format((len(X_Train[0]))))\n",
    "\n",
    "if Apply_PCA == 'Y':\n",
    "    for i in range(len(X_Train[0])):\n",
    "        if i == len(X_Train[0])-1:\n",
    "            break\n",
    "        pca = PCA(n_components = i+1) \n",
    "        X_Train_PC = pca.fit_transform(X_Train)\n",
    "        X_Vald_PC = pca.transform(X_Vald) \n",
    "        X_Test_PC = pca.transform(X_Test)\n",
    "        explained_variance = pca.explained_variance_ratio_ \n",
    "        if sum(explained_variance) >= variance_thresh:\n",
    "            break\n",
    "            \n",
    "    X_Train = X_Train_PC.copy()\n",
    "    X_Vald = X_Vald_PC.copy()\n",
    "    X_Test = X_Test_PC.copy()\n",
    "\n",
    "    print(\"Number of Principal Components: {}\".format(len(explained_variance)))\n",
    "    print(\"Total Variance Explained: {}\".format(sum(explained_variance)))\n",
    "else:\n",
    "    print(\"PCA not applied\")\n",
    "\n",
    "# does not generally work for lesser no of variables, but works for very high number \n",
    "    # like 200+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################\n",
    "############# XGBoost (Binary) ##############\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######\n",
    "####### Training (Base Model) & Validation\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification related packages\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def common_predictions(model, X_test, Y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.astype(int)\n",
    "#     y_pred[y_pred > 0.5] = 1\n",
    "#     y_pred[y_pred <= 0.5] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1774,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "from xgboost import XGBClassifier\n",
    "def xgb_classifier(X_Train, Y_Train, max_depth, learning_rate, n_estimators, objective):\n",
    "    model = XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, \n",
    "                          n_estimators=n_estimators, objective=objective)\n",
    "    model.fit(X_Train, Y_Train)\n",
    "    return model\n",
    "\n",
    "# multi-class classification\n",
    "model = xgb_classifier(X_Train, Y_Train, max_depth=8, learning_rate=0.001, \n",
    "                       n_estimators=200, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1775,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction (class)\n",
    "y_pred = common_predictions(model, X_Vald, Y_Vald)\n",
    "\n",
    "## Prediction (probabilities)\n",
    "    # use 'predict_proba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221  85]\n",
      " [133 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       354\n",
      "           1       0.61      0.71      0.66       297\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       651\n",
      "   macro avg       0.67      0.67      0.67       651\n",
      "weighted avg       0.67      0.67      0.67       651\n",
      "\n",
      "first_class_f1: 0.67\n",
      "last_class_f1: 0.66\n",
      "micro_f1: 0.67\n",
      "macro_f1: 0.67\n",
      "wtd_f1: 0.67\n"
     ]
    }
   ],
   "source": [
    "## Validation Accuracy\n",
    "cm1 = confusion_matrix(y_pred, Y_Vald)\n",
    "print(cm1)\n",
    "print(classification_report(Y_Vald, y_pred))\n",
    "# Micro Avg = Avg like this: P=(Match_1+Match_2+Match_3)/(Actual_1+Actual_2+Actual_3)\n",
    "# Macro Avg = Avg of (P,R) for individual classes\n",
    "# Weighted Avg = f-score weighted on support\n",
    "\n",
    "    # Micro vs Macro Avg - 1 literature said micro is good for \n",
    "        # skewed multi-class classification(its wrong info); but in one experiment \n",
    "        # on skewed data, micro-avg was giving incorrect picture and macro was much better\n",
    "        # so, macro-avg is the best indicator for skewed data\n",
    "    # Macro Avg best for Skewed data - best for skewed data for both binary and \n",
    "        # multi-class classification as it gives equal weightage to classes \n",
    "        # irrespective of their occurance (if all classes are importance)\n",
    "\n",
    "    # Ref: https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
    "    \n",
    "# get micro_f1, macro_f1, weighted_f1 (use to optimize params)\n",
    "temp = classification_report(Y_Vald, y_pred)\n",
    "list1 = temp.split()\n",
    "\n",
    "first_class_f1 = list1[7]\n",
    "last_class_f1 = list1[len(list1)-20]\n",
    "micro_f1 = list1[len(list1)-14]\n",
    "macro_f1 = list1[len(list1)-8]\n",
    "wtd_f1 = list1[len(list1)-2]\n",
    "\n",
    "print(\"first_class_f1: {}\".format(first_class_f1))\n",
    "print(\"last_class_f1: {}\".format(last_class_f1))\n",
    "print(\"micro_f1: {}\".format(micro_f1))\n",
    "print(\"macro_f1: {}\".format(macro_f1))\n",
    "print(\"wtd_f1: {}\".format(wtd_f1))\n",
    "\n",
    "# use micro_f1 for skewed multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f529b5e2320>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot Confusion Matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    plt.figure(figsize=[7, 6])\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)\n",
    "        plt.savefig('confusion-matrix.png')\n",
    "\n",
    "plot_confusion_matrix(cm1, ['8', '15'])\n",
    "# ref: https://github.com/gabrielziegler3/xgboost-multiclass-multilabel/blob/master/xgboost-multiclass-multilabel/multiclass-classification-examples.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######\n",
    "####### Hyper-Param Tuning (K-fold CV) - Grid/Random Search\n",
    "####### 1st Approach - Recommended\n",
    "####### (easily extensible to other algorithms)\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1778,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "from xgboost import XGBClassifier\n",
    "def xgb_classifier(X_Train, Y_Train, max_depth, learning_rate, n_estimators, objective):\n",
    "    model = XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, objective=objective)\n",
    "    model.fit(X_Train, Y_Train)\n",
    "    return model\n",
    "\n",
    "# multi-class classification\n",
    "clf = xgb_classifier(X_Train, Y_Train, max_depth=12, learning_rate=0.05, \n",
    "                       n_estimators=100, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.9366267 , 1.03071048, 0.61588416, 0.23185661, 1.09189107,\n",
      "       0.43744645, 2.35396323, 0.91454961, 0.60839   , 0.23397107,\n",
      "       0.23725412, 1.96131179, 0.80777464, 1.02693613, 1.34292281,\n",
      "       0.24923449, 0.74660254, 0.58267279, 1.00311291, 0.5386023 ,\n",
      "       0.16667018, 0.83773103, 0.41413081, 0.08545306, 0.58179996,\n",
      "       1.3510612 , 0.084408  , 1.92777462, 0.40685689, 1.12264318,\n",
      "       0.38956828, 0.93453288, 0.25189824, 1.47242997, 2.44520495,\n",
      "       1.20996106, 0.52425563, 0.90400381, 1.40355744, 1.78039486,\n",
      "       0.27291911, 0.16586211, 0.08645077, 0.2789212 , 0.76894531,\n",
      "       0.54405103, 1.15541492, 0.2183959 , 0.38832898, 0.16498086,\n",
      "       0.80100281, 2.21436186, 1.65150938, 0.64672925, 1.03226013,\n",
      "       1.22100534, 1.79913995, 0.22684138, 2.22765071, 0.37116592,\n",
      "       0.42583952, 1.31065466, 0.44155202, 0.32838421, 0.20757437,\n",
      "       0.16814742, 0.99286313, 1.1864181 , 1.68716431, 1.09615219,\n",
      "       2.54664965, 0.44632699, 0.6142498 , 0.21637707, 0.78701971,\n",
      "       0.41162183, 0.43443899, 0.2544337 , 2.4861253 , 1.11567669,\n",
      "       0.60506725, 2.41483676, 0.8522361 , 0.95801089, 0.44256365,\n",
      "       0.3170471 , 1.47120709, 0.31279697, 0.71184998, 1.69422748,\n",
      "       0.60989358, 0.2858968 , 0.20800908, 1.71656899, 1.78055608,\n",
      "       0.61675587, 1.62918088, 0.15253792, 0.09328687, 0.15644917,\n",
      "       1.35439777, 0.42762966, 1.85192692, 0.63969202, 0.09217095,\n",
      "       0.78120213, 0.50309253, 0.98412614, 0.15313704, 0.6700459 ,\n",
      "       1.24379449, 0.35344028, 0.36116548, 1.78910897, 0.87656817,\n",
      "       0.30319076, 0.51839931, 0.64558427, 1.18359454, 1.0022619 ,\n",
      "       1.00229897, 0.33372207, 1.32989788, 0.23441176, 1.26145957,\n",
      "       0.60484283, 0.4961082 , 1.26781616, 0.09285083, 0.32665529,\n",
      "       1.18061697, 0.66089118, 0.83504372, 1.36715889, 0.10123401,\n",
      "       2.27736826, 0.83910892, 0.36258891, 2.68337629, 0.61654193,\n",
      "       1.29814291, 0.92896502, 1.36935127, 0.68280909, 0.29432709,\n",
      "       1.36400409, 0.47599962, 0.908412  , 0.3206418 , 2.42008293,\n",
      "       0.99827316, 0.78295352, 0.6288831 , 2.12705975, 0.58309925,\n",
      "       0.47239497, 0.64851584, 1.23303242, 1.39872916, 0.32170312,\n",
      "       0.47846425, 0.09160831, 0.87463171, 1.23730307, 0.370541  ,\n",
      "       0.78765235, 0.67781751, 1.97759609, 0.1533011 , 0.08623562,\n",
      "       0.89860041, 1.6577739 , 0.43366127, 0.99923277, 0.1515311 ,\n",
      "       1.28919711, 0.45032291, 0.75314343, 0.63738232, 1.0596725 ,\n",
      "       0.43556001, 0.61238906, 0.44298985, 1.18431854, 0.50666401,\n",
      "       0.36372607, 1.68789768, 0.83721793, 0.94451132, 0.32931285,\n",
      "       0.2688134 , 1.02193959, 1.01983323, 0.32497275, 0.33074143,\n",
      "       0.28706603, 0.91058776, 1.29125614, 1.19132414, 1.87911327]), 'std_fit_time': array([0.08484028, 0.01947361, 0.01249866, 0.00643761, 0.00739336,\n",
      "       0.00661419, 0.06088296, 0.03183346, 0.02673241, 0.00507265,\n",
      "       0.03179656, 0.07839326, 0.0243633 , 0.0636092 , 0.05983955,\n",
      "       0.00432639, 0.05008535, 0.02653217, 0.01322832, 0.00797468,\n",
      "       0.0015442 , 0.00304514, 0.00486913, 0.00089436, 0.00308964,\n",
      "       0.01092768, 0.00089838, 0.01186823, 0.00354008, 0.04504667,\n",
      "       0.00516936, 0.00645359, 0.00296729, 0.02722962, 0.13216757,\n",
      "       0.05974513, 0.02634357, 0.04967758, 0.05517805, 0.01950807,\n",
      "       0.00304047, 0.00303398, 0.00125679, 0.00486901, 0.00283391,\n",
      "       0.01177186, 0.0169568 , 0.00287361, 0.0041115 , 0.00239265,\n",
      "       0.01174309, 0.01815715, 0.07294327, 0.01103488, 0.03021482,\n",
      "       0.0065759 , 0.08017165, 0.00625493, 0.12058637, 0.01664666,\n",
      "       0.02119134, 0.09245806, 0.00909192, 0.00585135, 0.01170264,\n",
      "       0.00482907, 0.0156365 , 0.03608338, 0.08500453, 0.04158879,\n",
      "       0.10833912, 0.01271923, 0.02451263, 0.01725972, 0.04736426,\n",
      "       0.01608349, 0.02721053, 0.00476019, 0.05332192, 0.05594854,\n",
      "       0.03063962, 0.08436503, 0.02475515, 0.06677348, 0.03312188,\n",
      "       0.03574217, 0.03296274, 0.00746863, 0.00596419, 0.03469199,\n",
      "       0.01913637, 0.00624343, 0.00786703, 0.06661787, 0.02540134,\n",
      "       0.02657146, 0.01880995, 0.00210475, 0.00279358, 0.00861138,\n",
      "       0.02663759, 0.00739305, 0.01594275, 0.01750112, 0.00111233,\n",
      "       0.00584963, 0.00736747, 0.01451003, 0.00359869, 0.0188433 ,\n",
      "       0.01093348, 0.00372365, 0.00700753, 0.02162473, 0.0204314 ,\n",
      "       0.00794152, 0.00834285, 0.00987826, 0.05168991, 0.00882612,\n",
      "       0.02285347, 0.00384793, 0.02480135, 0.00536593, 0.01233398,\n",
      "       0.02305592, 0.00384646, 0.0684752 , 0.00153429, 0.02278559,\n",
      "       0.03755389, 0.03018178, 0.01710621, 0.03419509, 0.005256  ,\n",
      "       0.17305712, 0.00906554, 0.01322129, 0.1089947 , 0.01772278,\n",
      "       0.02011659, 0.01310104, 0.03362725, 0.01299094, 0.01050828,\n",
      "       0.03992787, 0.01522937, 0.02799519, 0.00911743, 0.11890651,\n",
      "       0.0799293 , 0.03040568, 0.06430524, 0.09365692, 0.02499274,\n",
      "       0.04253773, 0.02460446, 0.02372454, 0.0504802 , 0.009609  ,\n",
      "       0.03760538, 0.00411377, 0.04051925, 0.03878885, 0.02998919,\n",
      "       0.02699528, 0.0313599 , 0.04169153, 0.00781846, 0.00109375,\n",
      "       0.04253189, 0.01274014, 0.05096384, 0.13019921, 0.00358589,\n",
      "       0.04648906, 0.02435997, 0.09410379, 0.06005421, 0.13300772,\n",
      "       0.01039831, 0.02547923, 0.03353396, 0.05008899, 0.02317638,\n",
      "       0.02720553, 0.06047226, 0.02994723, 0.0304805 , 0.0010621 ,\n",
      "       0.01162182, 0.05438163, 0.08986763, 0.02722915, 0.04858837,\n",
      "       0.01170891, 0.05278866, 0.0901359 , 0.03423864, 0.12262331]), 'mean_score_time': array([0.00792778, 0.00450289, 0.00255947, 0.00161343, 0.00830126,\n",
      "       0.00253875, 0.00918579, 0.0070653 , 0.0045753 , 0.00161617,\n",
      "       0.00234957, 0.00801141, 0.00672243, 0.00822399, 0.00763233,\n",
      "       0.002002  , 0.005987  , 0.00492902, 0.0086458 , 0.00240521,\n",
      "       0.001613  , 0.00706165, 0.00274503, 0.00110056, 0.00492675,\n",
      "       0.01029034, 0.00099046, 0.01434267, 0.00340095, 0.00885847,\n",
      "       0.00285072, 0.00751545, 0.002332  , 0.00807707, 0.0101902 ,\n",
      "       0.00531754, 0.00314262, 0.00716434, 0.01090336, 0.00778253,\n",
      "       0.00232899, 0.00123153, 0.00106776, 0.0019058 , 0.0065645 ,\n",
      "       0.00309074, 0.00909231, 0.00167916, 0.00332499, 0.00126455,\n",
      "       0.00408702, 0.01143878, 0.00799825, 0.00462539, 0.00869141,\n",
      "       0.00997183, 0.00884607, 0.00166144, 0.01405635, 0.00320799,\n",
      "       0.00362852, 0.00629339, 0.00320678, 0.00179801, 0.00200641,\n",
      "       0.00121903, 0.00606768, 0.0048707 , 0.00985708, 0.00924132,\n",
      "       0.01614799, 0.00282028, 0.00261185, 0.00218432, 0.00664356,\n",
      "       0.00363152, 0.00352259, 0.00199265, 0.01295671, 0.00927749,\n",
      "       0.00481515, 0.01066267, 0.00711949, 0.00819664, 0.00375392,\n",
      "       0.00210013, 0.00703957, 0.00277569, 0.00606024, 0.00986872,\n",
      "       0.00328023, 0.00209336, 0.00208762, 0.01271148, 0.00933857,\n",
      "       0.0048991 , 0.01184866, 0.00161929, 0.00107601, 0.00134611,\n",
      "       0.01047561, 0.00357494, 0.01323509, 0.00266323, 0.00127578,\n",
      "       0.00649183, 0.00391471, 0.00768952, 0.00164466, 0.00381274,\n",
      "       0.00530562, 0.00302765, 0.00296028, 0.00859017, 0.0049094 ,\n",
      "       0.00253885, 0.00345967, 0.00297563, 0.00520556, 0.00769875,\n",
      "       0.00541658, 0.00299883, 0.00660014, 0.00199897, 0.00853441,\n",
      "       0.00303743, 0.00399523, 0.00970922, 0.00103884, 0.00267706,\n",
      "       0.00896697, 0.00441206, 0.0069309 , 0.0078824 , 0.00129447,\n",
      "       0.0160378 , 0.00676153, 0.00198023, 0.01240025, 0.0028024 ,\n",
      "       0.00631335, 0.00754697, 0.00717721, 0.00352046, 0.002759  ,\n",
      "       0.00730202, 0.00380983, 0.0069591 , 0.00205779, 0.0109458 ,\n",
      "       0.00841484, 0.00645959, 0.00520778, 0.01176529, 0.00342171,\n",
      "       0.00410001, 0.00443666, 0.00665069, 0.01195204, 0.00208931,\n",
      "       0.00282445, 0.0010602 , 0.00470655, 0.00492191, 0.00288212,\n",
      "       0.00701785, 0.00585608, 0.00912845, 0.00146649, 0.00104332,\n",
      "       0.00565357, 0.01218078, 0.00372655, 0.00824468, 0.00140731,\n",
      "       0.00988979, 0.00326097, 0.00472362, 0.00420363, 0.00827434,\n",
      "       0.00252428, 0.00284865, 0.00246928, 0.00902228, 0.00243547,\n",
      "       0.00248327, 0.00784781, 0.00694942, 0.00475173, 0.00251751,\n",
      "       0.00248671, 0.00656149, 0.0061511 , 0.00260596, 0.00198505,\n",
      "       0.00247483, 0.00505278, 0.00876071, 0.00977347, 0.00727794]), 'std_score_time': array([5.42610886e-04, 2.13180936e-04, 1.30808687e-04, 6.59131264e-05,\n",
      "       6.31457222e-04, 3.59222719e-04, 9.07308185e-04, 9.45744039e-04,\n",
      "       2.26941472e-04, 1.36481593e-04, 3.86476293e-04, 1.70352758e-03,\n",
      "       2.53988297e-04, 9.29410120e-04, 1.33223129e-03, 8.65075129e-05,\n",
      "       4.12602815e-04, 2.03789173e-04, 1.84703704e-04, 1.43513996e-04,\n",
      "       6.58293687e-05, 1.90497491e-04, 7.63200365e-05, 5.45633251e-05,\n",
      "       9.38002474e-05, 2.73358620e-04, 5.05880236e-05, 3.05844507e-04,\n",
      "       7.61824180e-05, 4.20709623e-04, 7.50645136e-05, 1.91776692e-04,\n",
      "       8.97621380e-05, 3.36473579e-04, 1.02842404e-03, 1.04366041e-03,\n",
      "       5.19146002e-04, 4.93011854e-04, 3.94408715e-04, 6.08026680e-04,\n",
      "       7.08074481e-05, 6.48347928e-05, 7.13816028e-05, 8.65506238e-05,\n",
      "       1.39354884e-04, 8.41567096e-05, 1.65576046e-04, 6.96587485e-05,\n",
      "       4.75886112e-05, 1.63902896e-04, 1.74393235e-04, 5.16036513e-04,\n",
      "       5.17091924e-04, 1.69322318e-04, 2.94948629e-04, 1.28606900e-04,\n",
      "       5.03358951e-04, 6.67217024e-05, 1.63667685e-03, 1.08225074e-04,\n",
      "       2.58015490e-04, 4.48866312e-04, 2.66899261e-04, 7.04082964e-05,\n",
      "       1.12887723e-04, 7.83064037e-05, 2.91373531e-04, 3.41915448e-04,\n",
      "       9.97376258e-04, 4.57559573e-04, 2.63490753e-03, 8.94727116e-05,\n",
      "       1.47801692e-04, 2.34524736e-04, 3.27838368e-04, 2.86670995e-04,\n",
      "       2.68805985e-04, 4.60361273e-05, 1.64282932e-03, 9.85245364e-04,\n",
      "       6.57196710e-04, 9.16734543e-04, 3.12593490e-04, 5.35740561e-04,\n",
      "       5.92157364e-04, 4.39086535e-04, 3.18404320e-04, 9.30592917e-05,\n",
      "       1.68699408e-04, 3.79264106e-04, 1.55757529e-04, 5.19034344e-05,\n",
      "       2.76042992e-04, 3.70549597e-04, 1.34410016e-03, 2.54322341e-04,\n",
      "       4.04861599e-04, 1.19005019e-04, 7.93382701e-05, 9.24680571e-05,\n",
      "       2.87135176e-04, 9.41583280e-05, 4.74074946e-04, 1.84522001e-04,\n",
      "       4.84869772e-05, 1.12887360e-04, 1.32056530e-04, 1.68814120e-04,\n",
      "       7.76591055e-05, 5.04598532e-04, 2.60080013e-04, 6.30736295e-05,\n",
      "       1.27596837e-03, 4.96234980e-04, 2.83152478e-04, 2.00524314e-04,\n",
      "       1.07904806e-04, 1.88270626e-04, 1.19468335e-03, 1.35582315e-04,\n",
      "       2.89406095e-04, 1.90489253e-04, 3.02236679e-04, 5.32039006e-05,\n",
      "       1.35169404e-03, 3.16952631e-04, 7.34657208e-05, 5.75221525e-04,\n",
      "       5.95792526e-05, 8.25429224e-05, 3.57734836e-04, 5.57707385e-04,\n",
      "       3.88003762e-04, 3.16788567e-04, 4.09902118e-04, 1.45643893e-03,\n",
      "       1.06367421e-04, 2.00762178e-04, 5.91322316e-03, 8.71164295e-05,\n",
      "       1.04151104e-03, 2.06566332e-04, 3.95677425e-04, 2.27744047e-04,\n",
      "       2.30322403e-04, 2.88331377e-04, 2.97044601e-04, 3.46278576e-04,\n",
      "       9.15257841e-05, 1.23062447e-03, 7.07336913e-04, 2.96601821e-04,\n",
      "       5.45639241e-04, 1.35019599e-03, 1.90255817e-04, 1.15464958e-03,\n",
      "       4.20162161e-04, 7.87792741e-04, 1.80710482e-03, 1.76462956e-04,\n",
      "       1.35005189e-04, 7.82876585e-05, 2.53155763e-04, 2.44625804e-04,\n",
      "       6.11133608e-04, 3.32499819e-04, 2.40760266e-04, 5.51397409e-04,\n",
      "       7.17926166e-05, 7.80543977e-05, 2.32550891e-04, 1.48399657e-03,\n",
      "       4.59437774e-04, 1.14039068e-03, 6.57200327e-05, 4.05334063e-04,\n",
      "       3.80594983e-04, 5.78022006e-04, 5.63726319e-04, 6.35537345e-04,\n",
      "       1.61653993e-04, 5.67133210e-04, 1.59019596e-04, 5.61640181e-04,\n",
      "       1.60756808e-04, 1.69513403e-04, 8.38474671e-04, 4.05114449e-04,\n",
      "       1.92514722e-04, 7.35038563e-05, 1.62050356e-04, 1.08951851e-03,\n",
      "       8.93553726e-04, 3.55471304e-04, 4.69788942e-04, 2.11224163e-04,\n",
      "       1.62943652e-04, 8.20951416e-04, 5.19794393e-04, 6.26898316e-04]), 'param_n_estimators': masked_array(data=[300, 200, 100, 100, 200, 100, 400, 200, 400, 100, 100,\n",
      "                   300, 200, 300, 200, 300, 200, 300, 400, 100, 200, 300,\n",
      "                   300, 100, 300, 300, 100, 400, 300, 300, 100, 200, 100,\n",
      "                   300, 400, 200, 100, 200, 400, 300, 200, 200, 100, 200,\n",
      "                   400, 400, 400, 100, 200, 200, 200, 400, 400, 300, 300,\n",
      "                   400, 300, 100, 400, 100, 100, 300, 300, 400, 100, 200,\n",
      "                   200, 200, 400, 400, 400, 200, 100, 100, 200, 200, 100,\n",
      "                   300, 400, 400, 100, 400, 300, 400, 100, 200, 300, 100,\n",
      "                   300, 300, 100, 200, 100, 400, 400, 400, 300, 100, 100,\n",
      "                   100, 300, 100, 400, 100, 100, 300, 100, 300, 100, 200,\n",
      "                   200, 100, 400, 300, 200, 200, 100, 100, 200, 300, 300,\n",
      "                   100, 400, 100, 300, 100, 100, 300, 100, 200, 300, 400,\n",
      "                   300, 400, 100, 400, 400, 400, 400, 100, 200, 200, 400,\n",
      "                   200, 100, 300, 300, 200, 200, 400, 300, 400, 300, 400,\n",
      "                   400, 300, 200, 300, 400, 100, 200, 100, 200, 200, 400,\n",
      "                   300, 200, 400, 100, 100, 400, 300, 100, 300, 100, 300,\n",
      "                   200, 200, 100, 300, 100, 100, 300, 300, 100, 400, 300,\n",
      "                   300, 300, 400, 100, 300, 400, 100, 300, 200, 400, 200,\n",
      "                   400, 300],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[16, 12, 16, 6, 18, 10, 14, 12, 4, 6, 6, 18, 14, 18, 18,\n",
      "                   2, 18, 6, 8, 14, 2, 10, 4, 2, 6, 14, 2, 18, 4, 16, 10,\n",
      "                   16, 8, 12, 18, 16, 12, 16, 16, 18, 4, 2, 2, 4, 6, 4,\n",
      "                   18, 6, 6, 2, 10, 14, 10, 6, 12, 12, 16, 6, 14, 12, 14,\n",
      "                   10, 4, 2, 6, 2, 12, 18, 10, 8, 16, 6, 18, 6, 12, 6, 16,\n",
      "                   2, 16, 10, 18, 16, 10, 8, 14, 4, 12, 10, 8, 14, 16, 4,\n",
      "                   6, 16, 10, 4, 18, 4, 2, 4, 14, 12, 18, 18, 2, 8, 18,\n",
      "                   14, 4, 8, 16, 10, 2, 14, 10, 4, 12, 18, 14, 16, 8, 10,\n",
      "                   8, 6, 10, 14, 16, 14, 2, 4, 10, 4, 8, 8, 2, 16, 6, 2,\n",
      "                   18, 14, 16, 14, 8, 8, 8, 10, 4, 16, 4, 14, 10, 6, 6,\n",
      "                   12, 4, 4, 8, 10, 12, 8, 6, 2, 10, 18, 2, 8, 10, 12, 4,\n",
      "                   2, 6, 18, 12, 12, 4, 16, 6, 8, 14, 12, 10, 16, 4, 18,\n",
      "                   12, 2, 14, 8, 8, 2, 8, 8, 6, 8, 2, 4, 6, 18, 12, 18],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.001, 0.0001, 0.0001, 0.001, 0.1, 0.001, 0.0001, 0.03,\n",
      "                   0.9, 0.0003, 0.1, 0.0001, 0.3, 0.9, 0.01, 0.03, 0.9,\n",
      "                   0.9, 0.1, 0.0001, 0.1, 0.6, 0.003, 0.1, 0.1, 0.03,\n",
      "                   0.03, 0.1, 0.1, 0.6, 0.03, 0.1, 0.9, 0.003, 0.0003,\n",
      "                   0.0003, 0.003, 0.3, 0.6, 0.001, 0.3, 0.001, 0.6, 0.003,\n",
      "                   0.1, 0.0001, 0.9, 0.01, 0.3, 0.0003, 0.0003, 0.003,\n",
      "                   0.0001, 0.01, 0.3, 0.6, 0.003, 0.003, 0.01, 0.6, 0.6,\n",
      "                   0.0001, 0.01, 0.0003, 0.6, 0.0001, 0.01, 0.0003, 0.003,\n",
      "                   0.03, 0.01, 0.003, 0.0003, 0.3, 0.1, 0.9, 0.9, 0.6,\n",
      "                   0.003, 0.9, 0.1, 0.001, 0.9, 0.9, 0.9, 0.0003, 0.001,\n",
      "                   0.9, 0.9, 0.01, 0.01, 0.01, 0.9, 0.3, 0.001, 0.03, 0.1,\n",
      "                   0.9, 0.0003, 0.0003, 0.1, 0.1, 0.3, 0.0001, 0.3, 0.6,\n",
      "                   0.6, 0.9, 0.6, 0.001, 0.001, 0.1, 0.6, 0.003, 0.003,\n",
      "                   0.03, 0.03, 0.003, 0.0003, 0.9, 0.001, 0.6, 0.0003,\n",
      "                   0.03, 0.01, 0.003, 0.3, 0.3, 0.0001, 0.9, 0.03, 0.003,\n",
      "                   0.3, 0.003, 0.003, 0.03, 0.3, 0.0001, 0.0001, 0.001,\n",
      "                   0.003, 0.1, 0.001, 0.0003, 0.1, 0.003, 0.6, 0.6, 0.001,\n",
      "                   0.001, 0.3, 0.6, 0.3, 0.003, 0.0003, 0.03, 0.01, 0.001,\n",
      "                   0.3, 0.003, 0.001, 0.001, 0.001, 0.0001, 0.1, 0.1, 0.1,\n",
      "                   0.0003, 0.01, 0.01, 0.003, 0.03, 0.9, 0.9, 0.003, 0.3,\n",
      "                   0.01, 0.003, 0.03, 0.6, 0.003, 0.0003, 0.0001, 0.6,\n",
      "                   0.0001, 0.01, 0.001, 0.03, 0.0001, 0.03, 0.3, 0.003,\n",
      "                   0.0003, 0.03, 0.0001, 0.6, 0.0001, 0.03, 0.9, 0.0003],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 300, 'max_depth': 16, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.0001}, {'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.0001}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 18, 'learning_rate': 0.1}, {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.001}, {'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.03}, {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 14, 'learning_rate': 0.3}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.9}, {'n_estimators': 200, 'max_depth': 18, 'learning_rate': 0.01}, {'n_estimators': 300, 'max_depth': 2, 'learning_rate': 0.03}, {'n_estimators': 200, 'max_depth': 18, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.9}, {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.1}, {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.03}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.03}, {'n_estimators': 400, 'max_depth': 18, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 16, 'learning_rate': 0.6}, {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.03}, {'n_estimators': 200, 'max_depth': 16, 'learning_rate': 0.1}, {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 18, 'learning_rate': 0.0003}, {'n_estimators': 200, 'max_depth': 16, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.003}, {'n_estimators': 200, 'max_depth': 16, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 16, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.3}, {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.001}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.6}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.0001}, {'n_estimators': 400, 'max_depth': 18, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.01}, {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.3}, {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.0003}, {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.0003}, {'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.0001}, {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.01}, {'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 16, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.01}, {'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.6}, {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.0001}, {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.01}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.6}, {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.01}, {'n_estimators': 200, 'max_depth': 18, 'learning_rate': 0.0003}, {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.03}, {'n_estimators': 400, 'max_depth': 16, 'learning_rate': 0.01}, {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.3}, {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.1}, {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 2, 'learning_rate': 0.6}, {'n_estimators': 400, 'max_depth': 16, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 16, 'learning_rate': 0.001}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.9}, {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.9}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.0003}, {'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.001}, {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.01}, {'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.01}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.01}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.9}, {'n_estimators': 400, 'max_depth': 16, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.001}, {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.03}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.1}, {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.0003}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.1}, {'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 18, 'learning_rate': 0.3}, {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.0001}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.3}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.6}, {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.6}, {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 16, 'learning_rate': 0.001}, {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.003}, {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.003}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.03}, {'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.03}, {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.003}, {'n_estimators': 200, 'max_depth': 14, 'learning_rate': 0.0003}, {'n_estimators': 300, 'max_depth': 16, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.001}, {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.6}, {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.03}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.01}, {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.3}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.3}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.03}, {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.003}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 16, 'learning_rate': 0.03}, {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.0001}, {'n_estimators': 400, 'max_depth': 18, 'learning_rate': 0.0001}, {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 16, 'learning_rate': 0.003}, {'n_estimators': 200, 'max_depth': 14, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.003}, {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.6}, {'n_estimators': 200, 'max_depth': 16, 'learning_rate': 0.6}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.001}, {'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.001}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.6}, {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.3}, {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.0003}, {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.03}, {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.01}, {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.001}, {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.3}, {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.003}, {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.001}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.001}, {'n_estimators': 200, 'max_depth': 18, 'learning_rate': 0.0001}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1}, {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.01}, {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.01}, {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.003}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.03}, {'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.9}, {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.003}, {'n_estimators': 300, 'max_depth': 16, 'learning_rate': 0.3}, {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.01}, {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.03}, {'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.6}, {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.003}, {'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.0003}, {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.0001}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.6}, {'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.0001}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.01}, {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.001}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.03}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.0001}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.03}, {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.3}, {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.003}, {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.0003}, {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.03}, {'n_estimators': 300, 'max_depth': 2, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.6}, {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.0001}, {'n_estimators': 200, 'max_depth': 18, 'learning_rate': 0.03}, {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.9}, {'n_estimators': 300, 'max_depth': 18, 'learning_rate': 0.0003}], 'split0_test_score': array([0.53623115, 0.54642221, 0.55569081, 0.55385791, 0.54642221,\n",
      "       0.53256444, 0.56309596, 0.53773087, 0.54642221, 0.50084157,\n",
      "       0.55681164, 0.55849205, 0.53976858, 0.53810916, 0.52269773,\n",
      "       0.53972749, 0.54365145, 0.5315508 , 0.58121981, 0.54642221,\n",
      "       0.54486232, 0.53810916, 0.5630547 , 0.54486232, 0.56970233,\n",
      "       0.53121451, 0.52387965, 0.54449673, 0.54995748, 0.52750809,\n",
      "       0.5338881 , 0.57616501, 0.57899841, 0.55107175, 0.55464801,\n",
      "       0.55664434, 0.55464801, 0.52956219, 0.52000822, 0.53623115,\n",
      "       0.55347053, 0.65746997, 0.5828303 , 0.56028058, 0.55552116,\n",
      "       0.67794621, 0.54549941, 0.52387965, 0.58721461, 0.66092311,\n",
      "       0.57413358, 0.52956219, 0.57271825, 0.5573133 , 0.53429027,\n",
      "       0.5248017 , 0.52881085, 0.55849205, 0.51333333, 0.55008841,\n",
      "       0.55196399, 0.5756183 , 0.5419155 , 0.66092311, 0.56129361,\n",
      "       0.66092311, 0.54045408, 0.55664434, 0.54524744, 0.55552116,\n",
      "       0.53292054, 0.49564201, 0.55849205, 0.60462144, 0.55917874,\n",
      "       0.5260702 , 0.5408805 , 0.58409277, 0.5315508 , 0.54919298,\n",
      "       0.53833394, 0.52209493, 0.54919298, 0.5389865 , 0.53533721,\n",
      "       0.67794621, 0.55464801, 0.54365145, 0.55107175, 0.525387  ,\n",
      "       0.52956219, 0.55621371, 0.54828566, 0.53500796, 0.54365145,\n",
      "       0.5704915 , 0.54174163, 0.56083622, 0.66092311, 0.67794621,\n",
      "       0.55943126, 0.5302143 , 0.53429027, 0.55569081, 0.53455449,\n",
      "       0.52807623, 0.56872931, 0.53533721, 0.56483961, 0.55917874,\n",
      "       0.55183172, 0.54317779, 0.58431568, 0.5389865 , 0.53702946,\n",
      "       0.54752872, 0.53833394, 0.53623115, 0.55385791, 0.54271281,\n",
      "       0.57834729, 0.57221521, 0.56368111, 0.5545971 , 0.53656265,\n",
      "       0.54549941, 0.5315508 , 0.54449673, 0.66092311, 0.57221521,\n",
      "       0.56779716, 0.55552116, 0.55746401, 0.53833394, 0.66361029,\n",
      "       0.53292054, 0.57790627, 0.66092311, 0.55849205, 0.55288967,\n",
      "       0.53773087, 0.54725202, 0.56368111, 0.5710142 , 0.55621371,\n",
      "       0.55569081, 0.56652576, 0.52750809, 0.67047538, 0.53228514,\n",
      "       0.53500796, 0.53429027, 0.57506043, 0.53623115, 0.67084684,\n",
      "       0.54486232, 0.55895833, 0.53347535, 0.5315508 , 0.57834729,\n",
      "       0.55664434, 0.66092311, 0.53713768, 0.56027992, 0.56003172,\n",
      "       0.58279441, 0.56591235, 0.55917874, 0.56970233, 0.65263889,\n",
      "       0.53121451, 0.55196399, 0.57221521, 0.58245068, 0.69865841,\n",
      "       0.53976858, 0.55188289, 0.56409569, 0.54375   , 0.5248017 ,\n",
      "       0.5408805 , 0.55849205, 0.67794621, 0.56652576, 0.55107175,\n",
      "       0.55135417, 0.54828566, 0.57058824, 0.54365145, 0.53972749,\n",
      "       0.55196399, 0.54524744, 0.55385791, 0.54590223, 0.66092311,\n",
      "       0.55008841, 0.50084157, 0.53773087, 0.57506043, 0.55385791]), 'split1_test_score': array([0.64215686, 0.66667843, 0.62619127, 0.6912594 , 0.58022247,\n",
      "       0.67084684, 0.63408521, 0.59893406, 0.57334087, 0.69107067,\n",
      "       0.65746997, 0.63730999, 0.59398567, 0.5968136 , 0.62660285,\n",
      "       0.67465372, 0.58992152, 0.56703795, 0.62151207, 0.63408521,\n",
      "       0.67794621, 0.58339278, 0.66860548, 0.67123288, 0.61382959,\n",
      "       0.58834586, 0.65400814, 0.60154338, 0.66210089, 0.59635629,\n",
      "       0.64376877, 0.60512236, 0.61607619, 0.66772557, 0.67296606,\n",
      "       0.64830909, 0.64869073, 0.59791073, 0.60276808, 0.63491389,\n",
      "       0.64505812, 0.62762139, 0.66280166, 0.65803513, 0.61705597,\n",
      "       0.6275821 , 0.58895132, 0.69141891, 0.5926609 , 0.61920486,\n",
      "       0.67067669, 0.65650292, 0.67753759, 0.68487237, 0.57657711,\n",
      "       0.60693369, 0.64180231, 0.68491673, 0.61885723, 0.60967647,\n",
      "       0.59034696, 0.67047538, 0.69165063, 0.61920486, 0.64789332,\n",
      "       0.61920486, 0.63671362, 0.64098927, 0.64725614, 0.63671362,\n",
      "       0.59893406, 0.69165063, 0.63775564, 0.60086727, 0.59635629,\n",
      "       0.57574314, 0.61100173, 0.63730999, 0.6498801 , 0.57457091,\n",
      "       0.60154338, 0.62512514, 0.588406  , 0.58025542, 0.60003779,\n",
      "       0.6275821 , 0.6519502 , 0.59314189, 0.58404558, 0.6325921 ,\n",
      "       0.65263889, 0.67711274, 0.58148846, 0.58522727, 0.66047708,\n",
      "       0.66771079, 0.60841333, 0.56185683, 0.61920486, 0.6275821 ,\n",
      "       0.59905303, 0.59398567, 0.5613178 , 0.62938448, 0.66692929,\n",
      "       0.56765336, 0.60448983, 0.60596591, 0.62395586, 0.68491673,\n",
      "       0.66968326, 0.66246756, 0.60167491, 0.64247704, 0.64655973,\n",
      "       0.7020513 , 0.61636637, 0.6405303 , 0.65231128, 0.59314189,\n",
      "       0.68141344, 0.59157935, 0.70535505, 0.68487237, 0.64376877,\n",
      "       0.65884227, 0.59635629, 0.60774887, 0.61920486, 0.57565661,\n",
      "       0.61932279, 0.66899679, 0.57245418, 0.69178082, 0.62762139,\n",
      "       0.58122913, 0.56555828, 0.61920486, 0.63730999, 0.67296606,\n",
      "       0.61100173, 0.61136827, 0.68479842, 0.70202334, 0.61824671,\n",
      "       0.66085947, 0.606469  , 0.59034696, 0.63894041, 0.62839367,\n",
      "       0.60047181, 0.59314189, 0.58575684, 0.6356016 , 0.6275821 ,\n",
      "       0.70196741, 0.67117117, 0.67784038, 0.56555828, 0.68141344,\n",
      "       0.68817696, 0.61920486, 0.65068493, 0.62938448, 0.68087432,\n",
      "       0.62113706, 0.62299373, 0.66337286, 0.66170142, 0.63854143,\n",
      "       0.69827627, 0.59761139, 0.58385452, 0.57245418, 0.64695842,\n",
      "       0.59157935, 0.68147323, 0.69176636, 0.60892857, 0.60047181,\n",
      "       0.681204  , 0.63775564, 0.6275821 , 0.61100173, 0.66667843,\n",
      "       0.66780432, 0.65884227, 0.64006903, 0.69172297, 0.67465372,\n",
      "       0.60003779, 0.68835251, 0.69477232, 0.64376877, 0.61920486,\n",
      "       0.57565661, 0.69107067, 0.60809984, 0.57513456, 0.66968326]), 'split2_test_score': array([0.61674636, 0.64401344, 0.63995432, 0.59058181, 0.64546106,\n",
      "       0.6482842 , 0.65054396, 0.66030589, 0.64867256, 0.59058181,\n",
      "       0.68276614, 0.64644082, 0.65419717, 0.67742589, 0.66802928,\n",
      "       0.64108159, 0.67417095, 0.63850932, 0.67048881, 0.64362404,\n",
      "       0.69239997, 0.65936455, 0.60820578, 0.64436824, 0.67494534,\n",
      "       0.66030589, 0.60099291, 0.6427405 , 0.67130373, 0.67003258,\n",
      "       0.65783817, 0.64919254, 0.6373658 , 0.65488615, 0.64036505,\n",
      "       0.65291031, 0.61740006, 0.65012797, 0.65613922, 0.61674636,\n",
      "       0.69041443, 0.5111608 , 0.67373569, 0.58411386, 0.67166289,\n",
      "       0.53754744, 0.68110349, 0.63186768, 0.63902672, 0.5111608 ,\n",
      "       0.65158789, 0.66438381, 0.65158789, 0.65939159, 0.65936455,\n",
      "       0.64491817, 0.62759503, 0.59776715, 0.65562953, 0.64054686,\n",
      "       0.67003258, 0.65158789, 0.65488615, 0.5111608 , 0.65661466,\n",
      "       0.5111608 , 0.6686907 , 0.65291031, 0.68186139, 0.67326804,\n",
      "       0.67650047, 0.60820578, 0.65291031, 0.63627165, 0.65291031,\n",
      "       0.63529917, 0.66580534, 0.66954349, 0.65848714, 0.64967758,\n",
      "       0.66723842, 0.60984089, 0.65661466, 0.65613922, 0.65337336,\n",
      "       0.53754744, 0.61740006, 0.66030589, 0.66723842, 0.64919254,\n",
      "       0.6377894 , 0.64855072, 0.6509258 , 0.64644082, 0.6352176 ,\n",
      "       0.68877745, 0.65291031, 0.64171558, 0.5111608 , 0.53754744,\n",
      "       0.67457409, 0.64867256, 0.64644082, 0.63950829, 0.70150286,\n",
      "       0.63902672, 0.63155757, 0.6427405 , 0.64546106, 0.66922421,\n",
      "       0.62610641, 0.66679389, 0.66631629, 0.63710108, 0.65544189,\n",
      "       0.67199013, 0.66723842, 0.61674636, 0.65380223, 0.65450621,\n",
      "       0.65921431, 0.64546106, 0.66922421, 0.66609887, 0.67166289,\n",
      "       0.61674636, 0.6630859 , 0.66111322, 0.5111608 , 0.62721341,\n",
      "       0.67091245, 0.62145222, 0.6550853 , 0.68186139, 0.53423316,\n",
      "       0.67276773, 0.66723842, 0.5111608 , 0.64644082, 0.64362404,\n",
      "       0.6305573 , 0.66723842, 0.64522696, 0.68476876, 0.64967758,\n",
      "       0.66565591, 0.65613922, 0.68110349, 0.53754744, 0.616364  ,\n",
      "       0.65884295, 0.64596851, 0.66679389, 0.66837607, 0.53754744,\n",
      "       0.68580107, 0.67199013, 0.64189701, 0.64867256, 0.6556702 ,\n",
      "       0.59058181, 0.5111608 , 0.64855072, 0.6427405 , 0.69169692,\n",
      "       0.65936455, 0.67742589, 0.62098608, 0.62177427, 0.54518329,\n",
      "       0.64914894, 0.65450621, 0.67326804, 0.64596851, 0.53754744,\n",
      "       0.65291031, 0.65211576, 0.66565591, 0.66072618, 0.64433953,\n",
      "       0.64522696, 0.65291031, 0.53754744, 0.6427405 , 0.64108159,\n",
      "       0.61740006, 0.62001425, 0.68110349, 0.68476876, 0.64436824,\n",
      "       0.69087263, 0.67918489, 0.59058181, 0.67494534, 0.5111608 ,\n",
      "       0.6630859 , 0.59058181, 0.67223447, 0.64967758, 0.65012797]), 'split3_test_score': array([0.65127372, 0.63449142, 0.61270083, 0.69363711, 0.71429078,\n",
      "       0.70622469, 0.63018872, 0.7034553 , 0.67347782, 0.69010318,\n",
      "       0.70404447, 0.61918245, 0.68722613, 0.70101681, 0.68608414,\n",
      "       0.72747964, 0.69741942, 0.6835461 , 0.70052167, 0.62934349,\n",
      "       0.70404447, 0.68728522, 0.67688055, 0.72414447, 0.69054258,\n",
      "       0.69298339, 0.71035169, 0.71076297, 0.69379648, 0.67651372,\n",
      "       0.7034553 , 0.71035169, 0.64944728, 0.67278215, 0.64319981,\n",
      "       0.60984089, 0.66508466, 0.6869155 , 0.68017065, 0.65127372,\n",
      "       0.69363711, 0.64919254, 0.6870487 , 0.6732926 , 0.6835461 ,\n",
      "       0.58703879, 0.68722613, 0.70438008, 0.68366575, 0.64546106,\n",
      "       0.69298339, 0.69027909, 0.69655892, 0.72058039, 0.7041844 ,\n",
      "       0.6700992 , 0.6625568 , 0.72164948, 0.7272339 , 0.67967095,\n",
      "       0.66944339, 0.69323068, 0.71700664, 0.64919254, 0.68300654,\n",
      "       0.60652888, 0.69363711, 0.62934349, 0.67651372, 0.70768285,\n",
      "       0.70651748, 0.70788998, 0.62564322, 0.70768285, 0.69678886,\n",
      "       0.6869155 , 0.65921431, 0.70784858, 0.67315355, 0.68035198,\n",
      "       0.70701806, 0.6482842 , 0.69063032, 0.66319444, 0.64240476,\n",
      "       0.58703879, 0.66508466, 0.67632999, 0.6700992 , 0.71700664,\n",
      "       0.67278215, 0.70722613, 0.70033734, 0.694028  , 0.67298343,\n",
      "       0.69730496, 0.71764956, 0.69063032, 0.64546106, 0.58703879,\n",
      "       0.70052167, 0.70722613, 0.6869155 , 0.62564322, 0.6870487 ,\n",
      "       0.68715222, 0.69988264, 0.6494804 , 0.68300654, 0.66627257,\n",
      "       0.6509258 , 0.68966253, 0.69759093, 0.65232975, 0.67632999,\n",
      "       0.71429078, 0.69323068, 0.64798387, 0.63383191, 0.63552793,\n",
      "       0.67678892, 0.69741942, 0.67678892, 0.72414447, 0.70740622,\n",
      "       0.64798387, 0.69344854, 0.68039727, 0.60652888, 0.68675255,\n",
      "       0.70651748, 0.6869155 , 0.70033734, 0.70090377, 0.64919254,\n",
      "       0.70368002, 0.69410028, 0.64546106, 0.61918245, 0.64036505,\n",
      "       0.66538639, 0.69298339, 0.69414363, 0.67347782, 0.71092715,\n",
      "       0.67632999, 0.6835461 , 0.67967095, 0.59036871, 0.65817919,\n",
      "       0.68017065, 0.68003452, 0.6833964 , 0.6833964 , 0.58703879,\n",
      "       0.70740622, 0.72492674, 0.68300654, 0.71117308, 0.67678892,\n",
      "       0.72164948, 0.64919254, 0.69655892, 0.61594436, 0.69730496,\n",
      "       0.70387637, 0.68655974, 0.65783817, 0.67340067, 0.73478132,\n",
      "       0.70777955, 0.72117534, 0.6665249 , 0.66660367, 0.59392148,\n",
      "       0.69042553, 0.71746235, 0.70103093, 0.69988264, 0.67347782,\n",
      "       0.68300654, 0.60619658, 0.58703879, 0.67632999, 0.64108159,\n",
      "       0.71746235, 0.6545584 , 0.71106383, 0.6735241 , 0.71368114,\n",
      "       0.69010318, 0.70090377, 0.72852234, 0.73180357, 0.64546106,\n",
      "       0.70755844, 0.69010318, 0.71764956, 0.66665092, 0.63627165]), 'split4_test_score': array([0.63214602, 0.64604811, 0.63552793, 0.67651372, 0.6390218 ,\n",
      "       0.65265845, 0.63570011, 0.63186768, 0.63186768, 0.68300654,\n",
      "       0.65635333, 0.62163121, 0.63874866, 0.62833491, 0.64914894,\n",
      "       0.65232975, 0.62833491, 0.66319444, 0.6422695 , 0.63563126,\n",
      "       0.6390218 , 0.65615843, 0.64260746, 0.65251061, 0.6487836 ,\n",
      "       0.65265845, 0.6625568 , 0.63214602, 0.65964912, 0.61790695,\n",
      "       0.67340067, 0.64589757, 0.58723404, 0.63570011, 0.62514625,\n",
      "       0.62875638, 0.65292096, 0.60746403, 0.62456057, 0.6286511 ,\n",
      "       0.6286511 , 0.62653294, 0.62535877, 0.64260746, 0.63186768,\n",
      "       0.5699869 , 0.62812382, 0.65292096, 0.63501041, 0.62653294,\n",
      "       0.64589757, 0.63890235, 0.64250614, 0.68381519, 0.62145222,\n",
      "       0.62429375, 0.63563126, 0.67353952, 0.6487836 , 0.65211576,\n",
      "       0.63186768, 0.64589757, 0.64598122, 0.62653294, 0.58723404,\n",
      "       0.62653294, 0.64544519, 0.62177427, 0.68039727, 0.65977774,\n",
      "       0.63890235, 0.65285537, 0.62163121, 0.65277335, 0.62514625,\n",
      "       0.65625591, 0.61456954, 0.63910707, 0.64589757, 0.62163121,\n",
      "       0.63573453, 0.6425737 , 0.61839447, 0.59342143, 0.59392148,\n",
      "       0.5699869 , 0.6494804 , 0.62145222, 0.5829316 , 0.6487836 ,\n",
      "       0.6286511 , 0.63910707, 0.65632086, 0.61767178, 0.65635333,\n",
      "       0.65632086, 0.63910707, 0.62198866, 0.62653294, 0.5699869 ,\n",
      "       0.62535877, 0.63890235, 0.61456954, 0.62833491, 0.6457804 ,\n",
      "       0.61435062, 0.62123722, 0.63167607, 0.66178843, 0.66978723,\n",
      "       0.6390218 , 0.63563126, 0.64604811, 0.63539007, 0.67697213,\n",
      "       0.65964912, 0.64914894, 0.6320243 , 0.6218815 , 0.61139015,\n",
      "       0.6665249 , 0.65251061, 0.6732926 , 0.67006803, 0.67678892,\n",
      "       0.62514625, 0.59725327, 0.6457804 , 0.62653294, 0.6288616 ,\n",
      "       0.65972952, 0.63563126, 0.60413783, 0.66665092, 0.65251061,\n",
      "       0.62851064, 0.6182682 , 0.62653294, 0.62177427, 0.62163121,\n",
      "       0.6494804 , 0.6390218 , 0.66991209, 0.67347782, 0.68375543,\n",
      "       0.66666667, 0.63214602, 0.62456057, 0.5699869 , 0.63223292,\n",
      "       0.64544519, 0.59776715, 0.62833491, 0.6494804 , 0.5699869 ,\n",
      "       0.64944728, 0.66665092, 0.65632086, 0.62163121, 0.6665249 ,\n",
      "       0.6595365 , 0.62653294, 0.65632086, 0.62833491, 0.63915821,\n",
      "       0.64598122, 0.6425737 , 0.64603139, 0.6390218 , 0.67688055,\n",
      "       0.65635333, 0.64250614, 0.60000948, 0.61347249, 0.59841058,\n",
      "       0.61409491, 0.67347782, 0.68039727, 0.64938102, 0.6239909 ,\n",
      "       0.65977774, 0.62875638, 0.5699869 , 0.62833491, 0.64604811,\n",
      "       0.65900456, 0.62514625, 0.66665092, 0.67688055, 0.65211576,\n",
      "       0.63552793, 0.65972952, 0.67651372, 0.6735241 , 0.62653294,\n",
      "       0.64562963, 0.67632999, 0.6390218 , 0.61347249, 0.62177427]), 'split5_test_score': array([0.63073297, 0.61892521, 0.59583333, 0.62365183, 0.63745847,\n",
      "       0.63902672, 0.61044177, 0.62681475, 0.62598215, 0.62653294,\n",
      "       0.65640964, 0.59950261, 0.63140549, 0.61803597, 0.62201828,\n",
      "       0.63356719, 0.61710526, 0.61001462, 0.65497967, 0.59987102,\n",
      "       0.63039206, 0.62424831, 0.63995432, 0.63356719, 0.67383041,\n",
      "       0.61096257, 0.61070234, 0.63837719, 0.66659431, 0.61186827,\n",
      "       0.63222638, 0.64009603, 0.63851804, 0.62760769, 0.62992794,\n",
      "       0.61582995, 0.64238554, 0.62224454, 0.61892521, 0.63073297,\n",
      "       0.65183395, 0.59392148, 0.66526074, 0.63670412, 0.67613282,\n",
      "       0.62456057, 0.62201828, 0.63995432, 0.64715297, 0.58750709,\n",
      "       0.64224586, 0.59375797, 0.63529917, 0.64919254, 0.66277127,\n",
      "       0.6211168 , 0.62058142, 0.62692308, 0.62681475, 0.62908336,\n",
      "       0.60277679, 0.6309934 , 0.63850932, 0.59392148, 0.62598215,\n",
      "       0.58750709, 0.63697693, 0.61582995, 0.62207792, 0.63923159,\n",
      "       0.61803597, 0.62653294, 0.59950261, 0.66088398, 0.64009603,\n",
      "       0.60902384, 0.629372  , 0.67043373, 0.63776663, 0.63128655,\n",
      "       0.6149532 , 0.61977352, 0.6211168 , 0.64402592, 0.62012315,\n",
      "       0.63230241, 0.6455371 , 0.6211168 , 0.63776663, 0.62369932,\n",
      "       0.61892521, 0.63950829, 0.60597485, 0.62529891, 0.63155757,\n",
      "       0.64689982, 0.64766098, 0.62992794, 0.58750709, 0.62456057,\n",
      "       0.65167579, 0.63073297, 0.62908336, 0.59583333, 0.67486815,\n",
      "       0.63303909, 0.60292398, 0.60639077, 0.62324116, 0.64362404,\n",
      "       0.63385598, 0.6502786 , 0.65886761, 0.60481133, 0.63155757,\n",
      "       0.64372479, 0.63303909, 0.63073297, 0.61582995, 0.61096257,\n",
      "       0.6377894 , 0.61709114, 0.64644082, 0.64546106, 0.63291565,\n",
      "       0.63073297, 0.63437306, 0.62529891, 0.58750709, 0.63073297,\n",
      "       0.6244799 , 0.63670412, 0.63745847, 0.64171558, 0.59392148,\n",
      "       0.64236259, 0.63776663, 0.58750709, 0.61044177, 0.62598215,\n",
      "       0.62907648, 0.64857216, 0.64728111, 0.6305573 , 0.65640964,\n",
      "       0.63356719, 0.61001462, 0.61096257, 0.62812382, 0.61977352,\n",
      "       0.63218279, 0.60788812, 0.64632961, 0.6149532 , 0.62812382,\n",
      "       0.64054686, 0.64171558, 0.63155757, 0.65255848, 0.6377894 ,\n",
      "       0.63118744, 0.58750709, 0.63580343, 0.60388916, 0.65188056,\n",
      "       0.63697693, 0.66126685, 0.63697693, 0.63670412, 0.58322779,\n",
      "       0.64362404, 0.62017395, 0.62017395, 0.61403487, 0.63417932,\n",
      "       0.6263071 , 0.64919254, 0.64036505, 0.60788812, 0.62419591,\n",
      "       0.63155757, 0.59950261, 0.62456057, 0.6130744 , 0.60695295,\n",
      "       0.60693068, 0.63073297, 0.65450621, 0.61594436, 0.63795579,\n",
      "       0.64009603, 0.62886635, 0.62727704, 0.63990773, 0.58750709,\n",
      "       0.64321352, 0.62653294, 0.62017395, 0.61001462, 0.61977352]), 'split6_test_score': array([0.74225587, 0.72850951, 0.72505669, 0.72847103, 0.7384579 ,\n",
      "       0.73519506, 0.72850951, 0.728317  , 0.70320209, 0.71818311,\n",
      "       0.74895116, 0.71465533, 0.72117534, 0.70982906, 0.74182902,\n",
      "       0.75572528, 0.71368114, 0.69730496, 0.73508235, 0.7319556 ,\n",
      "       0.75243407, 0.69379648, 0.75572528, 0.75910596, 0.75582921,\n",
      "       0.74562937, 0.73793725, 0.73459283, 0.73508235, 0.7041844 ,\n",
      "       0.73539519, 0.71746235, 0.70651748, 0.72840688, 0.73539519,\n",
      "       0.71812984, 0.74225587, 0.71780984, 0.71092715, 0.74225587,\n",
      "       0.74546099, 0.66475053, 0.74534059, 0.75921986, 0.74555724,\n",
      "       0.70012437, 0.70651748, 0.74562937, 0.71804991, 0.6829572 ,\n",
      "       0.72132039, 0.71794326, 0.72132039, 0.74909349, 0.7280599 ,\n",
      "       0.73494446, 0.73875449, 0.74567744, 0.73528265, 0.71342295,\n",
      "       0.71057118, 0.7145609 , 0.7594246 , 0.66802928, 0.73875449,\n",
      "       0.6829572 , 0.71125496, 0.72159688, 0.7319556 , 0.73882853,\n",
      "       0.7488443 , 0.75601375, 0.71465533, 0.72453616, 0.74215843,\n",
      "       0.69010318, 0.72100373, 0.75507664, 0.7248227 , 0.71313705,\n",
      "       0.73858156, 0.7319556 , 0.71644168, 0.72058039, 0.71092715,\n",
      "       0.71644168, 0.74225587, 0.71313705, 0.71700664, 0.74519595,\n",
      "       0.72820137, 0.7594246 , 0.70722613, 0.72453616, 0.73193027,\n",
      "       0.75600222, 0.74838022, 0.71746235, 0.6829572 , 0.70012437,\n",
      "       0.72132039, 0.74207311, 0.71746235, 0.71812984, 0.76618773,\n",
      "       0.72080545, 0.72414447, 0.71125496, 0.73519506, 0.74567744,\n",
      "       0.74909349, 0.74215843, 0.73746439, 0.73858156, 0.74226804,\n",
      "       0.7594246 , 0.71130952, 0.74225587, 0.72850951, 0.72453616,\n",
      "       0.74570146, 0.70097443, 0.74570146, 0.74912904, 0.73538269,\n",
      "       0.73875449, 0.71794326, 0.73830935, 0.6829572 , 0.71429078,\n",
      "       0.74909349, 0.75255102, 0.71780984, 0.75600222, 0.70101681,\n",
      "       0.72492674, 0.71746235, 0.6829572 , 0.71465533, 0.7319556 ,\n",
      "       0.72505669, 0.73157521, 0.74567744, 0.74226804, 0.74225587,\n",
      "       0.73539519, 0.73875449, 0.69716178, 0.72747964, 0.74912904,\n",
      "       0.71794326, 0.73508235, 0.70740622, 0.73180357, 0.71673789,\n",
      "       0.7525744 , 0.75590998, 0.7319556 , 0.71746235, 0.74570146,\n",
      "       0.74570146, 0.66802928, 0.73193027, 0.71465533, 0.75234043,\n",
      "       0.74855892, 0.72820137, 0.73539519, 0.75544771, 0.71472273,\n",
      "       0.7490342 , 0.7248227 , 0.73104086, 0.72769914, 0.72414447,\n",
      "       0.72453616, 0.74909349, 0.74221934, 0.74207311, 0.73124467,\n",
      "       0.7319556 , 0.72159688, 0.70012437, 0.72364672, 0.7319556 ,\n",
      "       0.75527391, 0.74221934, 0.7386804 , 0.73534518, 0.76618773,\n",
      "       0.74207311, 0.74912904, 0.73538269, 0.76278575, 0.6829572 ,\n",
      "       0.73180357, 0.71818311, 0.71794326, 0.72769914, 0.7215311 ]), 'split7_test_score': array([0.59482428, 0.60181006, 0.58456736, 0.62835249, 0.6213494 ,\n",
      "       0.60578477, 0.61121075, 0.62907648, 0.62058142, 0.6309934 ,\n",
      "       0.66468216, 0.59468298, 0.59720032, 0.65640964, 0.63851804,\n",
      "       0.6073253 , 0.65107491, 0.62975322, 0.63673901, 0.59640363,\n",
      "       0.62276743, 0.62276743, 0.61918245, 0.6119394 , 0.63222638,\n",
      "       0.63923159, 0.60484563, 0.63537349, 0.64623681, 0.61977352,\n",
      "       0.62835249, 0.62592357, 0.63222638, 0.62975322, 0.59408369,\n",
      "       0.59160859, 0.58605974, 0.63923159, 0.62287894, 0.59482428,\n",
      "       0.64372479, 0.58387794, 0.64689982, 0.60855901, 0.62058142,\n",
      "       0.59445862, 0.65255617, 0.64687827, 0.65071058, 0.59392148,\n",
      "       0.61765409, 0.6373658 , 0.62084464, 0.6524128 , 0.63222638,\n",
      "       0.64166023, 0.6309934 , 0.62886635, 0.65071058, 0.62975322,\n",
      "       0.58628916, 0.62721341, 0.61765409, 0.58750709, 0.63990773,\n",
      "       0.59392148, 0.64054686, 0.59160859, 0.64811733, 0.65071058,\n",
      "       0.63607504, 0.63670412, 0.59160859, 0.64919254, 0.63463396,\n",
      "       0.6244799 , 0.62287894, 0.65007215, 0.6347586 , 0.6263071 ,\n",
      "       0.63673901, 0.59795524, 0.62324116, 0.63149897, 0.6211168 ,\n",
      "       0.59411348, 0.59301672, 0.62992794, 0.62760769, 0.64689982,\n",
      "       0.61960784, 0.62192927, 0.62201828, 0.63291565, 0.65613922,\n",
      "       0.63607504, 0.63222638, 0.64752653, 0.59392148, 0.60802061,\n",
      "       0.60108225, 0.65640964, 0.64689982, 0.58456736, 0.62975322,\n",
      "       0.62341833, 0.63923159, 0.64166023, 0.65640964, 0.59934151,\n",
      "       0.59408369, 0.64224586, 0.65255617, 0.64491817, 0.65562953,\n",
      "       0.63039206, 0.6213494 , 0.58708514, 0.60808081, 0.62058142,\n",
      "       0.61821596, 0.62658752, 0.60484563, 0.64372479, 0.63418138,\n",
      "       0.60947086, 0.62276743, 0.61355515, 0.59392148, 0.63463396,\n",
      "       0.64491817, 0.61310541, 0.63073297, 0.65324202, 0.58982529,\n",
      "       0.63607504, 0.64238554, 0.59392148, 0.59864983, 0.59301672,\n",
      "       0.6347586 , 0.6073253 , 0.61433735, 0.60751244, 0.62780162,\n",
      "       0.66355174, 0.63291565, 0.62287894, 0.60210451, 0.60108225,\n",
      "       0.63673901, 0.64166023, 0.66024723, 0.64811733, 0.60984089,\n",
      "       0.6538919 , 0.66205328, 0.64054686, 0.62836145, 0.61121075,\n",
      "       0.62886635, 0.5841728 , 0.61765409, 0.58853103, 0.62207792,\n",
      "       0.64752653, 0.63923159, 0.57910276, 0.62653294, 0.59237892,\n",
      "       0.64644082, 0.62592357, 0.62058142, 0.62760769, 0.60533454,\n",
      "       0.63537349, 0.64867256, 0.6373658 , 0.63537349, 0.63149897,\n",
      "       0.63673901, 0.59160859, 0.60802061, 0.62681475, 0.59866883,\n",
      "       0.62780162, 0.60947086, 0.65957524, 0.62835249, 0.61044177,\n",
      "       0.62836145, 0.64811733, 0.63155757, 0.66468216, 0.59392148,\n",
      "       0.63697693, 0.6309934 , 0.63291565, 0.62369932, 0.57927711]), 'split8_test_score': array([0.67494534, 0.6524128 , 0.65936455, 0.68366575, 0.66802928,\n",
      "       0.66641455, 0.6598521 , 0.67611537, 0.63627165, 0.68003452,\n",
      "       0.68675255, 0.66580534, 0.62163121, 0.6239909 , 0.65848714,\n",
      "       0.71700664, 0.62812382, 0.67199013, 0.65876221, 0.65936455,\n",
      "       0.72080545, 0.66178843, 0.67918489, 0.71644168, 0.66897336,\n",
      "       0.64522696, 0.70368002, 0.66508466, 0.6898977 , 0.64728111,\n",
      "       0.68580107, 0.6869155 , 0.67298343, 0.68249526, 0.65783817,\n",
      "       0.67166289, 0.66897336, 0.68548761, 0.6427405 , 0.6686907 ,\n",
      "       0.68548761, 0.62835249, 0.67944329, 0.67559298, 0.66897336,\n",
      "       0.61489744, 0.62812382, 0.6869155 , 0.67632999, 0.63155757,\n",
      "       0.66313079, 0.6752849 , 0.66991209, 0.70368002, 0.64468864,\n",
      "       0.66072618, 0.68249526, 0.68366575, 0.6686907 , 0.66030589,\n",
      "       0.68655974, 0.66991209, 0.71368114, 0.63155757, 0.66508466,\n",
      "       0.63155757, 0.69206349, 0.67166289, 0.68321658, 0.68939753,\n",
      "       0.66944339, 0.68366575, 0.65936455, 0.68633699, 0.65518059,\n",
      "       0.66508466, 0.64468864, 0.6725496 , 0.67857525, 0.64898297,\n",
      "       0.65876221, 0.67857525, 0.64544519, 0.65544189, 0.64764957,\n",
      "       0.61489744, 0.67228564, 0.63833817, 0.65232975, 0.66508466,\n",
      "       0.6788956 , 0.69961201, 0.65783817, 0.69629981, 0.68027645,\n",
      "       0.70368002, 0.66837607, 0.63449142, 0.63155757, 0.61489744,\n",
      "       0.6482842 , 0.65186852, 0.66178843, 0.65936455, 0.69270654,\n",
      "       0.62851064, 0.66922421, 0.63710108, 0.65054396, 0.70446386,\n",
      "       0.67130373, 0.64855072, 0.67967095, 0.67857525, 0.69716178,\n",
      "       0.72747964, 0.68633699, 0.66508466, 0.66802928, 0.65488615,\n",
      "       0.71125496, 0.66233305, 0.67697213, 0.70067746, 0.66538639,\n",
      "       0.65419717, 0.68249526, 0.63118744, 0.63155757, 0.62001425,\n",
      "       0.64436824, 0.68877745, 0.69862508, 0.66897336, 0.62835249,\n",
      "       0.64898297, 0.67586975, 0.63155757, 0.66398429, 0.64644082,\n",
      "       0.67944329, 0.65211576, 0.70755844, 0.67353952, 0.6869155 ,\n",
      "       0.69678886, 0.62692308, 0.64036505, 0.66565591, 0.6686907 ,\n",
      "       0.66072618, 0.65848714, 0.66897336, 0.68608414, 0.65876221,\n",
      "       0.72414447, 0.68300654, 0.68017065, 0.64468864, 0.70784858,\n",
      "       0.68366575, 0.63155757, 0.67666667, 0.65936455, 0.71035169,\n",
      "       0.67228564, 0.6545584 , 0.64728111, 0.68910256, 0.69716178,\n",
      "       0.6898977 , 0.64898297, 0.66641455, 0.6665249 , 0.66233305,\n",
      "       0.69988264, 0.70368002, 0.71092715, 0.66589335, 0.66398429,\n",
      "       0.6665249 , 0.65936455, 0.61489744, 0.65518059, 0.6524128 ,\n",
      "       0.71010436, 0.65746388, 0.67228564, 0.6975052 , 0.71368114,\n",
      "       0.69496855, 0.68633699, 0.68366575, 0.66508466, 0.63155757,\n",
      "       0.66438381, 0.68003452, 0.66274834, 0.67678892, 0.65012797]), 'split9_test_score': array([0.66468216, 0.63795579, 0.64546106, 0.65337336, 0.65884295,\n",
      "       0.65419717, 0.64919254, 0.67650047, 0.67003258, 0.65337336,\n",
      "       0.66580534, 0.63902672, 0.69087263, 0.68186023, 0.64224586,\n",
      "       0.67417095, 0.6824249 , 0.64433953, 0.68067748, 0.64491817,\n",
      "       0.67417095, 0.66030589, 0.6629078 , 0.67048881, 0.67697927,\n",
      "       0.67742589, 0.66355174, 0.67373569, 0.69169692, 0.65613922,\n",
      "       0.66765014, 0.66258651, 0.67486815, 0.65291031, 0.63155757,\n",
      "       0.64171558, 0.66580534, 0.67048881, 0.66355174, 0.66148588,\n",
      "       0.6958444 , 0.63155757, 0.68067748, 0.66319444, 0.68067748,\n",
      "       0.61709165, 0.68186023, 0.65232975, 0.67865374, 0.63155757,\n",
      "       0.65746388, 0.63257576, 0.66072618, 0.66355174, 0.6598521 ,\n",
      "       0.6598521 , 0.65188056, 0.68375543, 0.67373569, 0.67650047,\n",
      "       0.67457409, 0.64967758, 0.66111322, 0.63155757, 0.67223447,\n",
      "       0.63155757, 0.64867256, 0.64171558, 0.63995432, 0.68476876,\n",
      "       0.67697927, 0.65615843, 0.6347586 , 0.66902125, 0.68761927,\n",
      "       0.64433953, 0.64867256, 0.67326804, 0.64224586, 0.67373569,\n",
      "       0.66468216, 0.64811733, 0.67373569, 0.65936455, 0.67223447,\n",
      "       0.61810572, 0.66258651, 0.67048881, 0.66258651, 0.67048881,\n",
      "       0.63155757, 0.65211576, 0.63795579, 0.67742589, 0.66072618,\n",
      "       0.68149805, 0.67276773, 0.67920821, 0.63155757, 0.61709165,\n",
      "       0.65562953, 0.6778406 , 0.67822365, 0.64546106, 0.6630859 ,\n",
      "       0.65291031, 0.66954349, 0.65613922, 0.68067748, 0.66233305,\n",
      "       0.65188056, 0.66765014, 0.69262531, 0.65188056, 0.65380223,\n",
      "       0.67457409, 0.65936455, 0.66088398, 0.64491817, 0.64491817,\n",
      "       0.65544189, 0.67130373, 0.66178843, 0.6598521 , 0.66072618,\n",
      "       0.658287  , 0.66954349, 0.69737141, 0.63155757, 0.68021978,\n",
      "       0.68186139, 0.6629078 , 0.68476876, 0.66897336, 0.66313079,\n",
      "       0.67544522, 0.67973012, 0.63155757, 0.6427405 , 0.6373658 ,\n",
      "       0.64171558, 0.6630859 , 0.66538639, 0.66398429, 0.70226992,\n",
      "       0.65419717, 0.68345745, 0.6598521 , 0.6545584 , 0.66148588,\n",
      "       0.67457409, 0.67598922, 0.66954349, 0.6427405 , 0.62177427,\n",
      "       0.66765014, 0.66438381, 0.65705613, 0.66355174, 0.65544189,\n",
      "       0.65783817, 0.63155757, 0.66111322, 0.64919254, 0.68436297,\n",
      "       0.69496855, 0.68803602, 0.64596851, 0.66963103, 0.65977774,\n",
      "       0.66897336, 0.66631629, 0.64054686, 0.64114936, 0.65544189,\n",
      "       0.67373569, 0.66398429, 0.67944329, 0.66355174, 0.6630859 ,\n",
      "       0.66030589, 0.6347586 , 0.61709165, 0.67697927, 0.63850932,\n",
      "       0.66765014, 0.658287  , 0.67417095, 0.66398429, 0.67003258,\n",
      "       0.67373569, 0.66922421, 0.65337336, 0.66765014, 0.63155757,\n",
      "       0.68345745, 0.65337336, 0.65131327, 0.64433953, 0.64171558]), 'mean_test_score': array([0.63856554, 0.63770529, 0.62800934, 0.65231599, 0.64489957,\n",
      "       0.65108575, 0.63725549, 0.64685782, 0.63293489, 0.64643741,\n",
      "       0.66796284, 0.62965113, 0.63757253, 0.64313061, 0.64551742,\n",
      "       0.6622689 , 0.64253876, 0.63366612, 0.65818621, 0.63213313,\n",
      "       0.66584705, 0.63866812, 0.65160628, 0.66282851, 0.66051696,\n",
      "       0.64434033, 0.64721057, 0.64783393, 0.66658996, 0.63270777,\n",
      "       0.65613137, 0.65192919, 0.63939475, 0.65030579, 0.63849581,\n",
      "       0.63351945, 0.64439306, 0.64067141, 0.63421698, 0.63654556,\n",
      "       0.66331428, 0.617461  , 0.66491077, 0.64613459, 0.65511031,\n",
      "       0.61514926, 0.64214652, 0.65758313, 0.65080572, 0.61909278,\n",
      "       0.65368791, 0.64362104, 0.65488068, 0.67235511, 0.64228699,\n",
      "       0.63888445, 0.64207112, 0.66049863, 0.65184826, 0.64407232,\n",
      "       0.63739703, 0.65289621, 0.6641497 , 0.61797391, 0.64777089,\n",
      "       0.61520224, 0.65140237, 0.63438311, 0.65561897, 0.6635437 ,\n",
      "       0.65025733, 0.65149212, 0.62961057, 0.65917996, 0.64895794,\n",
      "       0.63127627, 0.63576761, 0.66589227, 0.64767467, 0.63683589,\n",
      "       0.64630616, 0.63238918, 0.63827415, 0.63423959, 0.62966997,\n",
      "       0.61762037, 0.64539558, 0.63674205, 0.63522187, 0.6523826 ,\n",
      "       0.63982764, 0.66005021, 0.63678772, 0.64342797, 0.65289632,\n",
      "       0.67044079, 0.65286986, 0.63851137, 0.61909278, 0.61650453,\n",
      "       0.64364883, 0.64773373, 0.63763741, 0.6281673 , 0.66619674,\n",
      "       0.62943823, 0.64305764, 0.63173265, 0.65247196, 0.66045554,\n",
      "       0.64375596, 0.65482594, 0.66166584, 0.64246957, 0.65723026,\n",
      "       0.67307734, 0.64752356, 0.63592318, 0.6380812 , 0.62927418,\n",
      "       0.66304646, 0.64370507, 0.66238988, 0.6698281 , 0.65643263,\n",
      "       0.63854107, 0.6408289 , 0.6444789 , 0.61520224, 0.63701576,\n",
      "       0.65685656, 0.6522288 , 0.6458318 , 0.66680817, 0.63035197,\n",
      "       0.64462989, 0.64757646, 0.61909278, 0.63134414, 0.63660744,\n",
      "       0.64037537, 0.64600798, 0.66377312, 0.66224467, 0.66339497,\n",
      "       0.66083417, 0.64364986, 0.63338987, 0.6285421 , 0.63672288,\n",
      "       0.64415787, 0.63698059, 0.649137  , 0.64963464, 0.62284224,\n",
      "       0.67279527, 0.67003886, 0.65334992, 0.63845907, 0.66165185,\n",
      "       0.65636149, 0.61699971, 0.6512027 , 0.62920805, 0.66897462,\n",
      "       0.66130623, 0.65663323, 0.63919399, 0.65427538, 0.64952674,\n",
      "       0.66404039, 0.64534976, 0.63742216, 0.63575648, 0.63571845,\n",
      "       0.64480699, 0.66906749, 0.67129687, 0.64769578, 0.63805731,\n",
      "       0.65368856, 0.62907295, 0.61650453, 0.64202626, 0.63742647,\n",
      "       0.65804531, 0.64047672, 0.66682713, 0.66113807, 0.6622467 ,\n",
      "       0.65471993, 0.66547575, 0.65752762, 0.66695588, 0.61909278,\n",
      "       0.65012546, 0.64577022, 0.64593292, 0.63621175, 0.63439848]), 'std_test_score': array([0.05090592, 0.04406006, 0.04393172, 0.05051242, 0.05371344,\n",
      "       0.05199624, 0.04015493, 0.05189673, 0.04413476, 0.06047124,\n",
      "       0.0460541 , 0.04041893, 0.05097315, 0.05006973, 0.05262902,\n",
      "       0.05975957, 0.04936349, 0.04948915, 0.04045863, 0.04549751,\n",
      "       0.05603262, 0.04560585, 0.04864314, 0.05819507, 0.0470102 ,\n",
      "       0.05581352, 0.06037986, 0.05081349, 0.04554723, 0.04734832,\n",
      "       0.05129287, 0.04225123, 0.0373716 , 0.04358039, 0.04504928,\n",
      "       0.04224587, 0.04833263, 0.05169553, 0.04891834, 0.05035723,\n",
      "       0.04908554, 0.04280386, 0.04017376, 0.05250138, 0.04865432,\n",
      "       0.04548742, 0.04730141, 0.05568124, 0.03856176, 0.04490274,\n",
      "       0.03787685, 0.05000763, 0.03923731, 0.04891591, 0.05363335,\n",
      "       0.05075188, 0.05018761, 0.05415248, 0.05863405, 0.04235193,\n",
      "       0.04961355, 0.03634933, 0.05770397, 0.04321791, 0.04710211,\n",
      "       0.0441295 , 0.04499067, 0.04224561, 0.04693992, 0.04692086,\n",
      "       0.05697351, 0.06621213, 0.04030877, 0.03809954, 0.04921552,\n",
      "       0.04820417, 0.04388216, 0.04282043, 0.046359  , 0.04620136,\n",
      "       0.052922  , 0.05171542, 0.04674965, 0.04861616, 0.04549738,\n",
      "       0.04887961, 0.04756381, 0.0449596 , 0.04742214, 0.05541741,\n",
      "       0.0487996 , 0.05221822, 0.04701751, 0.05419953, 0.04502263,\n",
      "       0.04642972, 0.05380791, 0.04795281, 0.04490274, 0.04505071,\n",
      "       0.0465804 , 0.05526484, 0.05323722, 0.04208   , 0.05619625,\n",
      "       0.05169249, 0.04521758, 0.04254762, 0.04253232, 0.04928996,\n",
      "       0.04899866, 0.04720849, 0.04275206, 0.04791635, 0.04985192,\n",
      "       0.05623044, 0.04691802, 0.05069208, 0.04283948, 0.04494085,\n",
      "       0.04427269, 0.04024834, 0.04765091, 0.05011275, 0.05018599,\n",
      "       0.04627388, 0.05290206, 0.05102718, 0.0441295 , 0.04334403,\n",
      "       0.04744327, 0.05035981, 0.05272228, 0.0522849 , 0.04497761,\n",
      "       0.05344963, 0.0467518 , 0.04490274, 0.03931919, 0.04453632,\n",
      "       0.04592   , 0.04778541, 0.04809209, 0.04606359, 0.05100589,\n",
      "       0.04361701, 0.04623521, 0.04797752, 0.05249951, 0.05264801,\n",
      "       0.04712857, 0.05332821, 0.03972521, 0.04889762, 0.04896316,\n",
      "       0.05440046, 0.0488202 , 0.04855431, 0.05446705, 0.04470016,\n",
      "       0.05449   , 0.0438543 , 0.04874025, 0.04002742, 0.05062803,\n",
      "       0.0441479 , 0.04164669, 0.04550226, 0.04651385, 0.05770457,\n",
      "       0.05449447, 0.04964081, 0.04567174, 0.04287128, 0.05167392,\n",
      "       0.05257663, 0.05000453, 0.04659492, 0.05143342, 0.05097077,\n",
      "       0.04646916, 0.04235837, 0.04505071, 0.04143055, 0.04474481,\n",
      "       0.05697534, 0.04660213, 0.04196648, 0.05068128, 0.05919827,\n",
      "       0.05198556, 0.05057358, 0.05512646, 0.05427698, 0.04490274,\n",
      "       0.05223097, 0.06009977, 0.05037829, 0.04475725, 0.04393257]), 'rank_test_score': array([133, 141, 186,  66, 102,  74, 147,  91, 169,  92,  10, 178, 143,\n",
      "       116,  99,  29, 118, 166,  42, 172,  17, 132,  70,  27,  37, 107,\n",
      "        90,  83,  14, 170,  51,  68, 129,  76, 136, 167, 106, 125, 165,\n",
      "       155,  25, 194,  19,  94,  53, 200, 121,  44,  75, 188,  59, 114,\n",
      "        54,   3, 120, 131, 122,  38,  69, 109, 146,  62,  20, 192,  84,\n",
      "       198,  72, 163,  52,  23,  77,  71, 179,  41,  82, 175, 158,  16,\n",
      "        87, 150,  93, 171, 138, 164, 177, 193, 100, 152, 161,  65, 128,\n",
      "        40, 151, 115,  61,   5,  63, 135, 188, 196, 113,  85, 142, 185,\n",
      "        15, 180, 117, 173,  64,  39, 110,  55,  32, 119,  46,   1,  89,\n",
      "       157, 139, 181,  26, 111,  28,   7,  49, 134, 124, 105, 198, 148,\n",
      "        47,  67,  97,  13, 176, 104,  88, 188, 174, 154, 127,  95,  22,\n",
      "        31,  24,  36, 112, 168, 184, 153, 108, 149,  81,  79, 187,   2,\n",
      "         6,  60, 137,  33,  50, 195,  73, 182,   9,  34,  48, 130,  57,\n",
      "        80,  21, 101, 145, 159, 160, 103,   8,   4,  86, 140,  58, 183,\n",
      "       196, 123, 144,  43, 126,  12,  35,  30,  56,  18,  45,  11, 188,\n",
      "        78,  98,  96, 156, 162], dtype=int32), 'split0_train_score': array([0.91595343, 0.84237648, 0.86252954, 0.74194698, 0.99961449,\n",
      "       0.83871899, 0.86517608, 0.98459925, 0.99961449, 0.73669437,\n",
      "       0.89469076, 0.86735644, 0.99961449, 0.99961449, 0.9783861 ,\n",
      "       0.72055713, 0.99961449, 0.99961449, 0.99768785, 0.85763719,\n",
      "       0.75550388, 0.99961449, 0.70866899, 0.73004842, 0.97576581,\n",
      "       0.9976875 , 0.70309304, 0.99961449, 0.90639279, 0.99961449,\n",
      "       0.94573921, 0.99961449, 0.99961449, 0.93229354, 0.89349161,\n",
      "       0.87595061, 0.89070114, 0.99961449, 0.99961449, 0.9163325 ,\n",
      "       0.96457828, 0.65398126, 0.81033202, 0.70758997, 0.98652723,\n",
      "       0.67168739, 0.99961449, 0.7667499 , 0.99884366, 0.65057129,\n",
      "       0.82290472, 0.95910118, 0.81901318, 0.79239971, 0.99961449,\n",
      "       0.99961449, 0.95177412, 0.7496474 , 0.99344641, 0.99961449,\n",
      "       0.99961449, 0.81855097, 0.7382851 , 0.65057129, 0.99961449,\n",
      "       0.65057129, 0.96108753, 0.8774964 , 0.90087772, 0.95772257,\n",
      "       0.99614583, 0.75827702, 0.86735644, 0.97459239, 0.99961449,\n",
      "       0.99961449, 0.99961449, 0.90251163, 0.96565767, 1.        ,\n",
      "       0.99961449, 0.92020045, 0.99961449, 0.99961449, 0.99961449,\n",
      "       0.67168739, 0.89147085, 0.99961449, 0.99961449, 0.98882035,\n",
      "       0.95409626, 0.72837445, 0.99961449, 0.99961449, 0.85378674,\n",
      "       0.80831521, 0.99961449, 0.99114006, 0.65057129, 0.67206026,\n",
      "       0.99961449, 0.99576074, 0.99961449, 0.86400561, 0.76867916,\n",
      "       0.99961449, 0.99961449, 0.99961449, 0.96614214, 0.80644658,\n",
      "       0.90694486, 0.98076521, 0.92995636, 0.94831416, 0.8714827 ,\n",
      "       0.77518095, 0.97420189, 0.91631949, 0.87296621, 1.        ,\n",
      "       0.80955   , 0.99961449, 0.80491349, 0.79434053, 0.9442379 ,\n",
      "       0.90710749, 0.99961449, 0.99961449, 0.65057129, 0.99961449,\n",
      "       0.97577873, 0.71375396, 0.99961449, 0.83718663, 0.66217786,\n",
      "       0.99922905, 0.99961449, 0.65057129, 0.86850496, 0.88471621,\n",
      "       0.9413805 , 0.99961449, 0.81214857, 0.79287705, 0.94276556,\n",
      "       0.88675124, 0.99961449, 0.99961449, 0.68663898, 0.9136797 ,\n",
      "       0.99961449, 0.99961449, 0.99961449, 0.94419209, 0.6811572 ,\n",
      "       0.78888664, 0.85213401, 0.85190925, 0.99961449, 0.80955   ,\n",
      "       0.74516606, 0.65057129, 0.84737119, 0.86587989, 0.78869425,\n",
      "       0.99614757, 0.99807277, 0.87617791, 0.70952651, 0.66639977,\n",
      "       0.7652423 , 0.99922905, 0.99961449, 0.99961449, 0.7005496 ,\n",
      "       0.99961449, 0.7778601 , 0.81981597, 0.98843217, 0.99961449,\n",
      "       0.85153375, 0.86660648, 0.67206026, 0.99961449, 0.84170351,\n",
      "       0.71075741, 0.90674324, 0.93893178, 0.78441726, 0.73342798,\n",
      "       0.99807306, 0.82591403, 0.74194698, 0.87803743, 0.65057129,\n",
      "       0.99884348, 0.73629536, 0.99845786, 0.99961449, 0.88486838]), 'split1_train_score': array([0.90875908, 0.84780477, 0.86431146, 0.70993987, 0.99961449,\n",
      "       0.83730671, 0.86603923, 0.98073783, 1.        , 0.70681622,\n",
      "       0.87363871, 0.86556432, 1.        , 1.        , 0.98069872,\n",
      "       0.72545104, 1.        , 1.        , 0.99922905, 0.8624389 ,\n",
      "       0.74607586, 1.        , 0.69913566, 0.73168917, 0.97613563,\n",
      "       0.99653099, 0.69461079, 1.        , 0.89534842, 1.        ,\n",
      "       0.93771264, 0.99961449, 1.        , 0.91702479, 0.89644116,\n",
      "       0.87133526, 0.8862934 , 1.        , 1.        , 0.91107877,\n",
      "       0.96882015, 0.67245724, 0.79650026, 0.69612583, 0.98921636,\n",
      "       0.67274587, 1.        , 0.7522736 , 0.99845833, 0.62981579,\n",
      "       0.82283044, 0.95020678, 0.81560928, 0.7925203 , 1.        ,\n",
      "       1.        , 0.94437535, 0.74036392, 0.98920833, 1.        ,\n",
      "       1.        , 0.81600473, 0.73423489, 0.64905894, 0.99961449,\n",
      "       0.62981579, 0.95415943, 0.87281506, 0.88777264, 0.95614468,\n",
      "       0.99691524, 0.7422963 , 0.86676412, 0.9788285 , 0.99922905,\n",
      "       1.        , 1.        , 0.90038402, 0.95596382, 1.        ,\n",
      "       0.99961449, 0.91653467, 1.        , 1.        , 1.        ,\n",
      "       0.67274587, 0.88401581, 1.        , 1.        , 0.98650524,\n",
      "       0.94786501, 0.72238457, 1.        , 1.        , 0.85827563,\n",
      "       0.81432778, 0.99961449, 0.98805478, 0.62981579, 0.67274587,\n",
      "       0.99961449, 0.9915259 , 1.        , 0.86581008, 0.76844454,\n",
      "       1.        , 1.        , 1.        , 0.96533322, 0.78721291,\n",
      "       0.90143911, 0.97843585, 0.92917671, 0.93707268, 0.87269154,\n",
      "       0.77081523, 0.97534076, 0.9114731 , 0.86870799, 1.        ,\n",
      "       0.7948507 , 1.        , 0.77538352, 0.78596745, 0.93310752,\n",
      "       0.90617261, 0.99961449, 1.        , 0.62981579, 0.99961449,\n",
      "       0.97343939, 0.70317874, 1.        , 0.81917295, 0.67245724,\n",
      "       0.99922893, 1.        , 0.62981579, 0.8710125 , 0.88197114,\n",
      "       0.92888769, 0.99961449, 0.79854061, 0.77605975, 0.9388938 ,\n",
      "       0.88041578, 0.99961449, 1.        , 0.68242424, 0.91076125,\n",
      "       1.        , 1.        , 0.99961449, 0.93025535, 0.67274587,\n",
      "       0.79538445, 0.84291087, 0.85061214, 1.        , 0.79447621,\n",
      "       0.73117934, 0.62981579, 0.8440553 , 0.86396297, 0.78106286,\n",
      "       0.99653151, 0.99576264, 0.87662888, 0.70214411, 0.67464972,\n",
      "       0.75409002, 0.99884348, 1.        , 1.        , 0.69953739,\n",
      "       1.        , 0.7721836 , 0.80694917, 0.98727637, 1.        ,\n",
      "       0.8510051 , 0.8652649 , 0.67274587, 1.        , 0.84889934,\n",
      "       0.70201294, 0.90538464, 0.93042995, 0.76726401, 0.73272189,\n",
      "       0.99807277, 0.81539273, 0.71257496, 0.87191452, 0.62981579,\n",
      "       0.99807306, 0.70681622, 0.99845786, 1.        , 0.88528381]), 'split2_train_score': array([0.88537633, 0.83312844, 0.85681689, 0.72504178, 0.99961467,\n",
      "       0.8074901 , 0.84611069, 0.97732089, 0.99961467, 0.72462863,\n",
      "       0.87992207, 0.86048695, 0.99961467, 1.        , 0.97647681,\n",
      "       0.71542219, 1.        , 1.        , 0.99845905, 0.84926778,\n",
      "       0.74599955, 0.99961467, 0.70238456, 0.72179443, 0.96847357,\n",
      "       0.99499452, 0.70171575, 0.99961467, 0.90555359, 1.        ,\n",
      "       0.92939894, 0.99961467, 0.99961467, 0.90399436, 0.87271773,\n",
      "       0.86053532, 0.85928446, 0.99961467, 1.        , 0.8868825 ,\n",
      "       0.95775227, 0.64163982, 0.81233728, 0.69820679, 0.98960703,\n",
      "       0.68152597, 1.        , 0.75017577, 0.99922941, 0.64163982,\n",
      "       0.8032172 , 0.93803605, 0.80245001, 0.78430854, 0.99961467,\n",
      "       1.        , 0.93143801, 0.72833403, 0.98806734, 0.99961467,\n",
      "       0.99961467, 0.80245001, 0.72586309, 0.64163982, 0.9988442 ,\n",
      "       0.64163982, 0.94999172, 0.86240723, 0.87896722, 0.94894673,\n",
      "       0.99191423, 0.73587863, 0.86051122, 0.98038   , 0.99845905,\n",
      "       0.99961467, 0.99961467, 0.89851384, 0.94678783, 1.        ,\n",
      "       0.99768857, 0.89731487, 1.        , 1.        , 0.99961467,\n",
      "       0.68152597, 0.86082233, 0.99961467, 1.        , 0.97997955,\n",
      "       0.93606017, 0.71693614, 0.99961467, 0.99961467, 0.82308032,\n",
      "       0.80605945, 0.99961467, 0.98613353, 0.64163982, 0.68152597,\n",
      "       0.99961467, 0.98653529, 0.99961467, 0.86083678, 0.76448759,\n",
      "       0.99961467, 0.99961467, 1.        , 0.95658077, 0.766831  ,\n",
      "       0.87669679, 0.97347344, 0.91928308, 0.92499279, 0.839626  ,\n",
      "       0.75212927, 0.96846931, 0.88571472, 0.84735218, 0.99961467,\n",
      "       0.76888732, 0.99961467, 0.7675483 , 0.78891324, 0.93322039,\n",
      "       0.87634803, 0.99961467, 0.99961467, 0.64163982, 0.99961467,\n",
      "       0.96581561, 0.70927887, 0.99961467, 0.83085859, 0.66894568,\n",
      "       0.99768857, 0.99961467, 0.64163982, 0.86086125, 0.85389384,\n",
      "       0.91316388, 0.9988442 , 0.77942296, 0.76031009, 0.94700489,\n",
      "       0.85888793, 0.99961467, 1.        , 0.68190065, 0.89093614,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.92204823, 0.68152597,\n",
      "       0.77938329, 0.85565041, 0.81731047, 0.99961467, 0.76877948,\n",
      "       0.72497967, 0.64163982, 0.81057861, 0.86051122, 0.77715785,\n",
      "       0.99730313, 0.99691856, 0.84425858, 0.70804439, 0.67860705,\n",
      "       0.75360714, 0.99768857, 0.99961467, 0.99961467, 0.6826348 ,\n",
      "       0.99961467, 0.77411568, 0.7963578 , 0.98306209, 0.99961467,\n",
      "       0.81688345, 0.85711933, 0.68152597, 1.        , 0.83514309,\n",
      "       0.70633533, 0.87672394, 0.92715346, 0.76034015, 0.72272452,\n",
      "       0.99537853, 0.82214927, 0.72504178, 0.87557196, 0.64163982,\n",
      "       0.99768892, 0.72462863, 0.99653364, 0.99961467, 0.86784126]), 'split3_train_score': array([0.89571802, 0.82530668, 0.85041271, 0.71381464, 0.99961467,\n",
      "       0.80371637, 0.84255013, 0.97611886, 0.99961467, 0.71499013,\n",
      "       0.87773895, 0.86038814, 0.99961467, 1.        , 0.98071097,\n",
      "       0.7173203 , 1.        , 1.        , 0.99961467, 0.84079122,\n",
      "       0.74945871, 0.99961467, 0.71758463, 0.7227039 , 0.97999389,\n",
      "       0.99230095, 0.69961937, 0.99961467, 0.9007528 , 1.        ,\n",
      "       0.93113765, 0.99961467, 0.99961467, 0.90942059, 0.87713686,\n",
      "       0.85522504, 0.87089613, 0.99961467, 1.        , 0.89805271,\n",
      "       0.96808695, 0.6294467 , 0.80895087, 0.70288324, 0.99306572,\n",
      "       0.66920849, 1.        , 0.74947908, 0.99961467, 0.62735183,\n",
      "       0.79556121, 0.94058978, 0.79545299, 0.79111744, 0.99961467,\n",
      "       0.99961467, 0.93940769, 0.73092381, 0.98265769, 0.99961467,\n",
      "       0.99961467, 0.79434769, 0.73889278, 0.6294467 , 0.99922929,\n",
      "       0.61837852, 0.95219371, 0.86116161, 0.88681459, 0.95614659,\n",
      "       0.99421834, 0.73630218, 0.85916424, 0.97690619, 0.99961467,\n",
      "       0.99961467, 0.99961467, 0.89889151, 0.95023026, 1.        ,\n",
      "       0.99922929, 0.90038648, 1.        , 0.99961467, 1.        ,\n",
      "       0.66920849, 0.87202254, 1.        , 0.99961467, 0.9799646 ,\n",
      "       0.94059936, 0.72413454, 0.99961467, 0.99961467, 0.8464286 ,\n",
      "       0.81227662, 0.99961467, 0.99152477, 0.6265126 , 0.66920849,\n",
      "       0.99961467, 0.9907543 , 0.99961467, 0.85908635, 0.76601623,\n",
      "       0.99961467, 0.99961467, 1.        , 0.96420201, 0.77204263,\n",
      "       0.88100048, 0.98268581, 0.92501339, 0.93054819, 0.86181894,\n",
      "       0.77150064, 0.9626119 , 0.89655999, 0.84486557, 1.        ,\n",
      "       0.77464678, 0.99961467, 0.77112811, 0.78861681, 0.92997863,\n",
      "       0.88365433, 0.99961467, 0.99961467, 0.61837852, 0.99961467,\n",
      "       0.9699737 , 0.72528612, 0.99961467, 0.82542572, 0.6294467 ,\n",
      "       0.99922929, 0.99961467, 0.6265126 , 0.8627331 , 0.85702124,\n",
      "       0.92237446, 0.99961467, 0.78744367, 0.7721202 , 0.94311379,\n",
      "       0.87375493, 0.99961467, 1.        , 0.67340477, 0.89332696,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.92480293, 0.67035094,\n",
      "       0.79458138, 0.8469975 , 0.83221305, 0.99961467, 0.7742817 ,\n",
      "       0.72788514, 0.6294467 , 0.82028398, 0.86038814, 0.77943818,\n",
      "       0.99768857, 0.99730354, 0.84489769, 0.7186866 , 0.66105942,\n",
      "       0.7504763 , 0.99961467, 0.99961467, 1.        , 0.67378559,\n",
      "       0.99961467, 0.76834906, 0.79846595, 0.97957775, 0.99961467,\n",
      "       0.83225354, 0.85285906, 0.66920849, 0.99961467, 0.82483387,\n",
      "       0.71107174, 0.88365433, 0.93234256, 0.77330644, 0.73255404,\n",
      "       0.99807396, 0.8098658 , 0.71308851, 0.87521565, 0.6265126 ,\n",
      "       0.99845882, 0.7149883 , 0.99845858, 1.        , 0.86936417]), 'split4_train_score': array([0.89743162, 0.83764275, 0.85536719, 0.7248371 , 0.99961467,\n",
      "       0.8261732 , 0.85746206, 0.97689267, 0.99961467, 0.72420016,\n",
      "       0.87076574, 0.86526277, 0.99961467, 1.        , 0.97956827,\n",
      "       0.73177719, 1.        , 0.99961467, 0.99845905, 0.85164967,\n",
      "       0.75243528, 0.99961467, 0.71584002, 0.73776089, 0.9776855 ,\n",
      "       0.99537853, 0.70223595, 0.99961467, 0.89304428, 1.        ,\n",
      "       0.92996876, 0.99961467, 0.99961467, 0.91754663, 0.87457005,\n",
      "       0.86927279, 0.87505605, 0.99961467, 1.        , 0.89971321,\n",
      "       0.96919022, 0.62898572, 0.80479299, 0.71119686, 0.98998831,\n",
      "       0.67180041, 1.        , 0.75682626, 0.99845905, 0.62898572,\n",
      "       0.81610937, 0.94907695, 0.81145656, 0.79269749, 0.99961467,\n",
      "       1.        , 0.94487287, 0.73916709, 0.98573634, 0.99961467,\n",
      "       0.99961467, 0.81145656, 0.7507342 , 0.62898572, 0.9988442 ,\n",
      "       0.62898572, 0.94909332, 0.86920975, 0.88693555, 0.95577713,\n",
      "       0.99344846, 0.74983275, 0.86484261, 0.97767918, 0.99922941,\n",
      "       0.99961467, 1.        , 0.90310081, 0.95447788, 1.        ,\n",
      "       0.99922941, 0.9074571 , 1.        , 0.99961467, 0.99961467,\n",
      "       0.67180041, 0.87348413, 0.99961467, 0.99961467, 0.98188692,\n",
      "       0.94831373, 0.73978244, 0.99961467, 1.        , 0.85108914,\n",
      "       0.81126366, 0.99961467, 0.98921497, 0.62898572, 0.67180041,\n",
      "       0.99961467, 0.99229983, 1.        , 0.85976266, 0.76928765,\n",
      "       0.99961467, 0.99961467, 1.        , 0.9687981 , 0.78060613,\n",
      "       0.89158684, 0.97882297, 0.9265314 , 0.93333868, 0.86243285,\n",
      "       0.77404924, 0.96415923, 0.89972926, 0.86383043, 1.        ,\n",
      "       0.78709693, 0.99961467, 0.77658116, 0.79155839, 0.9269211 ,\n",
      "       0.8905423 , 0.99961467, 0.99961467, 0.62898572, 0.99961467,\n",
      "       0.97382323, 0.72554862, 0.99961467, 0.81509733, 0.65574092,\n",
      "       0.99922941, 0.99961467, 0.62898572, 0.86528524, 0.86801997,\n",
      "       0.92365211, 0.99961467, 0.78891324, 0.77255284, 0.94082307,\n",
      "       0.87629819, 0.99961467, 1.        , 0.67180041, 0.89977669,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.9289932 , 0.67180041,\n",
      "       0.79090473, 0.83668779, 0.84335717, 0.99961467, 0.7870829 ,\n",
      "       0.73470486, 0.62898572, 0.83298095, 0.86252562, 0.781163  ,\n",
      "       0.99653312, 0.99691856, 0.85169254, 0.71765181, 0.66732593,\n",
      "       0.76696192, 0.9988442 , 0.99961467, 0.99961467, 0.69707049,\n",
      "       1.        , 0.77894682, 0.7998537 , 0.98071408, 1.        ,\n",
      "       0.84337608, 0.86118565, 0.67180041, 0.99961467, 0.83726941,\n",
      "       0.71121504, 0.89013125, 0.94311379, 0.76772723, 0.74018883,\n",
      "       0.99768822, 0.80585687, 0.72524463, 0.86575025, 0.62898572,\n",
      "       0.99807337, 0.72451313, 0.99807337, 1.        , 0.8703354 ]), 'split5_train_score': array([0.88937749, 0.84798521, 0.85996497, 0.74317194, 0.99961467,\n",
      "       0.82435805, 0.8643986 , 0.98844287, 0.99961467, 0.73082224,\n",
      "       0.88399623, 0.86592076, 0.99961467, 1.        , 0.97337463,\n",
      "       0.71564333, 1.        , 1.        , 0.99845905, 0.85732003,\n",
      "       0.74985915, 1.        , 0.71489677, 0.72619843, 0.98190592,\n",
      "       0.99653312, 0.70014671, 0.99961467, 0.8961075 , 1.        ,\n",
      "       0.93969719, 0.99961467, 1.        , 0.93061463, 0.87267112,\n",
      "       0.86959893, 0.88095255, 0.99961467, 1.        , 0.88937749,\n",
      "       0.96496165, 0.67260445, 0.80062341, 0.70822435, 0.9930678 ,\n",
      "       0.69639356, 1.        , 0.76919923, 0.99922941, 0.67110061,\n",
      "       0.82222839, 0.95562439, 0.82555259, 0.79698253, 0.99961467,\n",
      "       0.99961467, 0.94519223, 0.76001313, 0.99190816, 0.99961467,\n",
      "       0.99961467, 0.82462285, 0.73871107, 0.67260445, 0.99922941,\n",
      "       0.67110061, 0.95221598, 0.86959893, 0.90823551, 0.9581013 ,\n",
      "       0.99422012, 0.76511512, 0.8642555 , 0.9761499 , 0.9988442 ,\n",
      "       1.        , 0.99961467, 0.90652948, 0.95832892, 1.        ,\n",
      "       0.99961467, 0.90521715, 1.        , 1.        , 1.        ,\n",
      "       0.69616477, 0.88102362, 0.99961467, 1.        , 0.98419432,\n",
      "       0.95213175, 0.72588161, 0.99961467, 0.99961467, 0.86755268,\n",
      "       0.80712347, 0.99961467, 0.98881685, 0.67110061, 0.69639356,\n",
      "       0.99961467, 0.99075707, 1.        , 0.85996497, 0.76716498,\n",
      "       1.        , 0.99961467, 1.        , 0.96534923, 0.79838888,\n",
      "       0.88026884, 0.97999107, 0.9269704 , 0.9409119 , 0.87983765,\n",
      "       0.76902849, 0.97223713, 0.89124481, 0.86615298, 1.        ,\n",
      "       0.80321208, 0.99961467, 0.78541529, 0.79275893, 0.93660025,\n",
      "       0.88704721, 0.99961467, 0.99961467, 0.67110061, 0.99961467,\n",
      "       0.97191647, 0.71574795, 0.99961467, 0.8366956 , 0.67260445,\n",
      "       0.99961467, 0.99961467, 0.67110061, 0.86709144, 0.86837736,\n",
      "       0.92548916, 0.99961467, 0.81074407, 0.78114716, 0.94006227,\n",
      "       0.89523124, 0.99961467, 1.        , 0.69651788, 0.9048246 ,\n",
      "       0.99961467, 1.        , 0.99961467, 0.94181585, 0.69692914,\n",
      "       0.78759585, 0.85151044, 0.85610364, 0.99961467, 0.80355189,\n",
      "       0.74928023, 0.67110061, 0.84416247, 0.86153591, 0.77649887,\n",
      "       0.99807396, 0.99691856, 0.86008825, 0.7131353 , 0.6749088 ,\n",
      "       0.77035738, 0.99884385, 0.99961467, 1.        , 0.70286364,\n",
      "       0.99961467, 0.78435219, 0.81835167, 0.98304697, 0.99961467,\n",
      "       0.85687109, 0.8642555 , 0.69639356, 1.        , 0.84826699,\n",
      "       0.70798633, 0.88670562, 0.933889  , 0.78089435, 0.72757199,\n",
      "       0.99691856, 0.83022511, 0.74755709, 0.87958544, 0.67110061,\n",
      "       0.9969181 , 0.73085122, 0.99884385, 1.        , 0.87271773]), 'split6_train_score': array([0.90326845, 0.83136135, 0.85395513, 0.71847767, 0.99961467,\n",
      "       0.80961681, 0.85113652, 0.98075237, 0.99961467, 0.71534991,\n",
      "       0.87425726, 0.8589411 , 0.99961467, 1.        , 0.98033307,\n",
      "       0.70795229, 1.        , 0.99961467, 0.99961467, 0.84723086,\n",
      "       0.73932832, 0.99961467, 0.69582938, 0.70820782, 0.97806245,\n",
      "       0.99499452, 0.68736353, 0.99961467, 0.88970856, 1.        ,\n",
      "       0.93734415, 0.99961467, 0.99961467, 0.91914819, 0.87444315,\n",
      "       0.86156075, 0.87994644, 0.99961467, 1.        , 0.90512845,\n",
      "       0.96882559, 0.63108661, 0.79408644, 0.68880192, 0.99152731,\n",
      "       0.69107944, 1.        , 0.75109978, 0.99807337, 0.62277938,\n",
      "       0.80625734, 0.94917886, 0.80553843, 0.78319266, 0.99961467,\n",
      "       1.        , 0.94522798, 0.73026772, 0.98844461, 0.99961467,\n",
      "       0.99961467, 0.80167171, 0.7207417 , 0.63064201, 0.99845905,\n",
      "       0.62277938, 0.95458868, 0.86607946, 0.89252584, 0.95041347,\n",
      "       0.99306572, 0.74088827, 0.85816817, 0.98036312, 0.9988442 ,\n",
      "       0.99961467, 1.        , 0.89860545, 0.95912689, 1.        ,\n",
      "       0.99922941, 0.91056997, 1.        , 0.99961467, 0.99961467,\n",
      "       0.68543667, 0.8791939 , 0.99961467, 0.99961467, 0.98459739,\n",
      "       0.94949893, 0.71741405, 0.99961467, 0.99961467, 0.86528609,\n",
      "       0.80128804, 0.99961467, 0.98574728, 0.62277938, 0.69107944,\n",
      "       0.99961467, 0.99576271, 1.        , 0.85764248, 0.75576166,\n",
      "       0.99961467, 0.99961467, 1.        , 0.96268872, 0.78054724,\n",
      "       0.89055917, 0.97614657, 0.92148104, 0.93566044, 0.88064733,\n",
      "       0.75980291, 0.97305332, 0.90514353, 0.85325769, 1.        ,\n",
      "       0.79956018, 0.99961467, 0.76867332, 0.78236243, 0.93543494,\n",
      "       0.89488495, 0.99961467, 0.99961467, 0.62277938, 0.99961467,\n",
      "       0.97114706, 0.70498353, 0.99961467, 0.8282424 , 0.65883328,\n",
      "       0.99845905, 0.99961467, 0.62277938, 0.86350644, 0.86200021,\n",
      "       0.92480293, 0.99961467, 0.80066832, 0.75634499, 0.94045788,\n",
      "       0.88592399, 0.99961467, 0.99961467, 0.68932993, 0.90336989,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.92991814, 0.68407607,\n",
      "       0.78266798, 0.85215617, 0.8539408 , 0.99961467, 0.79877941,\n",
      "       0.72738484, 0.63064201, 0.84193315, 0.85572133, 0.77260188,\n",
      "       0.99730313, 0.99807396, 0.84312833, 0.69655304, 0.66038744,\n",
      "       0.75269608, 0.99961467, 1.        , 1.        , 0.69180133,\n",
      "       0.99961467, 0.77296669, 0.80929437, 0.98305462, 1.        ,\n",
      "       0.85321047, 0.8548511 , 0.69107944, 1.        , 0.83140365,\n",
      "       0.69607039, 0.89488495, 0.92472223, 0.75623367, 0.71895064,\n",
      "       0.99653364, 0.81943703, 0.7227675 , 0.86941034, 0.62277938,\n",
      "       0.99768857, 0.71534096, 0.99884402, 1.        , 0.87475311]), 'split7_train_score': array([0.90840767, 0.84855967, 0.86210564, 0.737149  , 0.99961467,\n",
      "       0.83433411, 0.8663326 , 0.98345533, 0.99961467, 0.73133338,\n",
      "       0.8844305 , 0.86592076, 0.99961467, 0.99961467, 0.97802625,\n",
      "       0.72513537, 0.99961467, 0.99961467, 0.99845905, 0.86224266,\n",
      "       0.75606937, 0.99961467, 0.71308851, 0.724374  , 0.97115107,\n",
      "       0.99691902, 0.69786655, 0.99961467, 0.89387232, 0.99961467,\n",
      "       0.93242858, 0.99961467, 0.99961467, 0.92773913, 0.88157491,\n",
      "       0.87310881, 0.89174523, 0.99961467, 0.99961467, 0.90840767,\n",
      "       0.9588422 , 0.66383567, 0.81455126, 0.71679826, 0.98767791,\n",
      "       0.68510098, 0.99961467, 0.76452255, 0.99768857, 0.64929689,\n",
      "       0.82619325, 0.94914091, 0.8197015 , 0.78838418, 0.99961467,\n",
      "       0.99961467, 0.94606672, 0.74864394, 0.98844461, 0.99961467,\n",
      "       0.99961467, 0.81985977, 0.75096336, 0.6618228 , 0.99922941,\n",
      "       0.64929689, 0.95650352, 0.87310881, 0.90198011, 0.95469092,\n",
      "       0.99267656, 0.75349561, 0.86631872, 0.9761432 , 0.99922941,\n",
      "       0.99961467, 0.99961467, 0.90734926, 0.95336845, 0.99961467,\n",
      "       0.99961467, 0.91615158, 0.99961467, 0.99961467, 0.99961467,\n",
      "       0.69130881, 0.89134163, 0.99961467, 0.99961467, 0.983431  ,\n",
      "       0.94759973, 0.73215443, 0.99961467, 0.99961467, 0.85785817,\n",
      "       0.81192022, 0.99961467, 0.9907543 , 0.64929689, 0.67522894,\n",
      "       0.99961467, 0.99114673, 0.99961467, 0.86210564, 0.77814662,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.96110554, 0.8017701 ,\n",
      "       0.89669289, 0.97499412, 0.9238441 , 0.94029266, 0.8740406 ,\n",
      "       0.77168445, 0.96845632, 0.90647677, 0.86982869, 0.99961467,\n",
      "       0.808319  , 0.99961467, 0.79302787, 0.78747794, 0.93742344,\n",
      "       0.90577317, 0.99961467, 0.99961467, 0.64929689, 0.99961467,\n",
      "       0.97038177, 0.72215613, 0.99961467, 0.83417794, 0.67197198,\n",
      "       0.9988442 , 0.99961467, 0.64929689, 0.87073191, 0.87215836,\n",
      "       0.93033867, 0.99961467, 0.81012186, 0.78520041, 0.94242456,\n",
      "       0.89274042, 0.99922941, 0.99961467, 0.71244948, 0.90970338,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.93923747, 0.70703546,\n",
      "       0.79663824, 0.85223753, 0.85605281, 0.99961467, 0.808319  ,\n",
      "       0.74607304, 0.65505   , 0.85114093, 0.8642555 , 0.78526422,\n",
      "       0.99576397, 0.99691902, 0.86145963, 0.71311095, 0.67593929,\n",
      "       0.76826345, 0.99922941, 0.99961467, 0.99961467, 0.71492057,\n",
      "       0.99961467, 0.77957849, 0.81281691, 0.98304954, 0.99961467,\n",
      "       0.85603552, 0.86631872, 0.67522894, 0.99961467, 0.84770911,\n",
      "       0.70752029, 0.90500397, 0.93129738, 0.77890287, 0.73207305,\n",
      "       0.99730313, 0.82497041, 0.73907783, 0.87281445, 0.64929689,\n",
      "       0.99807396, 0.73207217, 0.9988442 , 0.99961467, 0.87888441]), 'split8_train_score': array([0.89662746, 0.84020834, 0.85953831, 0.72338399, 0.99961467,\n",
      "       0.81785416, 0.86589743, 0.98459739, 0.99961467, 0.72071529,\n",
      "       0.8673139 , 0.86348203, 0.99961467, 0.99961467, 0.97957145,\n",
      "       0.72086701, 0.99961467, 0.99961467, 0.99922941, 0.85731976,\n",
      "       0.74771275, 0.99961467, 0.70326012, 0.72449925, 0.97613639,\n",
      "       0.99499378, 0.70143895, 0.99961467, 0.9011715 , 0.99961467,\n",
      "       0.93620358, 0.99961467, 0.99961467, 0.90597337, 0.88522056,\n",
      "       0.87095506, 0.86723906, 0.99961467, 0.99961467, 0.90089412,\n",
      "       0.96461929, 0.6290924 , 0.79844973, 0.69995923, 0.99037123,\n",
      "       0.66430324, 0.99961467, 0.75055111, 0.99922941, 0.6286093 ,\n",
      "       0.8122304 , 0.93992983, 0.81169812, 0.78378076, 0.99961467,\n",
      "       0.99961467, 0.93788428, 0.72300645, 0.98959461, 0.99961467,\n",
      "       0.99961467, 0.80977009, 0.73005535, 0.6286093 , 0.99961467,\n",
      "       0.6286093 , 0.95417386, 0.87212518, 0.88180626, 0.9458427 ,\n",
      "       0.99383337, 0.73344727, 0.86156075, 0.97768235, 0.99922941,\n",
      "       0.99961467, 1.        , 0.89775856, 0.95064379, 1.        ,\n",
      "       0.99961467, 0.90632243, 1.        , 0.99961467, 0.99961467,\n",
      "       0.66391325, 0.867201  , 0.99961467, 0.99961467, 0.98689993,\n",
      "       0.94368511, 0.72005559, 0.99961467, 0.99961467, 0.84854775,\n",
      "       0.80827795, 0.99961467, 0.98921334, 0.6286093 , 0.66430324,\n",
      "       0.99961467, 0.99268322, 0.99961467, 0.86033769, 0.76792672,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.96765453, 0.77801854,\n",
      "       0.88725912, 0.97462507, 0.92459237, 0.92788794, 0.85768729,\n",
      "       0.76414326, 0.97073071, 0.90051638, 0.86781818, 1.        ,\n",
      "       0.7770422 , 0.99961467, 0.77140803, 0.78006023, 0.93274912,\n",
      "       0.88702947, 0.99961467, 0.99961467, 0.6286093 , 0.99961467,\n",
      "       0.97078816, 0.70703492, 0.99961467, 0.81498147, 0.6290924 ,\n",
      "       0.9988442 , 0.99961467, 0.6286093 , 0.87015983, 0.87435544,\n",
      "       0.92328463, 0.99961467, 0.78562958, 0.76671647, 0.94353814,\n",
      "       0.86763062, 0.99961467, 0.99961467, 0.6955844 , 0.89939904,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.92061686, 0.69694821,\n",
      "       0.78192396, 0.84349331, 0.84014649, 0.99961467, 0.77669152,\n",
      "       0.72186172, 0.6286093 , 0.83028326, 0.85871236, 0.77483138,\n",
      "       0.99768857, 0.99730354, 0.85558989, 0.70476459, 0.66740444,\n",
      "       0.75316265, 0.9988442 , 1.        , 1.        , 0.69597805,\n",
      "       0.99961467, 0.772001  , 0.79820116, 0.98613353, 0.99961467,\n",
      "       0.83903825, 0.86076236, 0.66430324, 0.99961467, 0.84090044,\n",
      "       0.70528313, 0.88624033, 0.92550879, 0.76173621, 0.730147  ,\n",
      "       0.99768857, 0.80852648, 0.72300161, 0.8632701 , 0.6286093 ,\n",
      "       0.99807367, 0.72071529, 0.99807367, 1.        , 0.88250505]), 'split9_train_score': array([0.89072482, 0.83752637, 0.86693781, 0.70180491, 0.99961467,\n",
      "       0.80969259, 0.86137654, 0.98230229, 0.99961467, 0.70265802,\n",
      "       0.87300213, 0.86891823, 0.99961467, 0.99961467, 0.97996154,\n",
      "       0.72633119, 0.99961467, 0.99961467, 0.99961467, 0.85606867,\n",
      "       0.75062764, 0.99961467, 0.70504332, 0.72937929, 0.9749976 ,\n",
      "       0.99845858, 0.70368584, 0.99961467, 0.89407372, 0.99961467,\n",
      "       0.91972429, 0.99961467, 0.99961467, 0.90548281, 0.87927981,\n",
      "       0.87316906, 0.86275388, 0.99961467, 0.99961467, 0.89458613,\n",
      "       0.96961246, 0.62847871, 0.8051646 , 0.69757763, 0.99037688,\n",
      "       0.66079564, 0.99961467, 0.74849971, 0.99922941, 0.62847871,\n",
      "       0.80926387, 0.94568558, 0.80923459, 0.78082978, 0.99961467,\n",
      "       0.99961467, 0.94597309, 0.73300192, 0.98690389, 0.99961467,\n",
      "       0.99961467, 0.80569056, 0.7419686 , 0.62847871, 0.99961467,\n",
      "       0.62847871, 0.94424829, 0.87427592, 0.86979937, 0.94817901,\n",
      "       0.99537358, 0.74848327, 0.86852235, 0.97460045, 0.99961467,\n",
      "       0.99961467, 0.99961467, 0.90200586, 0.95371379, 0.99961467,\n",
      "       0.99961467, 0.90386943, 0.99961467, 0.99961467, 0.99961467,\n",
      "       0.67313946, 0.86279026, 0.99961467, 0.99961467, 0.9792003 ,\n",
      "       0.9467449 , 0.73323592, 0.99961467, 0.99961467, 0.83510108,\n",
      "       0.80166042, 0.99961467, 0.98690971, 0.62847871, 0.66079564,\n",
      "       0.99961467, 0.99191423, 0.99961467, 0.86804157, 0.76790049,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.96231698, 0.77526382,\n",
      "       0.88454672, 0.97499412, 0.93312026, 0.93141729, 0.84970609,\n",
      "       0.76338303, 0.96535928, 0.8945683 , 0.86741744, 0.99961467,\n",
      "       0.78052185, 0.99961467, 0.7694028 , 0.78045756, 0.92587905,\n",
      "       0.88582734, 0.99961467, 0.99961467, 0.62847871, 0.99961467,\n",
      "       0.9684861 , 0.71610348, 0.99961467, 0.80816217, 0.6649071 ,\n",
      "       0.99961467, 0.99961467, 0.62847871, 0.87046037, 0.87392026,\n",
      "       0.92280596, 0.99961467, 0.78426744, 0.76324442, 0.93628318,\n",
      "       0.86210134, 0.99961467, 0.99961467, 0.70426995, 0.89813735,\n",
      "       0.99961467, 0.99961467, 0.99961467, 0.9178393 , 0.67354228,\n",
      "       0.77991396, 0.83796124, 0.8240275 , 0.99961467, 0.78052185,\n",
      "       0.70546675, 0.62847871, 0.82092188, 0.86808429, 0.77903844,\n",
      "       0.99845905, 0.99807396, 0.8531526 , 0.71276586, 0.66940075,\n",
      "       0.75113405, 0.99922929, 0.99961467, 0.99961467, 0.71121931,\n",
      "       0.99961467, 0.77244513, 0.79618632, 0.98151137, 0.99961467,\n",
      "       0.8247755 , 0.86741744, 0.66079564, 0.99961467, 0.83794673,\n",
      "       0.71230011, 0.88390806, 0.9213636 , 0.75903367, 0.73712799,\n",
      "       0.99807396, 0.8023862 , 0.70173286, 0.85219764, 0.62847871,\n",
      "       0.99807396, 0.70223156, 0.99845858, 0.99961467, 0.87421506]), 'mean_train_score': array([0.89916444, 0.83919001, 0.85919397, 0.72395679, 0.99961464,\n",
      "       0.82092611, 0.85864799, 0.98152198, 0.99965319, 0.72082083,\n",
      "       0.87797563, 0.86422415, 0.99965319, 0.99984585, 0.97871078,\n",
      "       0.7206457 , 0.99984585, 0.99976879, 0.99888265, 0.85419668,\n",
      "       0.74930705, 0.99969172, 0.70757319, 0.72566556, 0.97603078,\n",
      "       0.99587915, 0.69917765, 0.99965319, 0.89760255, 0.99984585,\n",
      "       0.9339355 , 0.99961464, 0.99969172, 0.91692381, 0.8807547 ,\n",
      "       0.86807116, 0.87648683, 0.99965319, 0.99984585, 0.90104535,\n",
      "       0.96552891, 0.64516086, 0.80457889, 0.70273641, 0.99014258,\n",
      "       0.6764641 , 0.99984585, 0.7559377 , 0.99880553, 0.63786293,\n",
      "       0.81367962, 0.94765703, 0.81157073, 0.78862134, 0.99965319,\n",
      "       0.99976879, 0.94322123, 0.73833694, 0.9884412 , 0.99965319,\n",
      "       0.99965319, 0.81044249, 0.73704502, 0.64218597, 0.99922939,\n",
      "       0.6369656 , 0.9528256 , 0.86982783, 0.88957148, 0.95319651,\n",
      "       0.99418115, 0.74640164, 0.86374641, 0.97733253, 0.99919086,\n",
      "       0.99969172, 0.99976879, 0.90156504, 0.95482993, 0.99992293,\n",
      "       0.99930644, 0.90840241, 0.99988438, 0.99973025, 0.99973025,\n",
      "       0.67769311, 0.87633661, 0.99969172, 0.99973025, 0.98354796,\n",
      "       0.94665949, 0.72603537, 0.99965319, 0.99969172, 0.85070062,\n",
      "       0.80825128, 0.99961464, 0.98875096, 0.63777901, 0.67551418,\n",
      "       0.99961464, 0.991914  , 0.99976879, 0.86175938, 0.76738156,\n",
      "       0.99969172, 0.99965319, 0.99984585, 0.96401712, 0.78471278,\n",
      "       0.88969948, 0.97749342, 0.92599691, 0.93504367, 0.8649971 ,\n",
      "       0.76717175, 0.96946199, 0.90077464, 0.86221974, 0.9998844 ,\n",
      "       0.7903687 , 0.99965319, 0.77834819, 0.78725135, 0.93355523,\n",
      "       0.89243869, 0.99961464, 0.99965319, 0.6369656 , 0.99961464,\n",
      "       0.97115502, 0.71430723, 0.99965319, 0.82500008, 0.65861776,\n",
      "       0.9989982 , 0.99965319, 0.63777901, 0.8670347 , 0.8696434 ,\n",
      "       0.925618  , 0.99953759, 0.79579003, 0.77265734, 0.94153671,\n",
      "       0.87797357, 0.99957611, 0.99980732, 0.68943207, 0.9023915 ,\n",
      "       0.99965319, 0.99969172, 0.99961464, 0.92997194, 0.68361116,\n",
      "       0.78778805, 0.84717392, 0.84256733, 0.99965319, 0.7902034 ,\n",
      "       0.73139816, 0.63943399, 0.83437117, 0.86215772, 0.77957509,\n",
      "       0.99714926, 0.99722651, 0.85670743, 0.70963832, 0.66960826,\n",
      "       0.75859913, 0.99899814, 0.99973025, 0.99980732, 0.69703608,\n",
      "       0.99969172, 0.77527987, 0.8056293 , 0.98358585, 0.99973025,\n",
      "       0.84249828, 0.86166405, 0.67551418, 0.99976879, 0.83940761,\n",
      "       0.70705527, 0.89193803, 0.93087525, 0.76898559, 0.73074879,\n",
      "       0.99738044, 0.81647239, 0.72520338, 0.87037678, 0.63777901,\n",
      "       0.99799659, 0.72084528, 0.99830456, 0.99984585, 0.87607684]), 'std_train_score': array([9.24471676e-03, 7.39249495e-03, 4.80960753e-03, 1.29971046e-02,\n",
      "       7.18184559e-08, 1.24266897e-02, 8.50601115e-03, 3.75038399e-03,\n",
      "       1.15603654e-04, 1.03845386e-02, 7.64316130e-03, 3.12442636e-03,\n",
      "       1.15603654e-04, 1.88792179e-04, 2.18320897e-03, 6.51175728e-03,\n",
      "       1.88792179e-04, 1.88784850e-04, 6.31910780e-04, 6.53094679e-03,\n",
      "       4.68491471e-03, 1.54139195e-04, 7.17535608e-03, 7.39881266e-03,\n",
      "       3.73057784e-03, 1.65107948e-03, 4.68876980e-03, 1.15603654e-04,\n",
      "       5.29079650e-03, 1.88792179e-04, 6.72255319e-03, 7.18184559e-08,\n",
      "       1.54139195e-04, 1.01008007e-02, 8.07587308e-03, 6.32770581e-03,\n",
      "       1.07994707e-02, 1.15603654e-04, 1.88792179e-04, 8.91314750e-03,\n",
      "       4.06897665e-03, 1.78334887e-02, 6.63935694e-03, 7.84680768e-03,\n",
      "       1.98595549e-03, 1.10246681e-02, 1.88792179e-04, 7.50562982e-03,\n",
      "       5.83017888e-04, 1.43753176e-02, 9.58563793e-03, 6.43108170e-03,\n",
      "       8.47435032e-03, 5.04479564e-03, 1.15603654e-04, 1.88784850e-04,\n",
      "       5.31661210e-03, 1.09198297e-02, 2.86808732e-03, 1.15603654e-04,\n",
      "       1.15603654e-04, 9.00202015e-03, 9.27722509e-03, 1.50690169e-02,\n",
      "       3.85184138e-04, 1.52564894e-02, 4.29876700e-03, 4.98208786e-03,\n",
      "       1.10469419e-02, 4.19391705e-03, 1.48542097e-03, 9.92697764e-03,\n",
      "       3.46962099e-03, 1.97280340e-03, 3.63388792e-04, 1.54139195e-04,\n",
      "       1.88784850e-04, 3.20394413e-03, 5.06057396e-03, 1.54130209e-04,\n",
      "       5.66139593e-04, 7.02266023e-03, 1.76605769e-04, 1.76590099e-04,\n",
      "       1.76590099e-04, 9.89504834e-03, 1.03812405e-02, 1.54139195e-04,\n",
      "       1.76590099e-04, 3.10720703e-03, 5.06273016e-03, 7.02559734e-03,\n",
      "       1.15603654e-04, 1.54139195e-04, 1.28223476e-02, 4.16736988e-03,\n",
      "       7.18184559e-08, 1.93898208e-03, 1.44387462e-02, 1.06297528e-02,\n",
      "       7.18184559e-08, 2.50407035e-03, 1.88784850e-04, 3.08565456e-03,\n",
      "       5.17888233e-03, 1.54139195e-04, 1.15603654e-04, 1.88792179e-04,\n",
      "       3.35524373e-03, 1.26696461e-02, 9.24454950e-03, 2.91983537e-03,\n",
      "       3.88339055e-03, 6.56568968e-03, 1.26326614e-02, 6.86567722e-03,\n",
      "       4.16061670e-03, 8.84737899e-03, 9.45744899e-03, 1.76578337e-04,\n",
      "       1.39769394e-02, 1.15603654e-04, 1.17201525e-02, 4.76692648e-03,\n",
      "       5.08505352e-03, 1.01454189e-02, 7.18184559e-08, 1.15603654e-04,\n",
      "       1.52564894e-02, 7.18184559e-08, 2.68433753e-03, 7.76571857e-03,\n",
      "       1.15603654e-04, 9.64600377e-03, 1.56697490e-02, 5.50155002e-04,\n",
      "       1.15603654e-04, 1.44387462e-02, 3.53953791e-03, 9.46576443e-03,\n",
      "       6.81876435e-03, 2.31130543e-04, 1.16139037e-02, 1.09204516e-02,\n",
      "       2.77711986e-03, 1.18569738e-02, 1.15568070e-04, 1.92680722e-04,\n",
      "       1.23264642e-02, 7.10702458e-03, 1.15603654e-04, 1.54139195e-04,\n",
      "       7.18184559e-08, 8.68103881e-03, 1.20386609e-02, 6.21596283e-03,\n",
      "       6.26343157e-03, 1.31975998e-02, 1.15603654e-04, 1.40391536e-02,\n",
      "       1.25247145e-02, 1.41118850e-02, 1.28884555e-02, 3.41028600e-03,\n",
      "       4.54974426e-03, 8.29659031e-04, 6.84567325e-04, 1.15232281e-02,\n",
      "       6.58673868e-03, 5.94206607e-03, 7.59660943e-03, 5.22546372e-04,\n",
      "       1.76590099e-04, 1.92680722e-04, 1.16193205e-02, 1.54139195e-04,\n",
      "       4.51669161e-03, 8.63096562e-03, 2.70827188e-03, 1.76590099e-04,\n",
      "       1.32155390e-02, 4.94486928e-03, 1.06297528e-02, 1.88784850e-04,\n",
      "       7.39151954e-03, 4.74852124e-03, 1.00353566e-02, 6.30304152e-03,\n",
      "       9.43649110e-03, 5.99943228e-03, 8.39920103e-04, 9.00319105e-03,\n",
      "       1.35663491e-02, 7.78152590e-03, 1.44387462e-02, 4.80959053e-04,\n",
      "       1.04906503e-02, 6.48877358e-04, 1.88792179e-04, 6.11240374e-03])}\n",
      "------- Ranks(lower is good) -------\n",
      "[133 141 186  66 102  74 147  91 169  92  10 178 143 116  99  29 118 166\n",
      "  42 172  17 132  70  27  37 107  90  83  14 170  51  68 129  76 136 167\n",
      " 106 125 165 155  25 194  19  94  53 200 121  44  75 188  59 114  54   3\n",
      " 120 131 122  38  69 109 146  62  20 192  84 198  72 163  52  23  77  71\n",
      " 179  41  82 175 158  16  87 150  93 171 138 164 177 193 100 152 161  65\n",
      " 128  40 151 115  61   5  63 135 188 196 113  85 142 185  15 180 117 173\n",
      "  64  39 110  55  32 119  46   1  89 157 139 181  26 111  28   7  49 134\n",
      " 124 105 198 148  47  67  97  13 176 104  88 188 174 154 127  95  22  31\n",
      "  24  36 112 168 184 153 108 149  81  79 187   2   6  60 137  33  50 195\n",
      "  73 182   9  34  48 130  57  80  21 101 145 159 160 103   8   4  86 140\n",
      "  58 183 196 123 144  43 126  12  35  30  56  18  45  11 188  78  98  96\n",
      " 156 162]\n",
      "--- Best Location ---\n",
      "115\n",
      "------- Best Score -------\n",
      "0.6730773376859407\n",
      "------- Best Params -------\n",
      "{'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.03}\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "# !pip install scikit-learn\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "sys.path.append('xgboost/wrapper/')\n",
    "import xgboost as xgb\n",
    "\n",
    "# USER INPUT\n",
    "acc_type = 'f1_macro'\n",
    "    # 'f1_micro', 'f1_macro', 'f1_weighted', \n",
    "    # refer: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring\n",
    "cv_folds = 10\n",
    "# also change 'objective': 'multi:softprob' as appropriate\n",
    "search_type = 'RandomizedSearchCV' # 'RandomizedSearchCV', 'GridSearchCV'\n",
    "iters_rand_search = 200 # applies for 'RandomizedSearchCV'\n",
    "# set algo seach 'parameters' below\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [100, 200, 300, 400], # no of trees\n",
    "    'learning_rate': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.6, 0.9],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18], # doesn't work for too small values like [1, 2]\n",
    "#     'gamma': [0, 0.2],\n",
    "#     min_child_weight=1,\n",
    "#     max_delta_step=0,\n",
    "#     subsample=1,\n",
    "#     'colsample_bytree': [0.7, 0.8, 1],\n",
    "#     colsample_bylevel=1,\n",
    "#     colsample_bynode=1,\n",
    "#     reg_alpha=0,\n",
    "#     reg_lambda=1,\n",
    "#     scale_pos_weight=1,\n",
    "}\n",
    "\n",
    "if search_type == 'GridSearchCV':\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs=1, cv=cv_folds, scoring=acc_type)\n",
    "elif search_type == 'RandomizedSearchCV':\n",
    "    clf = RandomizedSearchCV(clf, parameters, n_jobs=1, \n",
    "                             cv=cv_folds, n_iter=iters_rand_search, scoring=acc_type)\n",
    "    # 'n_iter' in random_search allows to do limited searches in a bigger search space\n",
    "        # say 100 random searches in a search space of 10,000\n",
    "        \n",
    "clf.fit(X_Train, Y_Train)\n",
    "print(clf.cv_results_)\n",
    "\n",
    "print(\"------- Ranks(lower is good) -------\")\n",
    "print(clf.cv_results_['rank_test_score'])\n",
    "\n",
    "list1 = list(clf.cv_results_['mean_test_score'])\n",
    "best_loc = list1.index( max(list1) )\n",
    "\n",
    "print(\"--- Best Location ---\")\n",
    "print(best_loc)\n",
    "\n",
    "print(\"------- Best Score -------\")\n",
    "print(clf.cv_results_['mean_test_score'][best_loc])\n",
    "print(\"------- Best Params -------\")\n",
    "print(clf.cv_results_['params'][best_loc])\n",
    "\n",
    "# Insight: Even after 5 fold CV, model may seem to overfit for acc. metrics \n",
    "    # affected by skewed target like 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction (class)\n",
    "y_pred = common_predictions(clf, X_Vald, Y_Vald)\n",
    "\n",
    "## Prediction (probabilities)\n",
    "    # use 'predict_proba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[234  88]\n",
      " [120 209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       354\n",
      "           1       0.64      0.70      0.67       297\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       651\n",
      "   macro avg       0.68      0.68      0.68       651\n",
      "weighted avg       0.68      0.68      0.68       651\n",
      "\n",
      "first_class_f1: 0.69\n",
      "last_class_f1: 0.67\n",
      "micro_f1: 0.68\n",
      "macro_f1: 0.68\n",
      "wtd_f1: 0.68\n"
     ]
    }
   ],
   "source": [
    "## Validation Accuracy\n",
    "cm1 = confusion_matrix(y_pred, Y_Vald)\n",
    "print(cm1)\n",
    "print(classification_report(Y_Vald, y_pred))\n",
    "\n",
    "# get micro_f1, macro_f1, weighted_f1 (use to optimize params)\n",
    "temp = classification_report(Y_Vald, y_pred)\n",
    "list1 = temp.split()\n",
    "\n",
    "first_class_f1 = list1[7]\n",
    "last_class_f1 = list1[len(list1)-20]\n",
    "micro_f1 = list1[len(list1)-14]\n",
    "macro_f1 = list1[len(list1)-8]\n",
    "wtd_f1 = list1[len(list1)-2]\n",
    "\n",
    "print(\"first_class_f1: {}\".format(first_class_f1))\n",
    "print(\"last_class_f1: {}\".format(last_class_f1))\n",
    "print(\"micro_f1: {}\".format(micro_f1))\n",
    "print(\"macro_f1: {}\".format(macro_f1))\n",
    "print(\"wtd_f1: {}\".format(wtd_f1))\n",
    "\n",
    "# use micro_f1 for skewed multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Only use k-fold CV for any param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################\n",
    "############# XGBoost (Regression) ##############\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 0.598257\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "model = xgb_classifier(X_Train, Y_Train, max_depth=6, learning_rate=0.3, \n",
    "                       n_estimators=150, objective='reg:linear')\n",
    "y_pred = common_predictions(model, X_Vald, Y_Vald)\n",
    "\n",
    "# Validation\n",
    "rmse = np.sqrt(mean_squared_error(Y_Vald, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1783,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search - not running\n",
    "# Ref: https://stats.stackexchange.com/questions/183984/how-to-use-xgboost-cv-with-hyperparameters-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
