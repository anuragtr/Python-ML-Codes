{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ### Anaconda & Python Version:\n",
    "\n",
    "The version of the notebook server is 5.0.0 and is running on:\n",
    "Python 3.6.6 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
    "\n",
    "Current Kernel Information:\n",
    "Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\n",
    "\n",
    "#### Anaconda 5.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Versions of Libraries: (Code: 'pip list' in anaconda prompt)\n",
    "# Check version of anaconda - 'conda list anaconda$' or 'conda info' in anaconda command prompt\n",
    "# Check version of python - 'python' in anaconda command prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem: Recommendation System for like/not-like recommendations\n",
    "### Problem Type: \n",
    "### Steps:\n",
    "#### 0. \n",
    "#### 1. \n",
    "#### 2. Note: Should have a validation set also\n",
    "#### 3. \n",
    "#### 4. \n",
    "#### 5. \n",
    "#### 6. \n",
    "#### 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## install pytorch:\n",
    "# pytorch - (wrapper library over torch) is easiest and fastest for Boltzmann Machines, compared to tensorflow, keras\n",
    "# pytorch - developed by Facebook AI research group, good for NLP, DL on GPUs\n",
    "# keras - (wrapper library over tensorflow/theano), makes DL more intuitive and easy to use but no enhancement in speed\n",
    "\n",
    "# installing pytorch:\n",
    "# go to: https://pytorch.org/; select Stable, Windows, Pip, 3.6, None;\n",
    "# change 'pip3' to 'pip' in below link:\n",
    "# run \"pip install http://download.pytorch.org/whl/cpu/torch-0.4.1-cp36-cp36m-win_amd64.whl\" in anaconda cmd\n",
    "# succefully installs: torch-0.4.1            # although author installed 'torch 0.1.10.post1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## standard datasets for movie recommendation system:\n",
    "# link - https://grouplens.org/datasets/movielens/\n",
    "# for this problem, download 'ml-100k.zip' and 'ml-1m.zip' (same on grouplens and superdatascience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Special Note: Here we are going to work on torch tensors and not tensorflow tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>Movie_Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID              Movie_Title                   Movie_Genre\n",
       "0         1         Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3  Grumpier Old Men (1995)                Comedy|Romance"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset:\n",
    "movies = pd.read_csv('C:/Users/anurag.trivedi/2. Data/5. Boltzmann Machines/Boltzmann_Machines/ml-1m/movies.dat',\n",
    "                     sep='::',header=None,engine='python',encoding='latin-1')\n",
    "# movie names have ',', separator is '::', movie names may have special character so encoder 'utf-8' not used\n",
    "# movies.head(3) # 4000 movies\n",
    "movies=movies.rename(columns = {0:'Movie_ID'})\n",
    "movies=movies.rename(columns = {1:'Movie_Title'})\n",
    "movies=movies.rename(columns = {2:'Movie_Genre'})\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job_Code</th>\n",
       "      <th>Zip_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Gender  Age  Job_Code Zip_Code\n",
       "0        1      F    1        10    48067\n",
       "1        2      M   56        16    70072\n",
       "2        3      M   25        15    55117"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset:\n",
    "users = pd.read_csv('C:/Users/anurag.trivedi/2. Data/5. Boltzmann Machines/Boltzmann_Machines/ml-1m/users.dat',\n",
    "                     sep='::',header=None,engine='python',encoding='latin-1')\n",
    "users.head(3) # 6000 users; ID, Gender, Age, Job Code, Zip Code\n",
    "users=users.rename(columns = {0:'User_ID'})\n",
    "users=users.rename(columns = {1:'Gender'})\n",
    "users=users.rename(columns = {2:'Age'})\n",
    "users=users.rename(columns = {3:'Job_Code'})\n",
    "users=users.rename(columns = {4:'Zip_Code'})\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time_Stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Movie_ID  Rating  Time_Stamp\n",
       "0        1      1193       5   978300760\n",
       "1        1       661       3   978302109\n",
       "2        1       914       3   978301968"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset:\n",
    "ratings = pd.read_csv('C:/Users/anurag.trivedi/2. Data/5. Boltzmann Machines/Boltzmann_Machines/ml-1m/ratings.dat',\n",
    "                     sep='::',header=None,engine='python',encoding='latin-1')\n",
    "# ratings.head(3) # 1,000,000 ratings; User, Movie, Rating, timestamp when user rated movie\n",
    "ratings=ratings.rename(columns = {0:'User_ID'})\n",
    "ratings=ratings.rename(columns = {1:'Movie_ID'})\n",
    "ratings=ratings.rename(columns = {2:'Rating'})\n",
    "ratings=ratings.rename(columns = {3:'Time_Stamp'})\n",
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#######################################################################################\n",
    "############################### Data Pre-Processing ###################################\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## reduce Train-Univ size (for faster execution)\n",
    "# remove users\n",
    "ratings_small = ratings.head(300000)\n",
    "ratings_small # 1779 users, ~4000 movies\n",
    "ratings = ratings_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normal train test split\n",
    "# 'same user same set' will not work for recomm engine because a user should have watched some movies for recomm to generate\n",
    "\n",
    "# random sampling\n",
    "np.random.seed(4)\n",
    "msk = np.random.rand(len(ratings)) < 0.75                        \n",
    "Train = ratings[msk] # generates random sample of nearly 75%        \n",
    "Test = ratings[~msk]\n",
    "\n",
    "# drop Time_Stamp as not required\n",
    "Train = Train.drop(['Time_Stamp'], axis=1)\n",
    "Test = Test.drop(['Time_Stamp'], axis=1)\n",
    "\n",
    "# save Train & Test as csv\n",
    "Train.to_csv('C:/Users/anurag.trivedi/2. Data/5. Boltzmann Machines/Boltzmann_Machines/Train.csv', sep=',')\n",
    "Test.to_csv('C:/Users/anurag.trivedi/2. Data/5. Boltzmann Machines/Boltzmann_Machines/Test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## converting train-test to np array\n",
    "Train_arr = np.array(Train, dtype='int')\n",
    "Test_arr = np.array(Test, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating Train & Test user-movie 2d array - list of lists, a row represents list of a user with all movie ratings\n",
    "# list of lists is required to create train/test torch tensors for NN\n",
    "# each matrix will have all train-test users and movies as rows and columns respectively\n",
    "# If user did not rate a movie, 0 will be put there\n",
    "\n",
    "# getting the number of user and movies\n",
    "frames = [Train, Test]\n",
    "Train_Test_concat = pd.concat(frames) # 300,000 rows \n",
    "nb_users = Train_Test_concat.iloc[:,0].nunique() # total no. of users = 1779\n",
    "nb_movies = Train_Test_concat.iloc[:,1].nunique() # total no. of movies = 3569\n",
    "\n",
    "# function to create list of lists for train/test - same structure of all_users*all_movies\n",
    "\n",
    "Train_Test_concat = Train_Test_concat.sort_values(['User_ID','Movie_ID'], ascending=[True,True])\n",
    "\n",
    "def convert(Data):\n",
    "    # create dataframe of user-movie(row*col) -> convert to list of list -> convert to torch tensor\n",
    "    Data_list = Train_Test_concat[['User_ID', 'Movie_ID']]\n",
    "    Data_list = pd.merge(Data_list, Data, how='left', on=['User_ID', 'Movie_ID'])\n",
    "    # Train_list/Test _list # 300,000 rows\n",
    "    \n",
    "    Data_list['Rating'].fillna(0, inplace=True) # replace NA with 0 - did not watch\n",
    "    # Train_list/Test_list # ratings will be correct only w.r.t. train/test set\n",
    "    # Transpose\n",
    "    Data_list = Data_list.pivot_table(index=['User_ID'],columns=['Movie_ID'],values='Rating',aggfunc='first',fill_value=0)\n",
    "    \n",
    "    # creating list of lists\n",
    "    Temp = []\n",
    "    for i in range(len(Data_list.index)):\n",
    "        Temp1 = []\n",
    "        for j in range(len(Data_list.columns)):\n",
    "            Temp1.append(Data_list.iloc[i,j])\n",
    "        Temp.append(Temp1)\n",
    "    return Temp\n",
    "\n",
    "Train_list = convert(Train) \n",
    "Test_list = convert(Test) \n",
    "# Temp # list of list is created with 1779 lists and 3569 values in each list\n",
    "\n",
    "# check the structure using pd df\n",
    "# Temp2 = pd.DataFrame(Train_list)\n",
    "# Temp2 # 1779 × 3569\n",
    "# Temp2 = pd.DataFrame(Test_list)\n",
    "# Temp2 # 1779 × 3569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## converting data into torch tensors\n",
    "# torch tensors are basically multi-dimensional arrays with same datatype, but compatible to torch\n",
    "# author says NN with torch tensors performed better than NN with tensorflow  tensors (for BM and Autoencoders)\n",
    "Train_torchtensor = torch.FloatTensor(Train_list)\n",
    "Test_torchtensor = torch.FloatTensor(Test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting ratings to like/not-like\n",
    "Train_torchtensor[Train_torchtensor == 0] = -1 # changing not seen movie to -1\n",
    "Train_torchtensor[Train_torchtensor == 1] = 0 # changing 1/2 rating movie to 0\n",
    "Train_torchtensor[Train_torchtensor == 2] = 0 # changing 1/2 rating movie to 0\n",
    "Train_torchtensor[Train_torchtensor >= 3] = 1 # changing 3/4/5 rating movie to 1\n",
    "\n",
    "Test_torchtensor[Test_torchtensor == 0] = -1 # changing not seen movie to -1\n",
    "Test_torchtensor[Test_torchtensor == 1] = 0 # changing 1/2 rating movie to 0\n",
    "Test_torchtensor[Test_torchtensor == 2] = 0 # changing 1/2 rating movie to 0\n",
    "Test_torchtensor[Test_torchtensor >= 3] = 1 # changing 3/4/5 rating movie to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#######################################################################################\n",
    "###################### Creating architecture of Neural Network ########################\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating NN architecture - in pytorch\n",
    "class RBM(): # always in caps\n",
    "    def __init__(self, nv, nh): # initialization function to create objects; nv=no of visible node; nh=no of hidden nodes\n",
    "        # nv = no of visible nodes = no of variables = no of movies\n",
    "        # when object created, this function is initialized automatically\n",
    "        self.W = torch.randn(nh, nv) # nh*nv are number of weights to be initialized by this nh*nv torch tensor\n",
    "        # weights should be random normal distribution values(hence randn), mean 0 and sd 1\n",
    "        self.a = torch.randn(1, nh) # initializing bias for hidden nodes given visible nodes(talking in PGM Model language)\n",
    "        self.b = torch.randn(1, nv) # initializing bias for visible nodes given hidden nodes\n",
    "    def sample_h(self, x): # Gibb's sampling function: will generate probabilities of all hidden nodes given visible nodes\n",
    "        # x represents the visible neurons/visible vector in the probabilities P(h/v)\n",
    "        wx = torch.mm(x, self.W.t()) # t() is transpose as W is wt matrix of P(v/h); mm=matrix multiplication\n",
    "        activation = wx + self.a.expand_as(wx) # activation is linear_comb=input*weight+bias; expand_as(wx) applies bias to all \n",
    "        # input vectors in mini-batch\n",
    "        p_h_given_v = torch.sigmoid(activation) # say a hidden neuron represents action movie, and Die Hard is input then this\n",
    "        # neuron will get activated\n",
    "        # if 100 neurons in hidden nodes, p_h_given_v represents 100 values vector of probabilities for these neurons\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "        # Bernoulli's Sampling-used to select 0/1(activation) as output for each hidden node; if p_h_given_v of a hidden node is\n",
    "        # 0.7, then Bernoulli's Sampling generates a rand prob between 0 and 1, if rand prob is 0.8 then output 1(as > 0.7),\n",
    "        # if rand prob 0.5, then output 0(as < 0.7)\n",
    "    def sample_v(self, y): # Gibb's sampling function: will generate probabilities of all visible nodes given hidden nodes\n",
    "        # y represents the hidden neurons/hidden vector in the probabilities V(v/h)\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk): # v0 & vk - 2D input/visible nodes values and visible nodes values after k C.Divergence\n",
    "        # ph0, phk are P(h0/v0) and P(hk/vk)\n",
    "        # self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk) # LHS and RHS not compatible\n",
    "        # 'print(rbm.W.size())'=100,3569--print((torch.mm(v0.t(), ph0)-torch.mm(vk.t(), phk)).size())=3569,100--t() required\n",
    "        self.W += ( torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk) ).t() # this line is diff than Udemy course\n",
    "        self.b += torch.sum((v0 - vk), 0) # 0 added to keep b as tensor of 2 dimensions\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "\n",
    "# with this class, many objects/models can be created with different configurations - can also add learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating RBM object/model\n",
    "nv = len(Train_torchtensor[0]) # nb_movies\n",
    "nh = 100 # no. of hidden nodes - say hundred features of movies to be identified - P. Tuning(100,200,)\n",
    "# lr: can be added in above function; currently default\n",
    "batch_size = 50 # weights update after these many steps - P. Tuning(50,100,200)\n",
    "rbm = RBM(nv, nh) # creating RBM object/model\n",
    "# there maybe class for 'adam', 'rmsprop' etc..maybe check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.2772)\n",
      "epoch: 2 loss: tensor(0.2373)\n",
      "epoch: 3 loss: tensor(0.2331)\n",
      "epoch: 4 loss: tensor(0.2278)\n",
      "epoch: 5 loss: tensor(0.2324)\n",
      "epoch: 6 loss: tensor(0.2330)\n",
      "epoch: 7 loss: tensor(0.2332)\n",
      "epoch: 8 loss: tensor(0.2331)\n",
      "epoch: 9 loss: tensor(0.2331)\n",
      "epoch: 10 loss: tensor(0.2325)\n",
      "epoch: 11 loss: tensor(0.2319)\n",
      "epoch: 12 loss: tensor(0.2328)\n",
      "epoch: 13 loss: tensor(0.2323)\n",
      "epoch: 14 loss: tensor(0.2323)\n",
      "epoch: 15 loss: tensor(0.2327)\n",
      "epoch: 16 loss: tensor(0.2326)\n",
      "epoch: 17 loss: tensor(0.2333)\n",
      "epoch: 18 loss: tensor(0.2326)\n",
      "epoch: 19 loss: tensor(0.2327)\n",
      "epoch: 20 loss: tensor(0.2331)\n"
     ]
    }
   ],
   "source": [
    "## training/opt the RBM\n",
    "np.random.seed(8)\n",
    "nb_epoch = 20 # P. Tuning(10,20)\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0. # float # to normalize the train_loss by dividng with this counter after every batch\n",
    "    for id_user in range(0, nb_users-batch_size, batch_size):\n",
    "        vk = Train_torchtensor[id_user:id_user+batch_size] # input; vk initialized with initial values\n",
    "        v0 = Train_torchtensor[id_user:id_user+batch_size] # target is v0\n",
    "        ph0,_ = rbm.sample_h(v0) # ,_ returns 1st value of function, p_v_given_h\n",
    "        for k in range(10): # k is number of random walks of contrastive divergence; no of times each input walks randomly\n",
    "            # P. Tuning(10,20)\n",
    "            _,hk = rbm.sample_h(vk) # _, returns 2nd value of function, bernoulli\n",
    "            _,vk = rbm.sample_v(hk) # these 2 steps will happen 10 times(random walks) for the whole batch(1 row a time)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk) # calculated after k CDs\n",
    "        rbm.train(v0, vk, ph0, phk) # weights/biases update after each batch completes random walk/Gibb's Sampling\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0])) # Mean Absolute Diff (RMSE to be used in Autoencoders)\n",
    "        # train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2)) # RMSE here\n",
    "        # here vk is the value of visible nodes after all iterations in an epoch\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "\n",
    "## validation set also required for train-test approach\n",
    "## understanding train_loss of 0.2328 - means nearly 3/4 predictions are correct on traning set - (1st iter)\n",
    "## (1st iter)-(nh=100,batch_size=100,nb_epoch=10,random_walks=10) - 0.2332\n",
    "## (2nd iter)-(nh=200,batch_size=100,nb_epoch=10,random_walks=10) - 0.2337\n",
    "## (3rd iter)-(nh=100,batch_size=100,nb_epoch=20,random_walks=10) - 0.2332\n",
    "## (4th iter)-(nh=100,batch_size=50,nb_epoch=20,random_walks=10) - 0.2331**\n",
    "## (5th iter)-(nh=100,batch_size=100,nb_epoch=20,random_walks=15) - 0.2334\n",
    "## (6th iter)-(nh=100,batch_size=100,nb_epoch=20,random_walks=15) - 0.2334\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2011)\n"
     ]
    }
   ],
   "source": [
    "## predicting on test data - calculating accuracy / test_loss\n",
    "\n",
    "# approach:\n",
    "# train,test are with same structure; all vacant(rating happened, but not present in train) ratings in train will be populated\n",
    "# then test ratings will be compared for accuracy\n",
    "np.random.seed(11)\n",
    "test_loss = 0\n",
    "s = 0. \n",
    "for id_user in range(nb_users): # rather than batch, for test we do this for each input\n",
    "    v = Train_torchtensor[id_user:id_user+1] # input; train set input will activate all required neurons; pred to happen on train data only\n",
    "    vt = Test_torchtensor[id_user:id_user+1] # target to be compared with\n",
    "    # ph0,_ = rbm.sample_h(v0) # required only for training, not testing\n",
    "    # for k in range(1): # model is trained, so in 1 CD we can get the output in visible nodes, so for loop not required\n",
    "    if len(vt[vt>=0]) > 0: # ratings prediction will happen for rows where some rating is present\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h) # only step of blind walk-random walks happen in training; single step while generating predictions is referred as blind walk because model strives to be accurate like a blind person walking\n",
    "        # vk[v0<0] = v0[v0<0] # required only for training\n",
    "        # phk,_ = rbm.sample_h(vk) # required only for training\n",
    "        # rbm.train(v0, vk, ph0, phk) # required only for training\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0])) # loss calculated only for present ratings present in test\n",
    "        # test_loss += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) # RMSE here\n",
    "        s += 1.\n",
    "        # test_loss and s counter brought under 'if' because they need to update only if some rating is present in test row\n",
    "print('test loss: '+str(test_loss/s)) # epochs removed\n",
    "\n",
    "# test loss: tensor(0.2171) is like 21.71% error, which is good - (1st iter)\n",
    "## (1st iter) - 0.2171\n",
    "## (4th iter) - 0.2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Error Metric and Activation Function:\n",
    "# MAE used here because of 0/1 predictions; Confusion Matrix can also be used\n",
    "# MAE may not be the best to optimize; can optimize using RMSE but report MAE\n",
    "## Activation Fn - Sigmoid (same for autoencoders)\n",
    "# Why Sigmoid - Maybe because only 1 hidden layer iteration(forward pass) before weight updation, \n",
    "#               so Relu's benefits of faster weight update and lesser risk of Van. Gradient do not apply\n",
    "#               Hence a more complex(non-linear) activation function used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## predicting on test data - calculating accuracy / test_loss\n",
    "## & creating an output with all recommendations\n",
    "\n",
    "# this code needs to be written - will be similar to previous para\n",
    "\n",
    "vt # shows how output looks (1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## also above code should be re-written with 2 vald sets, and auto parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#######################################################################################\n",
    "################### Stacked Autoencoders - Scoring on new data ######################\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Try to find existing packages\n",
    "# 2. Custom approach:\n",
    "    # find existing user closest to new user using RMSE(not cosine sim here)\n",
    "    # use this existing user's recomm for the new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
