{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) \n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "################ Importing Data #################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"abalone.csv\", encoding='ISO-8859-1')\n",
    "print(len(df1))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  \n",
       "0         0.150      15  \n",
       "1         0.070       7  \n",
       "2         0.210       9  \n",
       "3         0.155      10  \n",
       "4         0.055       7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename target to 'Target'\n",
    "df1 = df1.rename(columns = {'Rings':'Target'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     689\n",
       "10    634\n",
       "8     568\n",
       "11    487\n",
       "7     391\n",
       "12    267\n",
       "6     259\n",
       "13    203\n",
       "14    126\n",
       "5     115\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "4      57\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "3      15\n",
       "21     14\n",
       "23      9\n",
       "22      6\n",
       "24      2\n",
       "27      2\n",
       "1       1\n",
       "25      1\n",
       "2       1\n",
       "26      1\n",
       "29      1\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Distribution of Target Var\n",
    "df1['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     2854\n",
      "9      689\n",
      "10     634\n",
      "Name: Target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.330</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.260</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.165</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8945</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.320</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "5   I   0.425     0.300   0.095        0.3515          0.1410          0.0775   \n",
       "6   F   0.530     0.415   0.150        0.7775          0.2370          0.1415   \n",
       "7   F   0.545     0.425   0.125        0.7680          0.2940          0.1495   \n",
       "8   M   0.475     0.370   0.125        0.5095          0.2165          0.1125   \n",
       "9   F   0.550     0.440   0.150        0.8945          0.3145          0.1510   \n",
       "\n",
       "   Shell_weight  Target  \n",
       "0         0.150       8  \n",
       "1         0.070       8  \n",
       "2         0.210       9  \n",
       "3         0.155      10  \n",
       "4         0.055       8  \n",
       "5         0.120       8  \n",
       "6         0.330       8  \n",
       "7         0.260       8  \n",
       "8         0.165       9  \n",
       "9         0.320       8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to 3 categories for ease of implementation (10, 9, 8+)\n",
    "df1.loc[ (df1['Target'] != 9) & (df1['Target'] != 10) , 'Target'] = 8\n",
    "print(df1['Target'].value_counts())\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "################ Dummy Coding #################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  Sex_F  Sex_I  Sex_M  \n",
       "0         0.150       8      0      0      1  \n",
       "1         0.070       8      0      0      1  \n",
       "2         0.210       9      1      0      0  \n",
       "3         0.155      10      0      0      1  \n",
       "4         0.055       8      0      1      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.copy()\n",
    "df2_new = df2.copy()\n",
    "for i in range(len(df2.columns)):\n",
    "        if (df2.iloc[:,i].dtype==np.object or df2.iloc[:,i].dtype.name==\"category\"):\n",
    "            df2_dummy = pd.get_dummies(df2.iloc[:,i]) # ignores NA\n",
    "            for j in range(len(df2_dummy.columns)):\n",
    "                df2_dummy.columns.values[j] = df2.columns.values[i] + \"_\" + df2_dummy.columns.values[j]\n",
    "            df2_new = pd.concat([df2_new, df2_dummy], axis=1)\n",
    "for y in df2_new.columns: # new vars created are of type ‘uint8’, so converting to int\n",
    "     if(df2_new [y].dtype == np.uint8):\n",
    "        df2_new [y] = df2_new [y].astype('int')\n",
    "        \n",
    "dfx = df2_new.copy()\n",
    "S_List_Numeric = []\n",
    "S_List_Non_Numeric = []\n",
    "for i in range(len(dfx.columns)):\n",
    "    if (dfx.iloc[:,i].dtype==np.int64 or dfx.iloc[:,i].dtype==np.float64 or dfx.iloc[:,i].dtype==np.int32 or dfx.iloc[:,i].dtype==np.float32 or dfx.iloc[:,i].dtype==np.int16 or dfx.iloc[:,i].dtype==np.float16):\n",
    "        S_List_Numeric.append(i)\n",
    "    else:\n",
    "        S_List_Non_Numeric.append(i)\n",
    "dfx_Numeric = dfx.iloc[:,S_List_Numeric]\n",
    "     \n",
    "df2 = dfx_Numeric.copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Target</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Target  Sex_F  Sex_I  \n",
       "0         0.150       8      0      0  \n",
       "1         0.070       8      0      0  \n",
       "2         0.210       9      1      0  \n",
       "3         0.155      10      0      0  \n",
       "4         0.055       8      0      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop last variable of dummy coding (for each cat var)\n",
    "df2 = df2.drop(['Sex_M'],axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "############# Train-Vald-Test Split ##############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2912\n",
      "651\n",
      "614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70:15:15\n",
    "np.random.seed(4)\n",
    "msk = np.random.rand(len(df2)) < 0.7\n",
    "\n",
    "# Train set\n",
    "Train = df2[msk]\n",
    "\n",
    "Vald_Test = df2[~msk]\n",
    "msk = np.random.rand(len(Vald_Test)) < 0.5\n",
    "\n",
    "# Vald and Test sets\n",
    "Vald = Vald_Test[msk]\n",
    "Test = Vald_Test[~msk]\n",
    "\n",
    "# QC\n",
    "print(len(Train))\n",
    "print(len(Vald))\n",
    "print(len(Test))\n",
    "len(Train)+len(Vald)+len(Test) == len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "########### Separate X & Y of all datasets ############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antrived/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/antrived/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/antrived/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train = Train.drop(['Target'], axis=1)\n",
    "Y_Train = Train[[\"Target\"]]\n",
    "X_Train = X_Train.as_matrix()\n",
    "Y_Train = np.asarray(Y_Train).flatten()\n",
    "\n",
    "X_Vald = Vald.drop(['Target'], axis=1)\n",
    "Y_Vald = Vald[[\"Target\"]]\n",
    "X_Vald = X_Vald.as_matrix()\n",
    "Y_Vald = np.asarray(Y_Vald).flatten()\n",
    "\n",
    "X_Test = Test.drop(['Target'], axis=1)\n",
    "Y_Test = Test[[\"Target\"]]\n",
    "X_Test = X_Test.as_matrix()\n",
    "Y_Test = np.asarray(Y_Test).flatten()\n",
    "\n",
    "# QC\n",
    "len(X_Train)+len(X_Vald)+len(X_Test) == len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################\n",
    "############# Mean Standardization ##############\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_Train = sc.fit_transform(X_Train)\n",
    "X_Vald = sc.transform(X_Vald)\n",
    "X_Test = sc.transform(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################\n",
    "############# XGBoost (Multi-class) ##############\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######\n",
    "####### Training (Base Model) & Validation\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification related packages\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def common_predictions(model, X_test, Y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.astype(int)\n",
    "#     y_pred[y_pred > 0.5] = 1\n",
    "#     y_pred[y_pred <= 0.5] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "from xgboost import XGBClassifier\n",
    "def xgb_classifier(X_Train, Y_Train, max_depth, learning_rate, n_estimators, objective):\n",
    "    model = XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, objective=objective)\n",
    "    model.fit(X_Train, Y_Train)\n",
    "    return model\n",
    "\n",
    "# multi-class classification\n",
    "model = xgb_classifier(X_Train, Y_Train, max_depth=12, learning_rate=0.05, \n",
    "                       n_estimators=100, objective='multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction (class)\n",
    "y_pred = common_predictions(model, X_Vald, Y_Vald)\n",
    "\n",
    "## Prediction (probabilities)\n",
    "    # use 'predict_proba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[373  74  87]\n",
      " [ 38  15  13]\n",
      " [ 27  12  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.70      0.85      0.77       438\n",
      "           9       0.23      0.15      0.18       101\n",
      "          10       0.24      0.11      0.15       112\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       651\n",
      "   macro avg       0.39      0.37      0.36       651\n",
      "weighted avg       0.55      0.61      0.57       651\n",
      "\n",
      "first_class_f1: 0.77\n",
      "last_class_f1: 0.15\n",
      "micro_f1: 0.61\n",
      "macro_f1: 0.36\n",
      "wtd_f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "## Validation Accuracy\n",
    "cm1 = confusion_matrix(y_pred, Y_Vald)\n",
    "print(cm1)\n",
    "print(classification_report(Y_Vald, y_pred))\n",
    "# Micro Avg = Avg like this: P=(Match_1+Match_2+Match_3)/(Actual_1+Actual_2+Actual_3)\n",
    "# Macro Avg = Avg of (P,R) for individual classes\n",
    "# Weighted Avg = f-score weighted on support\n",
    "\n",
    "    # Micro vs Macro Avg - 1 literature said micro is good for \n",
    "        # skewed multi-class classification(its wrong info); but in one experiment \n",
    "        # on skewed data, micro-avg was giving incorrect picture and macro was much better\n",
    "        # so, macro-avg is the best indicator for skewed data\n",
    "    # Macro Avg best for Skewed data - best for skewed data for both binary and \n",
    "        # multi-class classification as it gives equal weightage to classes \n",
    "        # irrespective of their occurance (if all classes are importance)\n",
    "\n",
    "    # Ref: https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
    "    \n",
    "# get micro_f1, macro_f1, weighted_f1 (use to optimize params)\n",
    "temp = classification_report(Y_Vald, y_pred)\n",
    "list1 = temp.split()\n",
    "\n",
    "first_class_f1 = list1[7]\n",
    "last_class_f1 = list1[len(list1)-20]\n",
    "micro_f1 = list1[len(list1)-14]\n",
    "macro_f1 = list1[len(list1)-8]\n",
    "wtd_f1 = list1[len(list1)-2]\n",
    "\n",
    "print(\"first_class_f1: {}\".format(first_class_f1))\n",
    "print(\"last_class_f1: {}\".format(last_class_f1))\n",
    "print(\"micro_f1: {}\".format(micro_f1))\n",
    "print(\"macro_f1: {}\".format(macro_f1))\n",
    "print(\"wtd_f1: {}\".format(wtd_f1))\n",
    "\n",
    "# use micro_f1 for skewed multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot Confusion Matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    plt.figure(figsize=[7, 6])\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)\n",
    "        plt.savefig('confusion-matrix.png')\n",
    "\n",
    "plot_confusion_matrix(cm1, ['8', '9', '10'])\n",
    "# ref: https://github.com/gabrielziegler3/xgboost-multiclass-multilabel/blob/master/xgboost-multiclass-multilabel/multiclass-classification-examples.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######\n",
    "####### Hyper-Param Tuning (K-fold CV) - Grid/Random Search\n",
    "####### 1st Approach - Recommended\n",
    "####### (easily extensible to other algorithms)\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "from xgboost import XGBClassifier\n",
    "def xgb_classifier(X_Train, Y_Train, max_depth, learning_rate, n_estimators, objective):\n",
    "    model = XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, objective=objective)\n",
    "    model.fit(X_Train, Y_Train)\n",
    "    return model\n",
    "\n",
    "# multi-class classification\n",
    "clf = xgb_classifier(X_Train, Y_Train, max_depth=12, learning_rate=0.05, \n",
    "                       n_estimators=100, objective='multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.85001364, 1.36617203, 0.79413776, 1.20495996]), 'std_fit_time': array([0.02387393, 0.08311611, 0.01987935, 0.04923845]), 'mean_score_time': array([0.01070089, 0.01654735, 0.01387987, 0.02265778]), 'std_score_time': array([0.00165201, 0.00473083, 0.00121138, 0.00369148]), 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.1, 0.1],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[8, 12, 8, 12],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.001, 'max_depth': 8}, {'learning_rate': 0.001, 'max_depth': 12}, {'learning_rate': 0.1, 'max_depth': 8}, {'learning_rate': 0.1, 'max_depth': 12}], 'split0_test_score': array([0.32236208, 0.3336395 , 0.34170739, 0.35387556]), 'split1_test_score': array([0.381422  , 0.42110597, 0.41751559, 0.42008462]), 'split2_test_score': array([0.3837938 , 0.41723964, 0.38606167, 0.39278896]), 'split3_test_score': array([0.38857698, 0.435405  , 0.43047367, 0.45092209]), 'split4_test_score': array([0.41424649, 0.40649868, 0.42812456, 0.40263258]), 'mean_test_score': array([0.37805183, 0.402764  , 0.4007476 , 0.40404565]), 'std_test_score': array([0.03022093, 0.0358002 , 0.03351841, 0.0319433 ]), 'rank_test_score': array([4, 2, 3, 1], dtype=int32), 'split0_train_score': array([0.62676618, 0.87453739, 0.9409456 , 0.99946867]), 'split1_train_score': array([0.55486248, 0.7824494 , 0.93625433, 0.99572032]), 'split2_train_score': array([0.60428959, 0.80953394, 0.9396521 , 0.99409808]), 'split3_train_score': array([0.58563832, 0.8244937 , 0.92108977, 0.99572084]), 'split4_train_score': array([0.59008983, 0.79018066, 0.9252969 , 0.99572972]), 'mean_train_score': array([0.59232928, 0.81623902, 0.93264774, 0.99614753]), 'std_train_score': array([0.02359023, 0.03265754, 0.00798179, 0.00177591])}\n",
      "------- Ranks(lower is good) -------\n",
      "[4 2 3 1]\n",
      "--- Best Location ---\n",
      "3\n",
      "------- Best Score -------\n",
      "0.40404565072077003\n",
      "------- Best Params -------\n",
      "{'learning_rate': 0.1, 'max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "# !pip install scikit-learn\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "sys.path.append('xgboost/wrapper/')\n",
    "import xgboost as xgb\n",
    "\n",
    "# USER INPUT\n",
    "acc_type = 'f1_macro'\n",
    "    # 'f1_micro', 'f1_macro', 'f1_weighted', \n",
    "    # refer: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring\n",
    "cv_folds = 5\n",
    "# also change 'objective': 'multi:softprob' as appropriate\n",
    "search_type = 'GridSearchCV' # 'RandomizedSearchCV', 'GridSearchCV'\n",
    "iters_rand_search = 20 # applies for 'RandomizedSearchCV'\n",
    "# set algo seach 'parameters' below\n",
    "\n",
    "parameters = {\n",
    "#     'n_estimators': [100, 150, 200, 250, 300], # no of trees\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'max_depth': [8, 12], # doesn't work for too small values like [1, 2]\n",
    "#     'gamma': [0, 0.2],\n",
    "#     min_child_weight=1,\n",
    "#     max_delta_step=0,\n",
    "#     subsample=1,\n",
    "#     'colsample_bytree': [0.7, 0.8, 1],\n",
    "#     colsample_bylevel=1,\n",
    "#     colsample_bynode=1,\n",
    "#     reg_alpha=0,\n",
    "#     reg_lambda=1,\n",
    "#     scale_pos_weight=1,\n",
    "}\n",
    "\n",
    "if search_type == 'GridSearchCV':\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs=1, cv=cv_folds, scoring=acc_type)\n",
    "elif search_type == 'RandomizedSearchCV':\n",
    "    clf = RandomizedSearchCV(clf, parameters, n_jobs=1, \n",
    "                             cv=cv_folds, n_iter=iters_rand_search, scoring=acc_type)\n",
    "    # 'n_iter' in random_search allows to do limited searches in a bigger search space\n",
    "        # say 100 random searches in a search space of 10,000\n",
    "        \n",
    "clf.fit(X_Train, Y_Train)\n",
    "print(clf.cv_results_)\n",
    "\n",
    "print(\"------- Ranks(lower is good) -------\")\n",
    "print(clf.cv_results_['rank_test_score'])\n",
    "\n",
    "list1 = list(clf.cv_results_['mean_test_score'])\n",
    "best_loc = list1.index( max(list1) )\n",
    "\n",
    "print(\"--- Best Location ---\")\n",
    "print(best_loc)\n",
    "\n",
    "print(\"------- Best Score -------\")\n",
    "print(clf.cv_results_['mean_test_score'][best_loc])\n",
    "print(\"------- Best Params -------\")\n",
    "print(clf.cv_results_['params'][best_loc])\n",
    "\n",
    "# Insight: Even after 5 fold CV, model may seem to overfit for acc. metrics \n",
    "    # affected by skewed target like 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction (class)\n",
    "y_pred = common_predictions(clf, X_Vald, Y_Vald)\n",
    "\n",
    "## Prediction (probabilities)\n",
    "    # use 'predict_proba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[371  75  86]\n",
      " [ 35  17  14]\n",
      " [ 32   9  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.70      0.85      0.76       438\n",
      "           9       0.26      0.17      0.20       101\n",
      "          10       0.23      0.11      0.15       112\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       651\n",
      "   macro avg       0.39      0.37      0.37       651\n",
      "weighted avg       0.55      0.61      0.57       651\n",
      "\n",
      "first_class_f1: 0.76\n",
      "last_class_f1: 0.15\n",
      "micro_f1: 0.61\n",
      "macro_f1: 0.37\n",
      "wtd_f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "## Validation Accuracy\n",
    "cm1 = confusion_matrix(y_pred, Y_Vald)\n",
    "print(cm1)\n",
    "print(classification_report(Y_Vald, y_pred))\n",
    "\n",
    "# get micro_f1, macro_f1, weighted_f1 (use to optimize params)\n",
    "temp = classification_report(Y_Vald, y_pred)\n",
    "list1 = temp.split()\n",
    "\n",
    "first_class_f1 = list1[7]\n",
    "last_class_f1 = list1[len(list1)-20]\n",
    "micro_f1 = list1[len(list1)-14]\n",
    "macro_f1 = list1[len(list1)-8]\n",
    "wtd_f1 = list1[len(list1)-2]\n",
    "\n",
    "print(\"first_class_f1: {}\".format(first_class_f1))\n",
    "print(\"last_class_f1: {}\".format(last_class_f1))\n",
    "print(\"micro_f1: {}\".format(micro_f1))\n",
    "print(\"macro_f1: {}\".format(macro_f1))\n",
    "print(\"wtd_f1: {}\".format(wtd_f1))\n",
    "\n",
    "# use micro_f1 for skewed multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######\n",
    "####### Hyper-Param Tuning (K-fold CV) - Grid/Random Search\n",
    "####### 2nd Approach (for custom score() function)\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[0.35, 0.265, 0.09, 0.2255, 0.0995, 0.0485, 0.07, 0.0, 0.0], [0.33, 0.255, 0.08, 0.205, 0.0895, 0.0395, 0.055, 0.0, 1.0], [0.425, 0.3, 0.095, 0.3515, 0.141, 0.0775, 0.12, 0.0, 1.0]]\n",
      "['8', '8', '8']\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing - bit different than above\n",
    "X_Train = Train.drop(['Target'], axis=1)\n",
    "Y_Train = Train[[\"Target\"]]\n",
    "X_Train = [ list(X_Train.iloc[x,:]) for x in range(len(X_Train)) ]\n",
    "Y_Train = [ str(Y_Train.iat[x,0]) for x in range(len(Y_Train)) ]\n",
    "\n",
    "X_Vald = Vald.drop(['Target'], axis=1)\n",
    "Y_Vald = Vald[[\"Target\"]]\n",
    "X_Vald = [ list(X_Vald.iloc[x,:]) for x in range(len(X_Vald)) ]\n",
    "# Y_Vald = [ str(Y_Vald.iat[x,0]) for x in range(len(Y_Vald)) ]\n",
    "\n",
    "X_Test = Test.drop(['Target'], axis=1)\n",
    "Y_Test = Test[[\"Target\"]]\n",
    "X_Test = [ list(X_Test.iloc[x,:]) for x in range(len(X_Test)) ]\n",
    "# Y_Test = [ str(Y_Test.iat[x,0]) for x in range(len(Y_Test)) ]\n",
    "\n",
    "# QC\n",
    "print( len(X_Train)+len(X_Vald)+len(X_Test) == len(df2) )\n",
    "print(X_Train[0:3])\n",
    "print(Y_Train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.3234547 , 0.51096169, 0.38306268, 0.54103994]), 'std_fit_time': array([0.01719548, 0.01296334, 0.00961556, 0.00262967]), 'mean_score_time': array([0.01097727, 0.01918117, 0.01260416, 0.01668946]), 'std_score_time': array([0.00060003, 0.00120961, 0.00090051, 0.00058927]), 'param_max_depth': masked_array(data=[12, 12, 14, 14],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_num_boost_round': masked_array(data=[100, 150, 100, 150],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 12, 'num_boost_round': 100}, {'max_depth': 12, 'num_boost_round': 150}, {'max_depth': 14, 'num_boost_round': 100}, {'max_depth': 14, 'num_boost_round': 150}], 'split0_test_score': array([0.38, 0.39, 0.37, 0.37]), 'split1_test_score': array([0.42, 0.42, 0.4 , 0.4 ]), 'split2_test_score': array([0.43, 0.42, 0.42, 0.42]), 'mean_test_score': array([0.40999313, 0.40999657, 0.39665865, 0.39665865]), 'std_test_score': array([0.021603  , 0.01414335, 0.02054702, 0.02054702]), 'rank_test_score': array([2, 1, 3, 3], dtype=int32), 'split0_train_score': array([1., 1., 1., 1.]), 'split1_train_score': array([1., 1., 1., 1.]), 'split2_train_score': array([1., 1., 1., 1.]), 'mean_train_score': array([1., 1., 1., 1.]), 'std_train_score': array([0., 0., 0., 0.])}\n",
      "------- Ranks(lower is good) -------\n",
      "[2 1 3 3]\n",
      "--- Best Location ---\n",
      "1\n",
      "------- Best Score -------\n",
      "0.40999656593406586\n",
      "------- Best Params -------\n",
      "{'max_depth': 12, 'num_boost_round': 150}\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "# Implementation Link:\n",
    "    # https://inclass.kaggle.com/tanitter/grid-search-xgboost-with-scikit-learn\n",
    "# Customized the code in link\n",
    "\n",
    "# !pip install scikit-learn\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "sys.path.append('xgboost/wrapper/')\n",
    "import xgboost as xgb\n",
    "\n",
    "# USER INPUT\n",
    "accuracy_type = 'macro_f1' \n",
    "    # 'first_class_f1', 'last_class_f1', 'micro_f1', 'macro_f1', 'wtd_f1', 'logloss'\n",
    "cv_folds = 3\n",
    "num_class = 3\n",
    "# also change 'objective': 'multi:softprob' as appropriate\n",
    "search_type = 'GridSearchCV' # 'RandomizedSearchCV', 'GridSearchCV'\n",
    "iters_rand_search = 10 # applies for 'RandomizedSearchCV'\n",
    "# set algo seach 'parameters' below\n",
    "\n",
    "class XGBoostClassifier():\n",
    "    \n",
    "    def __init__(self, num_boost_round=10, **params):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = params\n",
    "        self.params.update({'objective': 'multi:softprob'}) # USER_INPUT\n",
    "            # binary classification - 'binary:logistic'\n",
    "            # linear regression - 'reg:linear'\n",
    "\n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        self.label2num = {label: i for i, label in enumerate(sorted(set(y)))}\n",
    "        dtrain = xgb.DMatrix(X, label=[self.label2num[label] for label in y])\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    "\n",
    "    def predict(self, X):\n",
    "        num2label = {i: label for label, i in self.label2num.items()}\n",
    "        Y = self.predict_proba(X)\n",
    "        y = np.argmax(Y, axis=1)\n",
    "        return np.array([num2label[i] for i in y])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.clf.predict(dtest)\n",
    "\n",
    "    def score(self, X, y):  \n",
    "        if accuracy_type in ['first_class_f1', 'last_class_f1', \n",
    "                             'micro_f1', 'macro_f1', 'wtd_f1']:\n",
    "            y = [int(x) for x in y]\n",
    "            y_pred = self.predict(X)\n",
    "            y_pred = y_pred.astype(int) \n",
    "            list1 = classification_report(y, y_pred).split()\n",
    "            \n",
    "            if accuracy_type == 'first_class_f1':\n",
    "                acc = float(list1[7]) # first_class_f1\n",
    "            elif accuracy_type == 'last_class_f1':\n",
    "                acc = float(list1[len(list1)-20]) # last_class_f1  \n",
    "            elif accuracy_type == 'micro_f1':\n",
    "                acc = float(list1[len(list1)-14]) # micro_f1\n",
    "            elif accuracy_type == 'macro_f1':\n",
    "                acc = float(list1[len(list1)-8]) # macro_f1\n",
    "            elif accuracy_type == 'wtd_f1':\n",
    "                acc = float(list1[len(list1)-2]) # wtd_f1\n",
    "        elif accuracy_type in ['logloss']:\n",
    "            Y = self.predict_proba(X)\n",
    "            acc = 1 / logloss(y, Y)\n",
    "            \n",
    "        return acc\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "def logloss(y_true, Y_pred):\n",
    "    label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))\n",
    "    return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf for y, label in zip(Y_pred, y_true)) / len(Y_pred)\n",
    "\n",
    "\n",
    "clf = XGBoostClassifier(\n",
    "    eval_metric = 'auc',\n",
    "    num_class = num_class,\n",
    "    nthread = 4,\n",
    "    silent = 1,\n",
    "    )\n",
    "parameters = {\n",
    "    'num_boost_round': [100, 150], # no of trees\n",
    "#     'eta': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1],\n",
    "    'max_depth': [12, 14], # doesn't work for too small values like [1, 2]\n",
    "#     'subsample': [0.6, 0.7, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.7, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "if search_type == 'GridSearchCV':\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs=1, cv=cv_folds)\n",
    "elif search_type == 'RandomizedSearchCV':\n",
    "    clf = RandomizedSearchCV(clf, parameters, n_jobs=1, \n",
    "                             cv=cv_folds, n_iter=iters_rand_search)\n",
    "    # 'n_iter' in random_search allows to do limited searches in a bigger search space\n",
    "        # say 100 random searches in a search space of 10,000\n",
    "clf.fit(X_Train, Y_Train)\n",
    "print(clf.cv_results_)\n",
    "\n",
    "print(\"------- Ranks(lower is good) -------\")\n",
    "print(clf.cv_results_['rank_test_score'])\n",
    "\n",
    "list1 = list(clf.cv_results_['mean_test_score'])\n",
    "best_loc = list1.index( max(list1) )\n",
    "\n",
    "print(\"--- Best Location ---\")\n",
    "print(best_loc)\n",
    "\n",
    "print(\"------- Best Score -------\")\n",
    "print(clf.cv_results_['mean_test_score'][best_loc])\n",
    "print(\"------- Best Params -------\")\n",
    "print(clf.cv_results_['params'][best_loc])\n",
    "\n",
    "# Insight: Even after 5 fold CV, model may seem to overfit for acc. metrics \n",
    "    # affected by skewed target like 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 9 8]\n",
      "651\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## Prediction (class)\n",
    "y_pred = clf.best_estimator_.predict(X_Vald)\n",
    "y_pred = y_pred.astype(int)\n",
    "print(y_pred[0:3])\n",
    "print(len(y_pred))\n",
    "print(type(y_pred))\n",
    "## Prediction (probability)\n",
    "    # use 'predict_proba' from class above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[360  71  84]\n",
      " [ 43  20  16]\n",
      " [ 35  10  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.70      0.82      0.76       438\n",
      "           9       0.25      0.20      0.22       101\n",
      "          10       0.21      0.11      0.14       112\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       651\n",
      "   macro avg       0.39      0.38      0.37       651\n",
      "weighted avg       0.55      0.60      0.57       651\n",
      "\n",
      "first_class_f1: 0.76\n",
      "last_class_f1: 0.14\n",
      "micro_f1: 0.60\n",
      "macro_f1: 0.37\n",
      "wtd_f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "## Validation Accuracy\n",
    "# model = xgb_classifier(X_Train, Y_Train, max_depth=12, learning_rate=0.3, \n",
    "#                        n_estimators=250, objective='multi:softmax')\n",
    "# c = common_predictions(model, X_Vald, Y_Vald)\n",
    "\n",
    "cm1 = confusion_matrix(y_pred, Y_Vald)\n",
    "print(cm1)\n",
    "print(classification_report(Y_Vald, y_pred))\n",
    "\n",
    "temp = classification_report(Y_Vald, y_pred)\n",
    "list1 = temp.split()\n",
    "\n",
    "first_class_f1 = list1[7]\n",
    "last_class_f1 = list1[len(list1)-20]\n",
    "micro_f1 = list1[len(list1)-14]\n",
    "macro_f1 = list1[len(list1)-8]\n",
    "wtd_f1 = list1[len(list1)-2]\n",
    "\n",
    "print(\"first_class_f1: {}\".format(first_class_f1))\n",
    "print(\"last_class_f1: {}\".format(last_class_f1))\n",
    "print(\"micro_f1: {}\".format(micro_f1))\n",
    "print(\"macro_f1: {}\".format(macro_f1))\n",
    "print(\"wtd_f1: {}\".format(wtd_f1))\n",
    "\n",
    "# should be close to 'K-fold CV accuracy above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################\n",
    "############# XGBoost (Regression) ##############\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antrived/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/antrived/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.946333\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "model = xgb_classifier(X_Train, Y_Train, max_depth=6, learning_rate=0.3, \n",
    "                       n_estimators=150, objective='reg:linear')\n",
    "y_pred = common_predictions(model, X_Vald, Y_Vald)\n",
    "\n",
    "# Validation\n",
    "rmse = np.sqrt(mean_squared_error(Y_Vald, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search - not running\n",
    "# Ref: https://stats.stackexchange.com/questions/183984/how-to-use-xgboost-cv-with-hyperparameters-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
